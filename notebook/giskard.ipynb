{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb432d4-ecf5-40cd-8215-8227100a0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/vishwajith/.local/lib/python3.10/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-openai in /home/vishwajith/.local/lib/python3.10/site-packages (0.2.14)\n",
      "Collecting langchain_pinecone\n",
      "  Downloading langchain_pinecone-0.2.12-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting docarray\n",
      "  Downloading docarray-0.41.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting pydantic==1.10.8\n",
      "  Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (146 kB)\n",
      "Requirement already satisfied: pytube in /home/vishwajith/.local/lib/python3.10/site-packages (15.0.0)\n",
      "Requirement already satisfied: python-dotenv in /home/vishwajith/.local/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: tiktoken in /home/vishwajith/.local/lib/python3.10/site-packages (0.9.0)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting ruff\n",
      "  Downloading ruff-0.14.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pypdf in /home/vishwajith/.local/lib/python3.10/site-packages (5.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from pydantic==1.10.8) (4.14.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (0.3.45)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.22-py3-none-any.whl.metadata (7.8 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (3.12.13)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.6-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.43 (from langchain)\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vishwajith/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vishwajith/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vishwajith/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.20.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/vishwajith/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/vishwajith/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio in /home/vishwajith/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/vishwajith/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vishwajith/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.3)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vishwajith/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vishwajith/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vishwajith/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/vishwajith/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.20-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.15-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from langchain-openai) (1.93.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/vishwajith/.local/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /home/vishwajith/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/vishwajith/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/vishwajith/.local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of langchain-pinecone to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_pinecone\n",
      "  Downloading langchain_pinecone-0.2.11-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading langchain_pinecone-0.2.10-py3-none-any.whl.metadata (5.3 kB)\n",
      "  Downloading langchain_pinecone-0.2.9-py3-none-any.whl.metadata (5.3 kB)\n",
      "  Downloading langchain_pinecone-0.2.8-py3-none-any.whl.metadata (5.3 kB)\n",
      "  Downloading langchain_pinecone-0.2.7-py3-none-any.whl.metadata (5.3 kB)\n",
      "  Downloading langchain_pinecone-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
      "  Downloading langchain_pinecone-0.2.5-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-pinecone to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_pinecone-0.2.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading langchain_pinecone-0.2.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading langchain_pinecone-0.2.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting langchain_pinecone\n",
      "  Downloading langchain_pinecone-0.2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting langchain_pinecone\n",
      "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_pinecone-0.1.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "\u001b[33mWARNING: langchain 0.3.26 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of langchain[docarray] to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[33mWARNING: langchain 1.0.1 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 1.0.0 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.27 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.25 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.24 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.23 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.22 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is still looking at multiple versions of langchain[docarray] to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[33mWARNING: langchain 0.3.21 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.20 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.19 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.18 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.17 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "\u001b[33mWARNING: langchain 0.3.16 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.15 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.14 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.13 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.12 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.11 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.10 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.9 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.8 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.7 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.6 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.5 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.4 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.3 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.2 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.1 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.3.0 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: langchain 0.2.17 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: rich>=13.1.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from docarray) (13.9.4)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in /home/vishwajith/.local/lib/python3.10/site-packages (from docarray) (2.32.4.20250809)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vishwajith/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/vishwajith/.local/lib/python3.10/site-packages (from typing-inspect>=0.8.0->docarray) (1.1.0)\n",
      "Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.2.17-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "Downloading langchain_pinecone-0.1.3-py3-none-any.whl (10 kB)\n",
      "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading docarray-0.41.0-py3-none-any.whl (302 kB)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.14.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, ruff, pydantic, pinecone-plugin-interface, numpy, pinecone-plugin-inference, scikit-learn, pinecone-client, docarray, langsmith, langchain-core, langchain-text-splitters, langchain_pinecone, langchain-openai, langchain\n",
      "\u001b[2K  Attempting uninstall: pydantic2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [ruff]\n",
      "\u001b[2K    Found existing installation: pydantic 2.11.738;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [ruff]\n",
      "\u001b[2K    Uninstalling pydantic-2.11.7:;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [ruff]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.11.7\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [ruff]\n",
      "\u001b[2K  Attempting uninstall: numpym\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.638;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.638;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: langsmith━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [docarray]necone-client]\n",
      "\u001b[2K    Found existing installation: langsmith 0.3.45237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [docarray]\n",
      "\u001b[2K    Uninstalling langsmith-0.3.45:━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [docarray]\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.3.455;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [docarray]\n",
      "\u001b[2K  Attempting uninstall: langchain-core━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [langsmith]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.687m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [langsmith]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.68:━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [langsmith]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.68237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [langsmith]\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splitters[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 0.3.84m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-0.3.8:[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-0.3.8114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain-openai━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-openai 0.2.149;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-openai-0.2.14:━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-openai-0.2.14249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain 0.3.2638;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-0.3.26:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m14/15\u001b[0m [langchain]in-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.3.26━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m14/15\u001b[0m [langchain]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [langchain][0m \u001b[32m14/15\u001b[0m [langchain]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "a2a-sdk 0.2.10 requires pydantic>=2.11.3, but you have pydantic 1.10.8 which is incompatible.\n",
      "acp-sdk 0.0.6 requires pydantic<3.0.0,>=2.7.2, but you have pydantic 1.10.8 which is incompatible.\n",
      "acp-sdk 0.0.6 requires setuptools==75.8.0, but you have setuptools 80.9.0 which is incompatible.\n",
      "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.22.1 which is incompatible.\n",
      "crewai 0.148.0 requires pydantic>=2.4.2, but you have pydantic 1.10.8 which is incompatible.\n",
      "crewai-tools 0.58.0 requires pydantic>=2.6.1, but you have pydantic 1.10.8 which is incompatible.\n",
      "docling 2.54.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "docling-core 2.48.3 requires pydantic!=2.10.0,!=2.10.1,!=2.10.2,<3.0.0,>=2.6.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "docling-ibm-models 3.9.1 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "docling-parse 4.5.0 requires pydantic>=2.0.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "embedchain 0.1.128 requires langchain<0.4.0,>=0.3.1, but you have langchain 0.2.17 which is incompatible.\n",
      "embedchain 0.1.128 requires langchain-openai<0.3.0,>=0.2.1, but you have langchain-openai 0.1.25 which is incompatible.\n",
      "embedchain 0.1.128 requires langsmith<0.4.0,>=0.3.18, but you have langsmith 0.1.147 which is incompatible.\n",
      "google-adk 1.9.0 requires pydantic<3.0.0,>=2.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "google-genai 1.28.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "instructor 1.9.2 requires pydantic<3.0.0,>=2.8.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "langchain-cohere 0.3.5 requires langchain-core<0.4.0,>=0.3.27, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-cohere 0.3.5 requires pydantic<3,>=2, but you have pydantic 1.10.8 which is incompatible.\n",
      "langchain-community 0.3.27 requires langchain<1.0.0,>=0.3.26, but you have langchain 0.2.17 which is incompatible.\n",
      "langchain-community 0.3.27 requires langchain-core<1.0.0,>=0.3.66, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-deepseek 0.1.3 requires langchain-core<1.0.0,>=0.3.47, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-deepseek 0.1.3 requires langchain-openai<1.0.0,>=0.3.9, but you have langchain-openai 0.1.25 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-google-genai 2.1.9 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "langchain-google-genai 2.1.9 requires langchain-core<0.4.0,>=0.3.68, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-google-genai 2.1.9 requires pydantic<3,>=2, but you have pydantic 1.10.8 which is incompatible.\n",
      "langchain-groq 0.3.6 requires langchain-core<1.0.0,>=0.3.68, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-mcp-adapters 0.1.9 requires langchain-core<0.4,>=0.3.36, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langgraph 0.5.3 requires pydantic>=2.7.4, but you have pydantic 1.10.8 which is incompatible.\n",
      "langgraph-prebuilt 0.5.2 requires langchain-core>=0.3.67, but you have langchain-core 0.2.43 which is incompatible.\n",
      "litellm 1.72.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "llama-cloud-services 0.6.54 requires pydantic!=2.10,>=2.8, but you have pydantic 1.10.8 which is incompatible.\n",
      "llama-index-core 0.13.4 requires pydantic>=2.8.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "llama-index-instrumentation 0.4.0 requires pydantic>=2.11.5, but you have pydantic 1.10.8 which is incompatible.\n",
      "llama-index-workflows 1.3.0 requires pydantic>=2.11.5, but you have pydantic 1.10.8 which is incompatible.\n",
      "mcp 1.11.0 requires pydantic<3.0.0,>=2.8.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "mem0ai 0.1.115 requires pydantic>=2.7.3, but you have pydantic 1.10.8 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pydantic-settings 2.10.1 requires pydantic>=2.7.0, but you have pydantic 1.10.8 which is incompatible.\n",
      "ragas 0.3.7 requires pydantic>=2.0.0, but you have pydantic 1.10.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed docarray-0.41.0 langchain-0.2.17 langchain-core-0.2.43 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langchain_pinecone-0.1.3 langsmith-0.1.147 numpy-1.26.4 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7 pydantic-1.10.8 ruff-0.14.1 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langchain_pinecone \"langchain[docarray]\" docarray pydantic==1.10.8 pytube python-dotenv tiktoken pinecone-client scikit-learn ruff pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99a1e9b-7e73-4ac5-9ae2-3957f7d97e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key set successfully! Model: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Ask user to input the API key securely\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Access the key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the model\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "print(\"API key set successfully! Model:\", MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fcd74a7-6f04-4a3f-ab2f-5bd762eaa507",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.text_splitter'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WebBaseLoader\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m      4\u001b[39m text_splitter = RecursiveCharacterTextSplitter(chunk_size=\u001b[32m1000\u001b[39m, chunk_overlap=\u001b[32m20\u001b[39m)\n\u001b[32m      6\u001b[39m loader = WebBaseLoader(\u001b[33m\"\u001b[39m\u001b[33mhttps://www.ml.school/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.text_splitter'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.ml.school/\")\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a349c8d-bb57-40d3-ab39-85815b357968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117554b5-fe30-4b27-822b-ba34db1a243e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a96de9-4eeb-4e4a-bd36-c1ce63b709c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901b119-3b48-4c92-a602-de50eba9af03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f0375-8c90-412d-b731-5aae696364ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49396a93-cef4-45d8-9a10-9531c0609662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99db0b-ab75-4967-93b0-7710174a96bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1fc7f-6e8f-4d9b-b351-27e1d51656cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136bd3e-e845-4d3e-a8b5-c7529c3f5b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6ee28-f7b1-45b7-8520-7c21b36b6a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c7801-588d-48e3-8e14-293af8f6c095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386b88a-03be-4cec-af2a-df9d32c40fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
