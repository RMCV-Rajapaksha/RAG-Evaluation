user_input,reference_contexts,reference,synthesizer_name
What is the importance of MCP in AI applications?,"[""**Time Range: 00:00:03 - 00:10:04**\n\n# [3.76s] Introduction to AI and Generative AI\nGood morning, everybody. The focus of today's discussion is on artificial intelligence (AI), particularly generative AI. We will explore the significance of integration in building AI applications in the current landscape, especially with the rise of generative AI. This topic is crucial, and we will also cover common integration patterns associated with generative AI.\n\n## [42.32s] The Need for Retrieval-Augmented Generation\nIn addition to integration patterns, we will delve into the necessity of retrieval-augmented generation. This will be discussed in detail, along with the concept of agents, which is a hot topic in the AI community today. We will also examine the importance of the Model Context Protocol (MCP) and the responsibility that comes with building effective AI applications. It is essential that AI systems are designed with certain guardrails and governance in mind. We will touch upon the concept of zero trust design for AI agents, which, while traditionally applied to other domains, is now being adapted for AI.""]","The Model Context Protocol (MCP) is important in AI applications as it is associated with the responsibility of building effective AI systems, ensuring they are designed with guardrails and governance in mind.",single_hop_specific_query_synthesizer
"Waht is the role of AI in generative content creation, and how do large language models fit into this?","['## [115.60s] Defining Key Terminologies\nBefore we proceed, it is important to define some key terminologies. AI refers to any system that can simulate human intelligence. This can range from simple functions to complex machine learning models and deep learning architectures. Generative AI, a subset of AI, focuses on creating original content, which can include text, audio, and visual elements.\n\n### [155.28s] Understanding Large Language Models\nLarge language models (LLMs), such as ChatGPT from OpenAI, are examples of generative AI that specialize in natural language processing. They are designed to understand and generate text, making them a significant advancement in the field.']","AI refers to any system that can simulate human intelligence, ranging from simple functions to complex machine learning models and deep learning architectures. Generative AI, a subset of AI, focuses on creating original content, which can include text, audio, and visual elements. Large language models (LLMs), such as ChatGPT from OpenAI, are examples of generative AI that specialize in natural language processing. They are designed to understand and generate text, making them a significant advancement in the field.",single_hop_specific_query_synthesizer
Why large language models important now?,"['## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.']","Large language models are important now because they allow users to perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. They are versatile, can be applied across different domains, and are available as APIs, making them easily accessible for developers.",single_hop_specific_query_synthesizer
"What are the challenges associated with hallucination in generative AI models, and how does it affect their factual accuracy?","['## [337.84s] Limitations of Generative AI\nWhile generative AI offers many advantages, it also has limitations. One of the primary challenges is the phenomenon known as ""hallucination,"" where generative models can produce false information that appears convincing. For instance, if asked about the first person to walk on the moon, a model might fabricate an incorrect answer, demonstrating its lack of factual accuracy.\n\n### [482.56s] Addressing Limitations\nTo mitigate these issues, providing context to the model can help. However, even with context, models can still produce inaccurate outputs. Another limitation is their performance with mathematical problems, which has improved with fine-tuning but remains a concern for integration developers.']","One of the primary challenges associated with hallucination in generative AI models is that they can produce false information that appears convincing. This affects their factual accuracy, as demonstrated by instances where a model might fabricate incorrect answers to factual questions, such as identifying the first person to walk on the moon.",single_hop_specific_query_synthesizer
"How does Retrieval-Augmented Generation (RAG) improve the efficiency of large language models in processing medical data, and what are the steps involved in the RAG process?","[""**Time Range: 00:10:01 - 00:20:02**\n\n# [1253.20s] Introduction to Retrieval-Augmented Generation\nTo address these challenges, the solution lies in retrieval-augmented generation (RAG). This approach is gaining attention as it allows for more efficient use of data within large language models (LLMs). The core idea is straightforward: rather than inputting all available information into the model's prompt, only the relevant data should be included. However, determining what is relevant poses a significant challenge.\n\n## [1298.16s] The RAG Process\nRAG suggests that before incorporating data into prompts, one should first index the data. This can be achieved using vector embeddings and a vector database. The process involves creating a search index, which allows for efficient retrieval of relevant information when a question or task arises. For instance, similar to how Google retrieves links based on a search query, RAG utilizes an index to find pertinent information, which is then fed to the LLM to generate answers.""]","Retrieval-Augmented Generation (RAG) improves the efficiency of large language models by ensuring that only relevant data is included in the model's prompt, rather than inputting all available information. This approach involves indexing the data using vector embeddings and a vector database, creating a search index for efficient retrieval of relevant information. When a question or task arises, the index is used to find pertinent information, which is then fed to the LLM to generate answers.",single_hop_specific_query_synthesizer
How does the use of JSON RPC in the MCP architecture facilitate client-server communication?,"['## [2914.80s] Architecture of MCP\nThe MCP architecture includes an MCP host, which can be any integration or agent that connects to data or tools. Clients connect to the MCP server using a JSON RPC protocol, simplifying the process of establishing connections.\n\nThe MCP server has a fixed specification, allowing for a single client definition that can communicate with the server without needing to rewrite the client for each new integration. This design streamlines the connection process to various data sources and APIs, enhancing the overall efficiency of LLM integrations.\n\n# [601.12s] Utilizing Single LLM Invocation\nIn the realm of generative models, there are instances where a single large language model (LLM) invocation is employed to address specific issues. This approach is often complemented by multiple techniques that involve several iterations of LLM calls to effectively overcome limitations.']","In the MCP architecture, clients connect to the MCP server using a JSON RPC protocol, which simplifies the process of establishing connections. This allows for a single client definition that can communicate with the server without needing to rewrite the client for each new integration.",single_hop_specific_query_synthesizer
How LLM use context for better results?,"['## [795.92s] Incorporating Contextual Information\nThe most critical aspect involves supplying the current text, which adds necessary context to the LLM. This includes information about existing libraries, as the LLM may not be aware of the latest updates due to frequent releases. By utilizing few-shot prompting, the amount of instruction can be minimized, allowing for a more streamlined interaction with the user’s queries.\n\n# [840.40s] Exploring Generative Integration Patterns\nThe discussion now shifts to generative integration patterns. In the early stages of generative AI, the primary focus was on integrating generative models into applications. This integration allowed for basic interactions, such as conversing with a chat-based assistant, without the need for external data. For instance, code generation could be performed without any additional context.']","The most critical aspect involves supplying the current text, which adds necessary context to the LLM. This includes information about existing libraries, as the LLM may not be aware of the latest updates due to frequent releases.",single_hop_specific_query_synthesizer
How are personalized suggestions generated for users in the mobile application?,"[""## [1072.00s] User Interaction and Suggestions\nWhen a user checks the sessions through the mobile application, a request is sent to the session integration, which retrieves the user ID. This ID is then used to access the agenda information and the user's profile, allowing the model to generate personalized suggestions.\n\n## [3713.68s] Common Examples of Guardrails\nTo better understand guardrails, it is helpful to explore common examples. One of the most widely used guardrails is content filtering. For instance, if a user attempts to generate harmful content, such as instructions on committing violence or self-harm, the content filtering guardrails will block such requests before they reach the user.\n\nAdditionally, classifier-based guardrails, such as Llama Guard, are employed to check for safety and policy violations. This tool is particularly effective against jailbreaking attempts, as it reviews prompts before they are sent to the LLM. If a prompt is identified as an attempt to jailbreak the model, it will not be processed.""]","When a user checks the sessions through the mobile application, a request is sent to the session integration, which retrieves the user ID. This ID is then used to access the agenda information and the user's profile, allowing the model to generate personalized suggestions.",single_hop_specific_query_synthesizer
"How is the integration of data into AI applications transforming the focus from training to integration, and what are the limitations organizations face in this process?","['# [1081.44s] Key Takeaways\nIn summary, the discussion has highlighted the importance of writing better prompts, which is becoming a new programming language for building AI applications. The real power lies in how data is integrated into generative applications, shifting the focus from training to integration.\n\n## [1118.56s] Addressing Limitations in Data Integration\nAs organizations consider integrating their data into prompts, questions arise regarding the feasibility of including all organizational data. While it is possible, there are technical limitations to consider. Models have a context size they can handle, with early models supporting around 4,000 tokens.']","The integration of data into AI applications is transforming the focus from training to integration by emphasizing the importance of writing better prompts, which is becoming a new programming language for building AI applications. However, organizations face limitations in this process, such as the feasibility of including all organizational data due to technical constraints. Models have a context size they can handle, with early models supporting around 4,000 tokens.",single_hop_specific_query_synthesizer
How does converting HTML content to Markdown benefit LLMs?,"['## [1664.32s] The Injection Pipeline\nThe injection pipeline connects to the data sources, fetching information in various formats, such as HTML or PDF. The first step involves parsing and cleaning the data, as it often comes in unstructured forms. For instance, HTML content is typically converted to Markdown, which provides a cleaner structure that is more suitable for LLMs. This conversion helps eliminate unnecessary HTML tags that could waste tokens and introduce noise into the model.\n\n## [1730.16s] Chunking and Indexing Data\nAfter converting the data to Markdown, the next step is chunking the content. This process is essential to ensure that only relevant information is indexed into the vector database, aligning with the RAG principle of minimizing the amount of data fed into the LLM. Each chunk should focus on a specific topic, and various chunking approaches are available across different frameworks.\n\nOnce the data is chunked, an embedding model is used to generate vector embeddings for these chunks. These embeddings are then stored in the vector database, which handles the indexing and mapping of the document chunks, facilitating efficient retrieval and response generation.']","Converting HTML content to Markdown benefits LLMs by providing a cleaner structure that eliminates unnecessary HTML tags, which could waste tokens and introduce noise into the model.",single_hop_specific_query_synthesizer
What AI agents do in healthcare?,"['## [1841.68s] Searching for Relevant Information\nThe vector database performs the search operation using the provided vector, returning a selection of relevant document chunks. These chunks can then be utilized in the prompt to generate a response.\n\n# [1861.20s] Mastery of Generative AI\nAs we delve deeper into retrieval-augmented generation (RAG), it is crucial to understand its applications in generative AI. This technology enables the creation of content, answering questions, and analyzing data, all of which can significantly enhance organizational operations.\n\n# [1961.04s] Understanding AI Agents\nAI agents are systems that utilize generative AI models to autonomously make decisions and perform tasks. These tasks, often referred to as tools, can include functions such as API calls, database interactions, or even controlling physical devices.']","AI agents are systems that utilize generative AI models to autonomously make decisions and perform tasks, which can include functions such as API calls, database interactions, or even controlling physical devices.",single_hop_specific_query_synthesizer
How do AI agents utilize databases in their operations?,"['## [2030.64s] The Functionality of AI Agents\nTo understand how AI agents operate, it is essential to recognize their components. An agent receives tasks from humans, has access to various tools (such as web services, APIs, and databases), and is connected to a large language model (LLM) for reasoning. Additionally, agents possess both short-term and long-term memory capabilities.\n\n### [2109.76s] Traits of AI Agents\nAI agents exhibit traits that enable them to reason, plan, act, learn, and adapt to their environment. They can also delegate tasks to other agents when necessary, leading to a multi-agent system, a concept that will be discussed in further detail in future sessions.']","AI agents have access to various tools, including databases, which they use as part of their operations to receive tasks from humans and connect with a large language model for reasoning.",single_hop_specific_query_synthesizer
What AI agent do in hotel industry?,"['# [2147.60s] Example: AI Agent in the Hotel Industry\nTo illustrate the functionality of AI agents, consider an application designed for the hotel industry. This application assists customers in planning trips and reserving hotels, functioning similarly to an AI assistant for booking platforms.\n\n**Time Range: 00:40:01 - 00:50:04**\n\n## [2210.80s] Tools Available to the AI Agent\nIn this scenario, the AI agent has access to various tools, including hotel APIs for searching and booking hotels, a weather API for forecasts, a user profile API for personalization, and a location API for fetching nearby attractions.']","In the hotel industry, an AI agent assists customers in planning trips and reserving hotels, functioning similarly to an AI assistant for booking platforms.",single_hop_specific_query_synthesizer
How does the LLM assist in planning a vacation to Japan?,"[""### [2220.16s] User Query and Agent Response\nWhen a user requests assistance in planning a vacation to Japan in August, the agent utilizes the LLM to reason through the user's travel preferences. The agent examines the available tools and determines the best course of action based on the user's request.\n\n### [2331.60s] Utilizing User Preferences\nAfter executing the user profile tool, the agent retrieves information about the user's preferences, such as a liking for warm weather and beach activities. This data is then sent back to the LLM to inform the next steps in the planning process.\n\n### [2350.08s] Finding Suitable Destinations\nThe agent will then search for destinations that align with the user's preferences, utilizing the location tool. By analyzing the input schema of the tool, the agent can enhance its search criteria, ensuring a more tailored experience for the user.""]",The LLM assists in planning a vacation to Japan by reasoning through the user's travel preferences and determining the best course of action based on the user's request.,single_hop_specific_query_synthesizer
How does the LLM help the agent in making decisions about locations?,"['# [2401.28s] Executing Location Retrieval\nTo begin the process, the agent is instructed to execute a command to retrieve locations. This information is essential for the next steps in the execution. The agent, having gathered the necessary data, will utilize an API to obtain a set of locations that it can recommend to the user.\n\n## [2419.76s] Decision-Making Process of the Agent\nOnce the agent has the set of locations, it will analyze the information and consult the language model (LLM) to determine the next course of action. The LLM will suggest checking the weather conditions in these locations, as adverse weather could affect the recommendations. The agent will then use a weather API, inputting the locations as parameters, to retrieve the current weather conditions.\n\nAfter receiving the weather data, the agent will iterate on this information and send it back to the LLM. With sufficient data at hand, the agent can confidently make a decision and recommend the best locations for the user, concluding the task.']","The LLM helps the agent by analyzing the information about the set of locations and suggesting that the agent check the weather conditions in these locations. This ensures that adverse weather does not affect the recommendations. After the agent retrieves the weather data, it sends this information back to the LLM, which aids in making a confident decision about recommending the best locations for the user.",single_hop_specific_query_synthesizer
What role does the WSU IP pass play in developing integrations?,"['## [2741.04s] Technologies for Building Integrations\nTo develop and deploy general integrations, we can utilize the WSU IP pass, which supports the integration and deployment of various workflows, including agents and RAG. Developers can use their preferred programming languages and frameworks, such as Python, Semantic Kernel, or LangChain, to build and deploy these integrations.\n\n# [2786.08s] Standardizing Integration Processes\nNext, we will discuss how to standardize the integration of LLMs with external data and APIs. The Model Context Protocol (MCP) serves as a framework for this standardization, allowing for seamless connections between tools, resources, and prompts.']","The WSU IP pass supports the integration and deployment of various workflows, including agents and RAG, allowing developers to use their preferred programming languages and frameworks to build and deploy these integrations.",single_hop_specific_query_synthesizer
Waht is MCP in AI?,"[""## [2846.24s] Overview of the Model Context Protocol\nThe MCP provides a universal port for agents and general integrations, facilitating the connection of data and APIs with minimal effort. It standardizes how tools, resources, and prompts interact, ensuring consistency across various applications.\n\n### [2859.44s] Components of MCP\nTools refer to API calls and database queries, while resources encompass data files and contextual information. Prompts are templates that guide the LLM's responses, allowing for reuse across different applications.\n\n**Time Range: 00:50:02 - 01:00:02**\n\n# [3002.40s] Importance of Reusable Code in Client Connections\nWhen multiple hosts attempt to connect to the same data source, it becomes crucial to avoid redundant coding practices. Writing the same code repeatedly for each client can be tedious and inefficient. While some instances may involve simple code, others can require more complex and lengthy implementations. Additionally, ensuring best practices in the code is essential for production readiness. \n\nTo streamline this process, one can create a Managed Code Platform (MCP) server, allowing all clients and hosts to reuse the same logic. This approach is akin to the use of APIs, where reusable segments of code are created and integrated into a monolithic architecture. APIs are deployed and created only once, which simplifies the integration process.""]","The MCP, or Model Context Protocol, provides a universal port for agents and general integrations, facilitating the connection of data and APIs with minimal effort. It standardizes how tools, resources, and prompts interact, ensuring consistency across various applications.",single_hop_specific_query_synthesizer
How does Cursor Cloud facilitate operations with MCP servers?,"['## [3081.60s] Fixed Specifications of MCP\nUnlike APIs, which can have flexible specifications, MCP has a fixed specification that defines the available endpoints. These endpoints include functionalities such as listing available resources or executing specific tools by name. This structured approach ensures consistency and reliability in interactions with the MCP server.\n\n## [3122.08s] Integration of APIs with MCP\nThere is a growing trend to connect APIs directly to MCP hosts. This integration allows agents to utilize API resources as tools, enhancing their functionality. For instance, platforms like Cursor Cloud enable users to register an MCP server and perform various operations using natural language. This trend highlights the importance of understanding how MCP works in conjunction with APIs.']",Cursor Cloud enables users to register an MCP server and perform various operations using natural language.,single_hop_specific_query_synthesizer
How do APIs interact with agents in MCP architecture?,"['### [3190.24s] Visualizing MCP Functionality\nTo illustrate how MCP operates, consider a diagram featuring two agents, each equipped with a set of tools. These agents connect to APIs, necessitating the writing of specific code for each agent to handle API connections, input formatting, and output processing. This complexity can be mitigated by utilizing MCP servers, which centralize the logic and reduce redundancy in coding.\n\n## [3293.44s] Complexity of Architecture with MCP\nAs the architecture evolves, the introduction of MCPs adds complexity between data APIs and agent integration. For effective MCP server management, technologies such as Bijira and Coro can be employed. These tools facilitate the deployment of MCP servers both locally and remotely, ensuring flexibility in server management.']","In MCP architecture, agents connect to APIs, requiring specific code to handle API connections, input formatting, and output processing. MCP servers help centralize the logic and reduce redundancy in coding.",single_hop_specific_query_synthesizer
What are some potential risks associated with AI technologies in healthcare?,"['# [3353.84s] Addressing Risks Associated with AI\nThe discussion shifts to the potential risks associated with AI technologies. While there are no immediate world-ending scenarios, there are personal and organizational risks that must be acknowledged. These risks can manifest in various forms, including financial and legal implications.\n\n## [3404.64s] Understanding AI Hallucinations and Bias\nAI models are trained on datasets that may contain biases or gaps, leading to problematic outputs. For example, an AI might generate images predominantly featuring one demographic due to the lack of diversity in its training data. This issue highlights the importance of addressing data quality and representation in AI training.']","The potential risks associated with AI technologies include personal and organizational risks, which can manifest in various forms such as financial and legal implications.",single_hop_specific_query_synthesizer
What are the security concerns associated with integrating AI with databases?,"['### [3522.16s] Security Concerns in AI Implementations\nDevelopers must exercise caution to prevent sensitive data leaks when integrating AI with databases. If proper validations are not in place, an AI could inadvertently disclose confidential information. For instance, if an agent is connected directly to a database, it could allow unauthorized access to user sessions, posing a significant risk.\n\n## [3564.56s] Threats from Malicious Actors\nThe landscape of AI integration is also threatened by malicious actors attempting to exploit vulnerabilities. Attackers may use prompting techniques to manipulate AI systems, necessitating robust security measures to prevent unauthorized access and ensure the integrity of AI outputs.\n\nIn conclusion, as developers and organizations, it is imperative to take these risks seriously and implement appropriate safeguards to protect against potential threats associated with AI technologies.']","Developers must exercise caution to prevent sensitive data leaks when integrating AI with databases. If proper validations are not in place, an AI could inadvertently disclose confidential information, such as allowing unauthorized access to user sessions, posing a significant risk.",single_hop_specific_query_synthesizer
Waht is LLM?,"['**Time Range: 01:00:01 - 01:10:03**\n\n# [3601.20s] Ensuring Responsible AI Development\nThe development of artificial intelligence (AI) applications must be approached with a sense of responsibility. This involves adhering to emerging regulations and policies that aim to ensure the safety and ethical behavior of AI systems. To avoid potential issues, one effective strategy is the implementation of guardrails.\n\n## [3606.80s] The Role of Guardrails in AI\nGuardrails serve as constraints that ensure AI behaves safely and ethically, as intended. For instance, when a prompt is submitted to a large language model (LLM), it should not be sent directly. Instead, it must first pass through a series of guardrails that check for potential issues such as personal information (PI) detection, proprietary information, or attempts to manipulate the model (jailbreaking). Only when these guardrails are satisfied will the prompt be forwarded to the LLM.\n\nOnce the output is generated, additional guardrails are necessary to address potential issues such as censorship, hallucinations, or discussions of sensitive topics. For example, certain topics, like the ongoing conflict in Israel and Palestine, may require censorship within specific organizational contexts. Thus, guardrails must be applied to both the input sent to the LLM and the output received from it.']","LLM refers to a large language model, which is an AI system that processes prompts and generates outputs. Guardrails are used to ensure that both the input to the LLM and the output from it are safe and ethical.",single_hop_specific_query_synthesizer
How can access control and monitoring enhance the security of AI models?,"['# [3926.56s] Beyond Guardrails: Access Control and Monitoring\nIn addition to guardrails, organizations must consider access control measures. This involves managing who can access AI models, ensuring that not everyone has unrestricted access. Rate limiting and budget constraints are also essential to prevent misuse, such as denial-of-service (DoS) attacks that could exhaust resources and hinder service for other users.\n\nMonitoring is another critical aspect, as it allows organizations to track what is sent to the LLM and what is generated in response. Maintaining a record of interactions is vital for accountability and troubleshooting in case of issues.']","Access control measures enhance the security of AI models by managing who can access them, ensuring that not everyone has unrestricted access. Monitoring allows organizations to track interactions with the AI models, maintaining a record for accountability and troubleshooting.",single_hop_specific_query_synthesizer
What AI gateways do?,"['## [4032.08s] Centralized Governance through AI Gateways\nThe implementation of guardrails and governance can be challenging if done at the application level for each individual model. A more scalable solution is to establish an AI gateway that centralizes control and enforcement of policies across all applications. This approach simplifies management and auditing, ensuring consistent enforcement of guidelines, such as prohibiting the submission of personal information to LLMs.\n\nThe AI gateway acts as a gatekeeper, monitoring and governing all incoming and outgoing traffic to and from the LLMs. This centralized system enhances security and efficiency, allowing organizations to manage their AI applications more effectively.']","AI gateways centralize control and enforcement of policies across all applications, acting as a gatekeeper to monitor and govern all incoming and outgoing traffic to and from the LLMs. This enhances security and efficiency, simplifying management and auditing.",single_hop_specific_query_synthesizer
"Wht is the imprtance of zero-trust design in AI systms, and how does it apply to AI agents?","['# [4171.52s] Trusting AI Agents\nAs organizations grant AI agents greater autonomy, questions arise regarding the level of trust that can be placed in these systems. While agents are designed to perform specific actions and utilize various tools independently, it is crucial to recognize that complete trust may not be warranted. This highlights the importance of implementing a zero-trust design for AI agents, ensuring that safeguards are in place to monitor and control their actions effectively.\n\n**Time Range: 01:10:00 - 01:14:46**\n\n# [4200.32s] Understanding Zero Trust in AI Systems\nZero trust is a security model that emphasizes the principle of never trusting and always verifying. This approach is applied to system architectures, ensuring that trust is not assumed but rather verified at every step. When designing systems, it is crucial to maintain this principle, especially when dealing with AI agents.']","The importance of zero-trust design in AI systems lies in its emphasis on the principle of never trusting and always verifying. This security model ensures that trust is not assumed but rather verified at every step, which is crucial when dealing with AI agents. Implementing a zero-trust design for AI agents ensures that safeguards are in place to monitor and control their actions effectively, especially as organizations grant these agents greater autonomy.",single_hop_specific_query_synthesizer
What role does RAG play in enhancing AI capabilities?,"['## [4375.04s] Final Architecture and Security Measures\nThe final architecture incorporates mechanisms to secure agent operations and establish a zero trust framework. Technologies like Asgardio and identity servers play a crucial role in managing agent identities and ensuring proper authorization for actions taken by AI tools.\n\n## [4408.08s] Conclusion and Key Takeaways\nIn conclusion, the discussion highlighted the accessibility of AI systems, such as Jenna, while acknowledging their limitations, including issues like hallucination due to outdated knowledge and lack of access to private data. The integration of generative models with retrieval-augmented generation (RAG) enhances capabilities by allowing efficient knowledge injection and enabling agents to execute actual tools.\n\nFurthermore, standardizing connections to external systems, such as APIs and databases, is essential for effective integration. Finally, it is imperative to implement responsible AI practices, including the use of AI gateways and zero trust designs, when developing AI agents.']",The integration of generative models with retrieval-augmented generation (RAG) enhances capabilities by allowing efficient knowledge injection and enabling agents to execute actual tools.,single_hop_specific_query_synthesizer
Wat is the role of a W integrator in AI transformation?,"['## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.']","Anjen will introduce a W integrator to facilitate the AI transformation process, as implementing these concepts in real life requires the right toolkit for development. The W integrator is used to demonstrate how to achieve this transformation.",single_hop_specific_query_synthesizer
What generative AI do?,"['## [77.52s] Understanding AI Transformation\nAI transformation is a term that, while not universally adopted, is gaining traction in discussions about enhancing business operations. The fundamental idea is to leverage AI to improve various aspects of an organization, leading to increased productivity, efficiency, and user experience. Additionally, AI can unlock new capabilities that were previously unattainable.\n\nAI has emerged as a powerful tool, particularly with the advent of generative AI. This technology allows us to create solutions that were once complex and resource-intensive, such as chatbots. Previously, developing a chatbot required extensive rule-based or knowledge-based systems. Now, it is as simple as writing a prompt and connecting to a large language model (LLM) with minimal financial investment.\n\nThe current landscape presents numerous opportunities, and businesses must adapt to these new capabilities to remain competitive. Failing to embrace AI transformation could result in falling behind in a rapidly evolving market, where many organizations are striving to enhance their operations through AI.']","Generative AI allows us to create solutions that were once complex and resource-intensive, such as chatbots, by simply writing a prompt and connecting to a large language model with minimal financial investment.",single_hop_specific_query_synthesizer
How does the proposed system architecture facilitate dynamic interactions and personalization in AI agents for medical applications?,"['## [1040.08s] The Role of AI Agents\nAI agents are essential for dynamic interactions, connecting to business APIs, and leveraging personalization. They can remember user preferences and provide a more tailored experience, which is not possible with generative integrations alone.\n\n# [1072.32s] System Architecture Overview\nThe proposed architecture includes core business APIs, such as search and booking APIs, and a trip planning agent that connects to user personalization data. This setup aims to streamline the process of answering hotel-specific questions without delays caused by waiting for human representatives.']","The proposed system architecture includes core business APIs, such as search and booking APIs, and a trip planning agent that connects to user personalization data. This setup aims to streamline the process of answering hotel-specific questions without delays caused by waiting for human representatives, thereby facilitating dynamic interactions and personalization.",single_hop_specific_query_synthesizer
What is WSO2's role in vertical solutions?,"[""## [1492.00s] Final Architecture Overview\nThe final architecture includes two new components: one for collecting and indexing information from hotel owners and another for querying the database to find answers. The AI agent will ask questions from the RAG, which will not only fetch data but also provide natural language responses back to the agent.\n\n# [1560.96s] Transition to Implementation\nAt this point, Anja will take over to discuss how to build this system using the W2 Integrator.\n\n### [139.44s] Historical Context\nThe concept of verticalization is not new. Even the largest horizontal tech companies have historically tailored their sales organizations and product features to cater to specific customer needs within particular domains. For instance, WSO2's solutions team exemplifies this approach by offering vertical solutions built on top of their core products, such as integration, identity and access management, and API management. This enables them to communicate effectively with customers and provide precise solutions in areas like open healthcare and open banking.""]","WSO2's solutions team exemplifies the approach of verticalization by offering vertical solutions built on top of their core products, such as integration, identity and access management, and API management. This enables them to communicate effectively with customers and provide precise solutions in areas like open healthcare and open banking.",single_hop_specific_query_synthesizer
What are the AI capabilities of the WSO2 W2 Integrator and how can they be effectively implemented in integration tasks?,"['## [1611.68s] Introduction to W2 Integrator\nThe W2 Integrator BI is a next-generation integration product recently introduced by WSO2. The focus will be on the AI capabilities of the tool and how to implement the use case effectively.\n\n### [1658.48s] Key Features of W2 Integrator\nOne of the key features of this product is its support for a seamless transition from low code to pro code, ensuring that all code written is reflected in the diagram without losing any information.\n\n### [1694.40s] AI Integration Capabilities\nThis product is designed in the age of AI, allowing for the development of integrations using natural language processing. It also supports building AI applications for enterprise use cases, making it a versatile tool for modern integration challenges.']","The W2 Integrator by WSO2 is designed with AI capabilities that allow for the development of integrations using natural language processing. It supports building AI applications for enterprise use cases, making it a versatile tool for modern integration challenges.",single_hop_specific_query_synthesizer
How does WC2 Integrator BI facilitate the development of AI applications in the healthcare sector?,"['## [1741.76s] Recap of Historical Context\nHistorically, adding AI features to products required extensive resources, including hiring data science engineers and building models from scratch. However, the current landscape has made AI more accessible, with capable reasoning models available through cloud providers, transforming the integration process into a more manageable task.\n\n**Time Range: 00:30:01 - 00:40:06**\n\n# [1801.52s] Introduction to AI Integration Development\nIn the past, the development of AI integrations was typically the responsibility of a separate team. However, current practices allow integration developers to utilize existing resources to create remarkable AI experiences for products. The focus of WC2 Integrator BI is to provide first-class abstractions and developer tooling specifically designed for building AI applications.']","WC2 Integrator BI focuses on providing first-class abstractions and developer tooling specifically designed for building AI applications, making the integration process more manageable and accessible.",single_hop_specific_query_synthesizer
What is Hello Agent and how it fit in AI integration?,"['## [1816.72s] Focus on AI Integration\nThe primary focus today will be on the AI aspects of the integration product, rather than the integration components themselves. At its core, this product specializes in AI, enabling developers to create innovative applications.\n\n## [1855.92s] Building a Hello Agent Application\nTo begin the programming exercise, the first step is to create a ""Hello Agent"" application. The process starts with an empty project, where the developer will add an artifact. This integration tool allows for the creation of various automations, HTTP services, file integrations, and event integrations. However, the focus here is on the AI agent component.']","The Hello Agent is an application that is part of the programming exercise focused on AI integration. It starts with an empty project where a developer adds an artifact, emphasizing the AI agent component.",single_hop_specific_query_synthesizer
Cud yu explane how WS2 is used in the context of creating an agent?,"['### [1891.84s] Creating the Agent\nThe developer will name the agent ""Creating Agent."" Once the agent is created, a diagram representing the agent will be displayed. Although the initial view may appear blank, it is possible to assign roles and provide specific instructions for the agent\'s functionality. The default model provider from WS2 is available, which serves as an open AI proxy to facilitate the development process.\n\n## [2205.04s] Integration Development Process\nBefore diving into the development, it is essential to understand the existing applications, including hotel APIs, admin APIs, and external APIs. The platform called Devant will be used for building, deploying, and managing integrations. The focus will be on the development aspect rather than existing applications.']","The default model provider from WS2 is available, which serves as an open AI proxy to facilitate the development process when creating an agent.",single_hop_specific_query_synthesizer
How copilot help with code generation for hotel APIs?,"['## [2700.40s] Addressing Latency Issues\nLatency has been identified as a challenge during code generation. To mitigate this issue, a streaming approach has been implemented, allowing users to see that the process is ongoing and not stalled. This method provides a concrete example of how latency can be managed effectively.\n\n## [2731.76s] Utilizing the Copilot for Code Generation\nThe copilot is designed to generate code for users, simplifying the process of connecting to the hotel search and admin APIs. Instead of manually writing the logic and data mapping, the copilot can handle these tasks efficiently. Once the code is generated, it is essential to review it before integrating it into the project.\n\nThe diagram reflecting the modified structure will show that the copilot has successfully fetched bookings and reviews without requiring manual coding.']","The copilot is designed to generate code for users, simplifying the process of connecting to the hotel search and admin APIs by handling the logic and data mapping efficiently.",single_hop_specific_query_synthesizer
How is a Large Language Model utilized for creating personalized profiles?,"['## [2816.00s] Calling the LLM for Personalized Profiles\nWith the data structure established, the next step involves calling the LLM (Large Language Model) using the gathered data. The objective is to create a personalized profile for the user. This process does not require an agent or retrieval-augmented generation; instead, it focuses on directly utilizing the LLM.\n\nTo facilitate this, a connection to the model provider has been created. A prompt will be generated for the LLM, specifying the need for a personalized profile. It is crucial to be precise in the prompt to ensure an accurate response. A comprehensive prompt has been prepared and will be used to guide the LLM in generating the desired output.']","The Large Language Model is utilized for creating personalized profiles by directly using the gathered data to generate a precise prompt, which guides the LLM in producing the desired output without the need for an agent or retrieval-augmented generation.",single_hop_specific_query_synthesizer
How is PostgreSQL utilized in the integration process for storing LLM responses?,"['## [2959.68s] Storing the LLM Response in a Database\nOnce the LLM response is generated, the next step is to store this information in a database. A database has already been set up and configured to work with the integration tool. The connection to the database will be established, allowing for the storage of the generated data. The necessary configurations, including the PostgreSQL host and username, have been prepared in advance to streamline this process.\n\n**Time Range: 00:50:01 - 01:00:02**\n\n**Time Range: 01:20:00 - 01:24:42**\n\n# [3001.68s] Integration Process Overview\nThe integration process appears to be nearing completion. Initially, there was a connection added, but it was necessary to edit the setup further. An insert query was required, and the variable name copied was incorrect. The focus shifted to pointing to the LLM response, which is intended to be inserted into the database.']","PostgreSQL is used in the integration process by setting up and configuring the database to store the LLM responses. The necessary configurations, including the PostgreSQL host and username, have been prepared to facilitate this storage process.",single_hop_specific_query_synthesizer
How does the process of database verification and token generation contribute to the effective execution of queries in the context of LLMs?,"['## [3042.48s] Database Verification\nBefore executing the query, it was essential to check the database to ensure it was clean. The SQL server database was examined, specifically the user activity table, which showed no entries. The next step involved generating the tokens required for the LLM and executing the query.\n\n### [3110.16s] Execution and Response\nAfter a brief wait, the execution began, and the API response was received after aggregation. The aggregated response was reviewed before sending it to the LLM, and it seemed to execute without any issues. The automation process was efficient, allowing for a quick refresh of the database.']","The process begins with database verification to ensure the database is clean, specifically checking the user activity table for no entries. This step is crucial before generating the tokens required for the LLM. After token generation, the query execution proceeds, and the API response is received after aggregation. The aggregated response is reviewed before being sent to the LLM, ensuring the process executes without issues. This efficient automation allows for a quick refresh of the database, contributing to the effective execution of queries.",single_hop_specific_query_synthesizer
What is Anthorpic in AI?,"['## [3340.72s] Custom Integration Development\nFor more customized solutions, such as triggering events from an FTP server, coding may be necessary. Although a new integration was not built during this session, a pre-existing integration was demonstrated to save time.\n\n## [474.56s] Trade-offs in AI Development\nThe conversation continues with a focus on the trade-offs involved in AI development. The moderator points out that teams often face decisions between optimizing for accuracy, latency, and cost. Alan Shmal responds by highlighting the three key metrics that matter: speed, quality, and cost. He explains that early in AI projects, engineers tend to prioritize accuracy to avoid user complaints about poor performance. However, this can lead to the use of expensive models that may not be efficient in terms of latency and cost.\n\nAlan shares his experience with high-quality models, such as those from Anthropic, which provide excellent reasoning but come with high operational costs. He notes the importance of balancing the need for speed in conversational assistants with the efficiency of the models used, ultimately leading to a focus on reducing latency while maintaining quality.']",Anthropic is mentioned as a provider of high-quality models that offer excellent reasoning but come with high operational costs.,single_hop_specific_query_synthesizer
"How does vertikal AI impact the finance industry, considering its regulatory alignment?","['## [195.60s] Advantages of Vertical AI\nVertical AI offers several advantages, including:\n\n1. **Domain Expertise**: Vertical AI can deliver precision and relevance in critical applications.\n2. **Regulatory Alignment**: Industries such as healthcare, finance, and legal are highly regulated, necessitating strict adherence to data sharing and communication protocols.\n3. **Business Impact**: Vertical AI can drive automation and insights tailored to specific verticals, which generic solutions may not address.\n4. **Competitive Advantage**: Specialized tools designed for specific requirements provide a competitive edge.']","Vertical AI impacts the finance industry by ensuring strict adherence to data sharing and communication protocols, which is crucial due to the highly regulated nature of the industry.",single_hop_specific_query_synthesizer
How much can API usage cost per month for small language models?,"['**Time Range: 01:10:01 - 01:20:03**\n\n# [990.00s] Insights on Small Language Models\nWe have been working with small language models for nearly a year, primarily focusing on translation tasks. Initially, we started with a very small model designed for machine translation, covering around 100 languages and operating on CPU, which was cost-effective. However, as we have scaled up and increased the number of parameters, the computational requirements have also risen. \n\nWhile using API keys may seem inexpensive initially, extensive usage can lead to significant costs, sometimes reaching $15,000 to $20,000 per month. This highlights the difference between a pay-as-you-go model and having an in-house solution, where a single server costing around $5,000 can meet all operational needs. However, this shift also introduces challenges, such as managing toxicity and hallucination in outputs, necessitating the implementation of additional safeguards that may cause delays.\n\nDespite these challenges, if generative AI can effectively complete tasks, the trade-off may be worthwhile. Users may express concerns about processing times, but when comparing a task that previously took three days to one that now takes three minutes, the benefits become clear.']","Extensive usage of API keys for small language models can lead to significant costs, sometimes reaching $15,000 to $20,000 per month.",single_hop_specific_query_synthesizer
What MCP server do?,"['## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.']","An MCP server provides weather information, allowing it to be incorporated into the planning process.",single_hop_specific_query_synthesizer
Where can one access the code and resources for the itinerary generation project?,"['### [4712.40s] Testing the Itinerary Generation Flow\nAlthough the current setup does not support booking capabilities, it should be able to generate an itinerary based on the available tools. We will test this flow, keeping in mind that integrating the booking API would follow a similar process of adding it as a connection and tool.\n\n## [4755.20s] Accessing Code and Resources\nThe code for this project is available on GitHub, and a link will be shared for those interested in trying out these functionalities independently.\n\n## [4780.24s] Transitioning from Low Code to Pro Code\nIt is important to note that we support a seamless transition from low code to pro code. However, I neglected to configure the MCP server, which only supports HTTP/1. This oversight needs to be addressed to ensure proper functionality.']","The code for this project is available on GitHub, and a link will be shared for those interested in trying out these functionalities independently.",single_hop_specific_query_synthesizer
What happen when system try plan trip to Sri Lanka?,"['# [4800.24s] Overview of MCP Server Configuration\nBy default, the configuration is set to two, but this particular MCP server only supports HTTP/1. This is something I confirmed through testing. You can edit the settings in local code or in pro code mode; either method works. Regardless of the approach taken, the diagram and the code remain in sync.\n\n## [4823.12s] Executing a Query\nThe system is currently running, and I should access the chat window. Here it is. We will proceed with our usual query: ""Plan me a trip for 5 days in Sri Lanka."" The system is taking some time to process the request. We will wait for the response, and then I will walk through the verbose logs.']","The system is currently running and processing the request to plan a trip for 5 days in Sri Lanka. It is taking some time to process the request, and the response is awaited.",single_hop_specific_query_synthesizer
What concerns did Nadish raise during the session regarding the implementation of AI features?,"[""## [4940.64s] Conclusion of the Session\nAs we wrap up, I want to highlight that we discussed many aspects today. To summarize, we implemented a practical use case for a hypothetical organization, adding value through AI features. This was accomplished within approximately 30 to 40 minutes using the integrated BI platform, along with assistance from the editors and databases.\n\nThere are a few key points to note. As Nadish mentioned earlier, some elements are still missing. For instance, we did not obtain user authorization before making a booking, which is something we need to address in the next session. Additionally, we must be cautious about granting the agent excessive power, as we are currently connecting to admin APIs. This is where agent identification and governance become crucial. We need to monitor the agent's actions and, if something goes wrong, analyze how it occurred and calculate the associated costs.\n\nAfter lunch, there will be a session led by Aisha that will cover these governance aspects. If you are interested, I encourage you to attend.""]","Nadish mentioned that some elements are still missing, such as not obtaining user authorization before making a booking, and highlighted the need to be cautious about granting the agent excessive power when connecting to admin APIs.",single_hop_specific_query_synthesizer
Who Malit Jing and what he do?,"[""**Time Range: 00:00:03 - 00:10:03**\n\n## [1324.32s] Change Management as a Key Challenge\nA significant challenge in the adoption of AI technologies is change management. The rapid pace of technological advancement often outstrips organizations' ability to adapt. It is essential to consider the human aspect, including the processes and people affected by AI implementation. Organizations must focus on managing this change effectively, whether by integrating new technologies into existing structures or creating new organizational frameworks to accommodate them.\n\n# [3.44s] Introduction\nMalit Jing serves as both the track lead and a speaker at this event. He introduces himself as the Vice President of Research and AI at WSO2, where he has been employed for nearly ten years. His expertise lies in distributed systems and artificial intelligence (AI). In the early part of his career, he focused on distributed systems but has since transitioned to AI, working closely with product teams to define WSO2's AI strategy.""]","Malit Jing is the Vice President of Research and AI at WSO2, where he has been employed for nearly ten years. His expertise lies in distributed systems and artificial intelligence (AI).",single_hop_specific_query_synthesizer
"Could you elaborate on the concept of 'AI for Code' as part of WSO2's AI strategy, particularly in terms of its impact on the developer experience and the integration of capabilities and features into their products?","['## [44.88s] WSO2\'s AI Strategy\nWSO2\'s AI strategy consists of two main components. The first is termed ""AI for Code,"" which focuses on enhancing the developer experience by integrating capabilities and features into their products. The second component, ""Code for AI,"" is centered around building AI applications and identifying the necessary abstractions for their development.\n\n# [85.12s] Evolution of AI Agents\nToday, Malit will discuss the evolution of AI agents. He emphasizes that this presentation will summarize key innovations driving the current adaptation of AI, referencing an article published by McKinsey.']",The concept of 'AI for Code' within WSO2's AI strategy focuses on enhancing the developer experience by integrating capabilities and features into their products.,single_hop_specific_query_synthesizer
What AI do now with poor grammar?,"['## [136.08s] Key Innovations in AI\nThe first key innovation is the increasing power of AI models, which are becoming more expert-like. For instance, models like GPT-4 have demonstrated the ability to achieve high scores on tests such as the SAT and the US medical exam. Additionally, reasoning capabilities are improving, as evidenced by advancements in prompting techniques that are no longer necessary for these advanced models.\n\nThe second innovation pertains to agentic capabilities, where agents can reason, act, and perform tasks autonomously. The third area of improvement is multi-modality, which extends beyond text to include advancements in video and voice interactions, making them more natural and real-time.']","AI models are becoming more expert-like, achieving high scores on tests such as the SAT and the US medical exam, and improving in reasoning capabilities. They also have agentic capabilities, allowing them to reason, act, and perform tasks autonomously. Additionally, there are advancements in multi-modality, extending beyond text to include video and voice interactions, making them more natural and real-time.",single_hop_specific_query_synthesizer
What AI do?,"['**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.']","AI advancements face challenges in scalability, but improvements in speed are enabling real-time interactions both in the cloud and at the edge. Additionally, transparency and explainability are ongoing challenges, with progress shown by the introduction of a transparency score for model training processes.",single_hop_specific_query_synthesizer
What WSO2 do with AI patterns?,"['# [339.20s] Building Modern AI Applications\nBuilding modern AI applications involves connecting various components. The process begins with developing AI components, which is itself an integration challenge. Traditional machine learning approaches are becoming less relevant, with integration taking precedence. The success of this integration process relies on utilizing the appropriate patterns.\n\n## [408.88s] Core Patterns in AI Strategy\nWSO2 has identified three core patterns in their AI strategy, which have been extensively covered in previous sessions. The first pattern is GenAI integration, which involves making calls to a GenAI API. This pattern supports various use cases, including text summarization, sentiment analysis, and email drafting.\n\nThe second pattern is Retrieval-Augmented Generation (RAG), where data is stored in a knowledge base and retrieved as needed to ground responses. However, both RAG and GenAI integrations are primarily passive or reactive, lacking the ability to perform actions independently.']","WSO2 has identified three core patterns in their AI strategy. The first pattern is GenAI integration, which involves making calls to a GenAI API for use cases like text summarization, sentiment analysis, and email drafting. The second pattern is Retrieval-Augmented Generation (RAG), where data is stored in a knowledge base and retrieved as needed to ground responses.",single_hop_specific_query_synthesizer
What enhancements were made to the WSO2 mobile app for the conference?,"['## [503.36s] Defining an Agent\nAgents introduce proactivity, allowing them to perform actions autonomously. An agent is defined as a system or entity capable of executing tasks by interacting with tools, such as APIs and databases, with the assistance of a large language model.\n\n# [556.40s] WSO2 Mobile App Development\nMalit discusses a WSO2 mobile app developed for the last WSO2 conference. Initially, the app was static and lacked AI features. To enhance user experience, the team added various features, including personalized scheduling and a chatbot for user interaction.\n\n**Time Range: 00:10:00 - 00:20:08**']","To enhance user experience, the team added various features to the WSO2 mobile app, including personalized scheduling and a chatbot for user interaction.",single_hop_specific_query_synthesizer
How has AI changed the aplication architechture?,"['# [600.64s] Application Update and Architecture Overview\nThe discussion begins with an update on the application. A review of the architecture, both before and after the update, is presented. Initially, the architecture consisted of two primary flows: the registration flow, where users would visit a website to register and input their details into a database, and the data retrieval flow, which allowed users to access their session data from the database. \n\nWith the integration of AI capabilities, the architecture has become significantly more complex. Various agents, retrieval-augmented generation (RAG) integrations, and other components have been added to enhance functionality.']","With the integration of AI capabilities, the architecture has become significantly more complex, incorporating various agents, retrieval-augmented generation (RAG) integrations, and other components to enhance functionality.",single_hop_specific_query_synthesizer
What is the role of the Surfer API in the personalization agent?,"[""## [651.84s] Personalization Agent\nA key component of the updated architecture is the personalization agent. This agent interacts with other components within the system. Upon receiving user consent, it utilizes the user's name and company information to conduct an internet search, thereby creating a personalized profile. The personalization agent employs two tools: the Surfer API, which retrieves a set of links relevant to the user, and the Scraper Web Scraper API, which scrapes content from those links. This process is iterative, continuing until the agent achieves its goal.\n\n## [720.96s] Introduction to MCP\nBefore delving into multi-agent systems, it is essential to briefly discuss the concept of the Multi-Component Protocol (MCP). The MCP standardizes how AI applications interact with external tools. The architecture of MCP includes concepts such as tools, resources, and prompts, which have been extensively discussed in AI labs.\n\nThe MCP introduces two new components to agent applications: the MCP client and the MCP server. The MCP client connects to the MCP host, allowing developers to access the MCP server without needing to write code for each individual tool connection. This simplifies the development process, enabling developers to focus on functionality rather than connectivity.""]","The Surfer API retrieves a set of links relevant to the user, which is used by the personalization agent to create a personalized profile.",single_hop_specific_query_synthesizer
Waht is the MCP servcie for Coro and how does it intgrate with Visual Studio Code?,"[""## [858.08s] MCP Service for Coro\nAn example of the MCP service is presented, specifically the MCP server for Coro, which is WSO2's internal developer platform. The service has been integrated into Visual Studio Code, facilitating the entire software development lifecycle. The process includes various checks, such as verifying user login to Coro, checking for project existence, and creating components as necessary. Ultimately, the service streamlines the deployment process to Coro.\n\n# [927.04s] Multi-Agent Systems\nThe discussion transitions to multi-agent systems. While single agents can function effectively, as systems grow in complexity, the need arises to connect agents to an increasing number of tools. This is particularly relevant in cases where accuracy issues may occur, necessitating the use of multiple specialized agents that can interact with one another to address larger problems.""]","The MCP service for Coro is WSO2's internal developer platform integrated into Visual Studio Code. It facilitates the entire software development lifecycle by verifying user login to Coro, checking for project existence, and creating components as necessary, ultimately streamlining the deployment process to Coro.",single_hop_specific_query_synthesizer
What functionalities does Coro Copilot provide to users?,"['# [1204.16s] Overview of Co-Pilot and Its Functionality\nThe discussion begins with an introduction to specific inputs and outputs related to a co-pilot system known as Coro Copilot. This system is currently undergoing a revamp, with a new version on the way. Coro Copilot allows users to interact with the Coro platform, providing access to various functionalities such as project documentation and service status inquiries.\n\n## [1242.24s] Architecture of Coro Copilot\nThe architecture of Coro Copilot follows a supervisor pattern. The initial interaction with the user is managed by a supervisor agent, which then delegates tasks to a set of domain-specific agents. These specialized agents include observability, marketplace, and testing agents, among others. The teams responsible for developing these features are best equipped to create the necessary prompts for their respective agents.']","Coro Copilot allows users to interact with the Coro platform, providing access to various functionalities such as project documentation and service status inquiries.",single_hop_specific_query_synthesizer
What role does Google play in the development of agent-to-agent communication protocols within the Coro ecosystem?,"['### [1300.00s] Functionality of Specialized Agents\nFor instance, the observability agent connects to numerous internal APIs to retrieve data. While it primarily focuses on data retrieval, other agents, such as those involved in deployment, can perform actions as well. This illustrates the diverse capabilities of the agents within the Coro ecosystem.\n\n# [1330.96s] Importance of Agent-to-Agent Communication\nAnother significant topic is the communication between agents. Standard protocols are emerging to facilitate agent-to-agent communication, similar to how the MCP standardizes communication between AI applications and tools. These protocols are still evolving, with several options available, including A2A by Google and ACP by IBM.']","Google is involved in the development of agent-to-agent communication protocols, specifically through the A2A protocol, which is one of the several options available to facilitate communication between agents within the Coro ecosystem.",single_hop_specific_query_synthesizer
What challenges does the A2A Protocol address in multi-agent systems?,"[""## [1391.20s] The Unpredictable Nature of AI Development\nThe unpredictable nature of AI development is highlighted, with the assertion that no one can be certain about future advancements. The analogy of electricity is used to illustrate how initial transformations often focus on replacing existing technologies rather than reimagining workflows. Companies that fail to rethink their processes in light of new capabilities may find themselves lagging behind.\n\n## [1410.48s] Challenges Addressed by A2A Protocol\nThe A2A protocol aims to address the challenges faced in multi-agent systems, where agents may not be aware of each other's capabilities or the data formats required for communication. A2A standardizes this communication, providing a transport protocol and features that allow agents to understand one another better.""]","The A2A protocol aims to address the challenges faced in multi-agent systems, where agents may not be aware of each other's capabilities or the data formats required for communication. A2A standardizes this communication, providing a transport protocol and features that allow agents to understand one another better.",single_hop_specific_query_synthesizer
What role does MCP play in standardizing AI applications?,"['### [1481.76s] Features of A2A Protocol\nA2A includes a standardized communication transport protocol, JSNRPC, and additional capabilities that enable agents to learn about each other through concepts like agent cards. These cards provide essential information such as names, descriptions, URLs, versions, skills, and IDs.\n\n# [1522.64s] Summary of Key Points\nAs the presentation nears its conclusion, a summary of the discussed topics is provided. The evolution of AI systems began with simple integrations, leading to the development of retrieval-augmented generation (RAG) for grounding answers with real data. The introduction of agents followed, with the MCP standardizing AI applications. The need for multi-agent communication has led to the emergence of various communication protocols, including A2A.']","MCP standardizes AI applications, facilitating the development and integration of AI systems.",single_hop_specific_query_synthesizer
How agents performance get tested with changes?,"['# [939.84s] Evaluating Model Performance\nAn important aspect of our work involves evaluating model performance, especially in light of changes that may affect functionality. This is a significant area of research within the field of agents and generative AI, as these systems are inherently probabilistic. When the same prompt is called multiple times, it can yield different responses, complicating the testing process. \n\nTo address this, we need to establish methodologies and benchmark datasets to ensure consistent performance, particularly given the rapid advancements in technology. As we transition to new models every six months, it is vital to confirm that we do not lose any previously effective functionalities.']","Evaluating model performance is crucial, especially with changes that may affect functionality. This involves establishing methodologies and benchmark datasets to ensure consistent performance, given the probabilistic nature of agents and generative AI systems.",single_hop_specific_query_synthesizer
What role does Rana Kalaf play at WSO2 in the context of AI development?,"[""### [1683.04s] Conclusion\nIn conclusion, the discussion highlights the ongoing work in fine-tuning SLMs to enhance agent performance and accuracy. The session wraps up with gratitude for the audience's attention and a transition to the next segment.\n\n**Time Range: 00:00:03 - 00:10:03**\n\n# [3.36s] Introduction to the Panel\nThe panel discussion begins with a warm welcome to the audience. The moderator introduces the panelists, highlighting their roles and affiliations. The panelists include Yad Ahmed, the CTO of Arabic AI; Rana Kalaf, the Chief AI Officer at WSO2; Alan Shmal, the Executive Vice President of Platform at Vistra; and Mahesh Saloria, the Head of Architecture at HSBC.""]",Rana Kalaf is the Chief AI Officer at WSO2.,single_hop_specific_query_synthesizer
What recent initiative has Canada HSBC Life Insurance undertaken?,"[""## [11.84s] Panelist Introductions\nYad Ahmed shares his background, stating that he has 24 years of experience in technology, with eight years focused on natural language processing (NLP) and AI. He explains that Arabic AI, which operates under the name Turjim, has been in business for 17 years, initially focusing on translation and content generation. In 2016, the company expanded into technology, developing automated systems for translation and content generation. Recently, they secured a Series A funding round of $50 million to further their work in AI, particularly in model fine-tuning and workflow automation.\n\nRana Kalaf introduces herself as the Chief AI Officer at WSO2. She emphasizes the company's focus on two main areas in their AI journey: accelerating user engagement with their products through embedded agents and co-pilots, and integrating AI into applications via connectors and an agent-building framework.\n\nAlan Shmal from Vistra describes the company as a corporate services provider that handles accounting, payroll, and legal entity management. He explains that their AI initiatives include a conversational agent built with Aentic AI frameworks, which serves three main functions: advisory, reporting on customer data, and executing workflows. He also mentions the use of asynchronous systems to process unstructured data, such as legal documents and voice notes.\n\nMahesh Saloria represents Canada HSBC Life Insurance, a joint venture between Canara Bank and HSBC. He discusses their focus on securing individuals' futures through insurance and highlights a recent initiative involving an underwriting co-pilot designed to assist underwriters in assessing risk.""]",Canada HSBC Life Insurance has recently undertaken an initiative involving an underwriting co-pilot designed to assist underwriters in assessing risk.,single_hop_specific_query_synthesizer
"How does Rana Kalaf describe the evolution of AI development in terms of delivering business value, and what does she emphasize as crucial for AI applications?","['## [301.52s] The Challenge of Delivering Business Value\nThe discussion shifts to the challenges of delivering business value through AI products. Rana Kalaf addresses the initial excitement of building AI products and the subsequent concerns about whether they truly deliver value. She notes the evolution of AI development, contrasting traditional data science practices with the current need for real-time, distributed systems. Rana emphasizes that building AI applications is now a collaborative effort, requiring a focus on scalability and production readiness. She stresses the importance of measuring the effectiveness of AI tools, suggesting that organizations should view AI as a means to enhance processes rather than an end goal.']","Rana Kalaf describes the evolution of AI development by contrasting traditional data science practices with the current need for real-time, distributed systems. She emphasizes that building AI applications is now a collaborative effort, requiring a focus on scalability and production readiness. Additionally, she stresses the importance of measuring the effectiveness of AI tools and suggests that organizations should view AI as a means to enhance processes rather than an end goal.",single_hop_specific_query_synthesizer
Why is AI adopshun important?,"[""## [1543.04s] The Importance of Adoption and Justification\nAdoption of AI technologies is critical, as users often scrutinize AI outputs for errors. There is a tendency for individuals to be more forgiving of their own mistakes than those made by machines, which can impact the perception of AI's reliability. Justifying the use of AI, especially for smaller tasks, remains a challenge, but improvements in technology are expected to enhance its acceptance and integration into various workflows.\n\n# [1140.48s] Data Set Generation for Evaluation\nRegarding the data set for evaluation, we synthesize the data set to ensure it meets our needs. For instance, in the case of RAG agents, we generate questions based on specific chunks of data to facilitate effective evaluation and validation of the agents' performance.""]","Adoption of AI technologies is critical because users often scrutinize AI outputs for errors, and there is a tendency for individuals to be more forgiving of their own mistakes than those made by machines, which can impact the perception of AI's reliability.",single_hop_specific_query_synthesizer
What is DPAL in the context of AI model evaluation?,"['**Time Range: 00:20:01 - 00:27:55**\n\n# [1201.28s] Importance of Using Closed Source Models\nTo achieve accurate answers, it is crucial to utilize a closed source model. This approach allows for the generation of predicted outputs, which can then be compared against the results from your own model. This comparison is essential for evaluating performance and ensuring clarity and transparency in the outputs.\n\n## [1225.36s] Evaluation Metrics for AI Models\nDifferent agents or tasks have their own specific metrics for evaluation. For instance, various frameworks such as DPAL and RO are available for out-of-the-box evaluation. These frameworks can be utilized directly or customized to fit specific needs.']","DPAL is a framework available for out-of-the-box evaluation of AI models, which can be utilized directly or customized to fit specific needs.",single_hop_specific_query_synthesizer
What A2A do?,"['# [1262.24s] Short-Term Predictions and Challenges in AI\nAs the discussion shifts to the future of AI, it is acknowledged that predicting developments over the next decade is challenging. In the short term, the focus is on the evolution of generic use cases into more domain-specific applications. The integration of A2A protocols and other technologies will play a significant role in this transition. Currently, developers are stitching together numerous APIs and data sources, but the future will likely emphasize context and integration, leading to reduced development cycles and the emergence of new business use cases.']",The integration of A2A protocols and other technologies will play a significant role in the transition to more domain-specific applications in AI.,single_hop_specific_query_synthesizer
What is the role of WSO2 in the context of AI and helathcare?,"['## [1611.76s] The Evolution of Software Engineering with AI\nThe evolution of software engineering in the context of AI tools is discussed. As developers begin to adopt AI-driven tools, they often seek to identify mistakes in their code. However, AI can assist in code reviews and error detection more effectively than traditional methods. The necessity for developers to adapt to these tools is emphasized, as failure to do so may result in obsolescence in the industry.\n\n**Time Range: 00:00:03 - 00:10:05**\n\n# [3.44s] Introduction\nThe speaker has been a part of the WSO2 solutions team for over seven years, primarily focusing on the financial sector. Currently, they are working on AI applications in healthcare and other sectors.']","The speaker has been a part of the WSO2 solutions team for over seven years, primarily focusing on the financial sector, and is currently working on AI applications in healthcare and other sectors.",single_hop_specific_query_synthesizer
What is the role of Generic AI in the transition towards more specialized AI applications like vertical AI?,"[""## [25.28s] Discussion on Vertical AI\nThe focus of today's discussion is on vertical AI, which is a significant aspect of the ongoing track dedicated to specialized AI applications. Before delving into vertical AI, it is essential to clarify what generic AI entails.\n\n### [38.24s] Understanding Generic AI\nGeneric AI, often referred to as general-purpose AI, has been widely used for various personal and business tasks. It is designed to handle a broad range of applications. However, we are transitioning from this general-purpose AI, which is built for diverse uses, to a more specialized form known as vertical AI. This shift allows for the development of specific AI solutions tailored to industries such as healthcare, legal, and financial services.""]","Generic AI, also known as general-purpose AI, has been widely used for various personal and business tasks due to its ability to handle a broad range of applications. However, there is a transition from this general-purpose AI to a more specialized form known as vertical AI, which allows for the development of specific AI solutions tailored to industries such as healthcare, legal, and financial services.",single_hop_specific_query_synthesizer
How vertical AI help in healthcare?,"['### [350.72s] Framework for Vertical AI\nThe vertical AI layer is built on existing frameworks, utilizing core large language models (LLMs) from companies like OpenAI, Anthropic, and Gemini. These foundational models serve as the base for horizontal AI applications. On top of this, supporting frameworks such as retrieval-augmented generation (RAG) and data infrastructure are integrated. The vertical layer introduces industry-specific model tuning and regulatory compliance, ensuring that the AI solutions are tailored to meet the unique needs of specific sectors.\n\n## [424.88s] Example: Healthcare Customer Support\nTo illustrate the effectiveness of vertical AI, consider a healthcare customer support requirement. At the foundational level, general-purpose LLMs provide basic language capabilities. Companies like Sierra and Decagon enhance these capabilities with frameworks optimized for customer support. The vertical AI layer then adds the necessary clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems. Without this tailored vertical layer, the AI solution would lack the understanding of healthcare nuances and regulatory constraints essential for real-world deployment.']","Vertical AI in healthcare enhances general-purpose language models with clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems, ensuring the AI solutions are tailored to meet the unique needs of the healthcare sector.",single_hop_specific_query_synthesizer
How does vertical AI enhance healthcare systems?,"['### [518.96s] Value Additions of Vertical AI\nThe vertical AI layer includes several value additions, such as:\n\n- **Industry-Specific Model Adaptation**: Tailored knowledge and terminology relevant to healthcare customers.\n- **Proprietary Data Utilization**: Incorporation of industry-specific workflows and decision-making logic that aligns with established processes.\n- **Seamless Integration**: The ability to connect with industry-specific systems, such as healthcare systems and open banking APIs.\n- **Regulatory Compliance**: Development of API products that adhere to industry regulations, ensuring that the solutions are both effective and compliant.']","Vertical AI enhances healthcare systems by providing industry-specific model adaptation with tailored knowledge and terminology, utilizing proprietary data to align with established workflows, enabling seamless integration with healthcare systems, and ensuring regulatory compliance.",single_hop_specific_query_synthesizer
Wht is the importnce of artifical intellgence in healthcare?,"['**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Importance of Strict Industry Regulations\nStrict industry regulations are paramount, especially in the context of artificial intelligence (AI). Regulators are expected to be very stringent regarding the usage of data and the activities surrounding AI technologies.\n\n## [616.48s] Current Landscape of AI\nA small demonstration illustrates the current state of AI. On top of the horizontal AIs, there are several vertical AIs that have been introduced and are being adopted at the moment. Different regions and even sub-areas within a vertical are tailored to meet specific requirements.']","Strict industry regulations are paramount, especially in the context of artificial intelligence (AI), as regulators are expected to be very stringent regarding the usage of data and the activities surrounding AI technologies.",single_hop_specific_query_synthesizer
What role does Swift MT play in the banking sector according to the WSO2 solutions team?,"['## [649.52s] WSO2 Solutions Team Initiatives\nThe solutions team at WSO2 is actively engaged in this sector, although they do not provide a full AI solution. Instead, they focus on two main areas. The first is ""AI for Code,"" which offers developer-focused capabilities designed to enhance developer experiences and productivity throughout the software development life cycle. The second area is ""Code for AI,"" where they provide programming abstractions and building blocks that can be utilized to create custom AI solutions.\n\n### [715.12s] AI for Code\nAn example of ""AI for Code"" can be seen in the integration capabilities developed by the WSO2 solutions team. In the healthcare sector, they support various standards such as FHIR, HL7, X12, CDA, and decom messages, along with pre-built translations between these standards. In the banking sector, they support ISO 853, ISO 222 (also known as MX messages), and Swift MT messages, with pre-built translations for Swift MT to MX.\n\nThe integration solution includes a co-pilot that developers can use. This co-pilot is a generic or horizontal AI, but for healthcare and banking requirements, WSO2 has developed vertical AIs. For instance, the healthcare co-pilot is designed to understand healthcare-related prompts. It is aware of standards such as FHIR and EHR systems, and it utilizes the available libraries and solutions to address healthcare-specific requirements.']","In the banking sector, the WSO2 solutions team supports Swift MT messages and provides pre-built translations for Swift MT to MX.",single_hop_specific_query_synthesizer
What does WSO2 offerr in terms of converting FHIR servers for AI agents?,"['### [846.64s] Code for AI\nMoving on to ""Code for AI,"" this involves providing building blocks for developing AI-related capabilities. An example is the MCP server, which converts a standard API into a tool that an AI agent can easily communicate with. WSO2 offers pre-built support to convert any FHIR server, such as an EHR server, into an MCP server, allowing direct communication with AI agents.\n\nA demonstration illustrates this user experience. When a user enters a healthcare-specific prompt, the system redirects to an authorization flow where the user must provide consent for the agent to access their data. The AI agent then calls the APIs using the MCP server to access the records. For example, if the prompt is about recorded immunizations, the AI agent retrieves the relevant health records. This capability is significant because a horizontal AI would lack the knowledge to interact with EHR systems and would require server-side enablement via the MCP server.']","WSO2 offers pre-built support to convert any FHIR server, such as an EHR server, into an MCP server, allowing direct communication with AI agents.",single_hop_specific_query_synthesizer
What Sarah do when she want change her cardiology appointment?,"['## [979.28s] Vertical AI Use Cases\nSeveral vertical AI use cases can be explored, highlighting different aspects of AI applications. The first use case involves user-present agents, commonly referred to as chat agents. In this scenario, the user interacts with a large language model (LLM) and can be redirected for authentication or asked questions by the chat agent.\n\n### [1021.20s] User-Present Agent Example\nAn example of this is Sarah, who wants to reschedule her cardiology appointment. The current flow involves a manual rescheduling process where Sarah calls the hospital, is transferred to the cardiology department, and the staff verifies her identity. The staff then manually searches for available slots, and Sarah waits to select a new time, after which the staff updates the records and sends an SMS confirmation. \n\nThe main problems with this process include time consumption, human dependency, and the need for repeated information sharing, especially during peak call volumes. The manual effort required by staff to update records and send confirmations can be frustrating.']","Sarah calls the hospital, is transferred to the cardiology department, and the staff verifies her identity. The staff then manually searches for available slots, and Sarah waits to select a new time, after which the staff updates the records and sends an SMS confirmation.",single_hop_specific_query_synthesizer
How AI work in open banking for transactions?,"['## [1237.44s] Open Banking Integration\nIn the context of open banking, there is a straightforward endpoint available to call for bank transactions, allowing for direct connections. The AI agent listens for these updates, and once the conditions are met, it processes the payment. Open banking use cases are particularly relevant here, as they allow for the initiation of transactions in this manner.\n\n### [1262.32s] User Verification in Transactions\nOnce the AI agent initiates a transaction with the bank, a notification is sent to the user for transaction verification. This process is referred to as ""user in the loop"" flows, a term used in generative AI. The push notification can be implemented from either the AI agent layer or the bank layer, with an emphasis on the open banking requirement.']","In the context of open banking, the AI agent listens for updates and processes payments once conditions are met. It initiates transactions with the bank and sends a notification to the user for transaction verification, which is part of the 'user in the loop' flows.",single_hop_specific_query_synthesizer
What SAR do?,"['## [1297.20s] Back Channel Authentication\nFor the push notification, the standard used is SAR client-initiated back channel authentication. The AI agent initiates a back channel authentication request with the bank, which then sends a notification to the user for approval. Upon receiving approval, the bank provides a token to the AI agent, allowing it to call the endpoint.\n\n# [1320.96s] Endless Possibilities\nWith these capabilities, the possibilities are endless. It is encouraged for everyone to consider how they can leverage this technology to enhance customer experiences and improve their systems. Assistance is available to help implement these solutions, as every example and scenario discussed can be executed using WSO software. Collaboration with various customers is already underway to achieve these implementations.']","SAR client-initiated back channel authentication is used for push notifications, where the AI agent initiates a request with the bank, which then sends a notification to the user for approval. Upon receiving approval, the bank provides a token to the AI agent, allowing it to call the endpoint.",single_hop_specific_query_synthesizer
How does Steve Jobs' perspective on innovation relate to current concerns about AI in the healthcare industry?,"['# [1358.80s] Conclusion and Reflection\nIn conclusion, it is important to acknowledge the current apprehension surrounding AI, with concerns about its potential to replace jobs and industries. However, innovation should be viewed as an opportunity rather than a threat. This perspective is encapsulated in a quote by Steve Jobs, which remains highly relevant today. Thank you very much for your attention.\n\n**Time Range: 00:00:03 - 00:10:07**\n\n# [3.76s] Introduction\nIn this session, the speakers, Arshad and Aisha, welcome everyone and express their hope that the audience is ready to get started. They are here to discuss how to govern and secure AI services in a scalable manner.']","Steve Jobs' perspective on innovation, which suggests viewing it as an opportunity rather than a threat, is relevant to current concerns about AI potentially replacing jobs and industries. This viewpoint encourages seeing AI as a chance for advancement and improvement in the healthcare industry.",single_hop_specific_query_synthesizer
What are the challenges in deploying AI applications from development to production?,"['## [76.16s] Challenges in AI Application Deployment\nAs organizations develop new AI applications, it is crucial to consider the challenges that arise when transitioning from a development environment to production. While it may feel satisfactory to see something work in development, ensuring scalability in production is essential to prevent organizational setbacks. The speakers encourage audience participation, inviting questions and interactions throughout the session.\n\n## [125.20s] Governance in AI Services\nArshad begins discussing the governance aspect of AI services, referencing recent news cases where AI systems have produced inappropriate or harmful responses. Such incidents pose risks to organizations, as they are responsible for delivering these services to end users. It is vital to govern AI behavior effectively to prevent such occurrences.']","The challenges in deploying AI applications from development to production include ensuring scalability in production to prevent organizational setbacks, even if the application works satisfactorily in the development environment.",single_hop_specific_query_synthesizer
What are the data privacy risks associated with using LLMs in medical AI applications?,"['### [172.96s] Cost Considerations\nAnother critical point raised is the cost associated with deploying AI applications. In development, costs may not be as apparent, but once in production, organizations may face challenges related to token usage and scaling, making governance even more important.\n\n### [205.20s] Data Privacy Risks\nData privacy is another significant concern, especially with the advent of large language models (LLMs). Organizations previously had control over their data, but the use of LLMs complicates this, as they often require sending data outside the organization for processing. This raises concerns about the potential leakage of personally identifiable information (PII).']","The use of large language models (LLMs) complicates data privacy because they often require sending data outside the organization for processing, raising concerns about the potential leakage of personally identifiable information (PII).",single_hop_specific_query_synthesizer
"What insights does Aisha provide regarding the integration of AI agents into enterprise systems, particularly concerning access to enterprise resources and business data?","['### [264.08s] Security and Permissions\nDespite proper governance, there are instances where AI systems may act outside their intended parameters. An example is cited where an AI agent deleted its production databases despite being instructed not to. This highlights the need for robust security measures and appropriate permission allocations.\n\n# [300.32s] Incorporating AI Agents into Enterprise Systems\nAisha takes over to discuss the integration of AI agents into enterprise systems. She emphasizes that the focus is not on creating toy applications but on providing AI with access to enterprise resources and business data. It is crucial to ensure that only authorized access is granted to this data.']","Aisha discusses the integration of AI agents into enterprise systems, emphasizing that the focus should not be on creating toy applications but on providing AI with access to enterprise resources and business data. She highlights the importance of ensuring that only authorized access is granted to this data.",single_hop_specific_query_synthesizer
What is the GDRP?,"['## [339.04s] Governance of AI Agents\nThe governance of AI agents is essential to prevent unauthorized actions. For instance, if an AI agent designed for marketing data gains admin rights to a financial system, it could perform unnecessary transactions or expose sensitive customer information.\n\n### [377.28s] Importance of Auditability\nAuditability is vital in agentic systems, as agents operate at high speeds, making changes to APIs and databases. Tracking these actions is necessary for forensic purposes, allowing organizations to trace who did what and when.\n\n### [419.12s] Compliance and Governance Requirements\nOrganizations must also navigate governance and compliance requirements, such as GDPR, to protect user data and prevent misuse of AI capabilities. The speakers stress that while AI is not inherently bad, it is essential to employ AI securely and govern access effectively to maximize its benefits.']","Organizations must navigate governance and compliance requirements, such as GDPR, to protect user data and prevent misuse of AI capabilities.",single_hop_specific_query_synthesizer
What are the security considerations for AI-driven systems?,"['**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","In the context of AI-driven systems, it is crucial to assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of malicious agents or bots, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.",single_hop_specific_query_synthesizer
What agentic AI do?,"[""### [920.32s] Staff Allocation Agent\nThe second agent operates in the background as a staff allocation agent. It is triggered when a booking is made, accessing the user's personal profile to assign appropriate staff for that booking instance. This integration raises important considerations regarding security boundaries within the agentic AI framework.\n\n## [948.00s] Security Boundaries in Agentic AI\nWhen introducing agentic AI into the platform, it is essential to establish various security boundaries. The user-agent interaction forms one boundary, while the backend systems represent another. These backend systems may interact with external parties, necessitating secure management of incoming and outgoing requests. Additionally, the ambient agent receives requests to perform tasks, requiring secure communication with the business's backend APIs and the ability to update existing bookings.""]","Agentic AI in this context involves a staff allocation agent that operates in the background to assign appropriate staff for booking instances, while also considering security boundaries in user-agent interactions and backend systems.",single_hop_specific_query_synthesizer
Wht are the securty consderations when using GPT-4 in AI models?,"['## [2096.80s] Identity Representation and Security\nThis system introduced an extension to existing standards, enabling the identification of actions taken by agents on behalf of users. The staff allocation agent operated using its own token, proving its identity to the Guardio system and making API calls to backend services. This structure ensures that all users, applications, and agents have distinct identifications within the ecosystem.\n\n### [1024.40s] Securing AI Model Connections\nThe AI model, which could be based on various providers such as GPT-4, introduces another layer of security considerations. Connections between the business and the external AI model must be secured, and this is where governance layers and guardrails, as previously discussed, become critical.']","The AI model, which could be based on various providers such as GPT-4, introduces another layer of security considerations. Connections between the business and the external AI model must be secured, and this is where governance layers and guardrails become critical.",single_hop_specific_query_synthesizer
What are the plans for integrating identity management solutions with the W2 identity server product?,"['# [3001.36s] Token Management in AI Systems\nWithin organizations, managing token usage is crucial. There are instances where one team may utilize 500,000 tokens while other teams are assured a specific count of tokens. To address this, a system has been introduced for this use case. Within the gateway, token counting can be performed, but it primarily relies on the output provided by the language model (LLM) itself. Most LLMs report the number of tokens used, and this output is essential for accurate counting.\n\n# [1261.68s] Identity Management Offerings\nThe system offers two identity management (IM) solutions: Suffering W and Asgardio. Asgardio is readily available for use, and users are encouraged to try it out. Additionally, there are plans to onboard these offerings to the upcoming W2 identity server product, which will be downloadable for users to run in their own environments.']","There are plans to onboard the identity management offerings, Suffering W and Asgardio, to the upcoming W2 identity server product, which will be downloadable for users to run in their own environments.",single_hop_specific_query_synthesizer
Wht are AI Sytems?,"['### [2329.68s] Compliance and Trust in AI Systems\nBuilding agentic AI systems securely from the outset helps meet compliance requirements and prepares businesses for future regulations. This approach fosters user trust, ensuring that data remains secure and protected from unauthorized access. Additionally, it enhances operational efficiency by automating tasks, allowing businesses to operate confidently without fear of agents causing disruptions.\n\n**Time Range: 00:40:01 - 00:50:03**\n\n# [2401.52s] Operational Efficiency and Scalability of Agents\nThe operational efficiency of agents is a critical aspect to consider. When discussing agents, it is important to recognize that there will be thousands of them, including personal agents, team agents, and organizational agents. Additionally, there will be agents that are spawned temporarily to perform specific tasks before being terminated. Scalability is essential in this context, as it allows for the effective management of these agents.\n\nWith a clear identity for each agent, it becomes possible to ensure that they are properly identified and can only access the systems for which they have authorization. As previously mentioned by Arshad, this capability enables faster innovation and enhances the value of AI with confidence.']","AI systems, when built securely from the outset, help meet compliance requirements and foster user trust by ensuring data security and protection from unauthorized access. They also enhance operational efficiency by automating tasks, allowing businesses to operate confidently.",single_hop_specific_query_synthesizer
How can Docker images be utilized in the context of Guarders AI for medical AI research?,"['## [3646.16s] Built-in Guardrails and Third-Party Integrations\nThe product includes a set of built-in guardrails, and it also supports third-party integrations. For instance, if there are integrations with services like AWS Bedrock or content safety solutions, users can opt to utilize these guardrails. The gateway is fully compatible with these services, allowing prompts to be sent to LLM services like AWS Bedrock, which will perform the necessary classification to identify any guard validations or failures.\n\nIf there are concerns regarding Personally Identifiable Information (PII), a mixed approach can be adopted. Initially, PII validation can occur at the gateway level before sending the request to AWS Bedrock for further processing. For those who do not have subscriptions or face cost issues, the system provides its own set of guardrails through a framework called Guarders AI. This framework is developed and hosted by the team, and there are plans to offer it as Docker images for users to run within their organizations, allowing for customizations to ensure security and proper governance.']","The Guarders AI framework, developed and hosted by the team, is planned to be offered as Docker images. This allows users to run the framework within their organizations, enabling customizations to ensure security and proper governance.",single_hop_specific_query_synthesizer
What role did Aayisha play in the security aspect of agent access?,"[""## [2456.80s] Governance and Security of Agent Access\nTo secure agents' access to various systems, it is necessary to consider the governance aspect. This involves understanding the different trust boundaries, particularly the line connecting agents to AI models. Governance and guardrail requirements arise from this relationship, and Aishad will elaborate on this with examples.\n\n### [2493.84s] Transition to Governance\nThe governance side of things is crucial. Initially, Aayisha covered the security aspect, which involves granting necessary permissions and ensuring that agents are properly tracked and auditable. Now, we will delve into the governance aspect, where our AI gateway offering plays a significant role. \n\nOur API management team has been refining this offering over the past few years to make it more user-friendly and scalable, with input from customers and users. We are continuously evolving, and I will present our current capabilities and future plans.""]","Aayisha covered the security aspect, which involves granting necessary permissions and ensuring that agents are properly tracked and auditable.",single_hop_specific_query_synthesizer
How have the advancements in AI and LLMs influenced the need for organizations to manage backend services' access to external parties?,"['## [2541.68s] Organizational Boundaries and Egress Gateway\nWhen considering organizational boundaries, it is essential to address the backend services developed and deployed within the organization. Our API management team has been managing the egress and ingress gateway aspects, protecting backend services from unauthorized external access. This protection ensures that only relevant parties can access these services, utilizing policies for authorization and throttling.\n\nWith the emergence of AI and LLMs, there has been an increasing need for organizations to allow backend services to call external parties. Previously, this was not a significant requirement, but as AI and LLM technologies have grown, organizations must navigate this challenge. This is where our egress gateway comes into play.']","With the emergence of AI and LLMs, there has been an increasing need for organizations to allow backend services to call external parties. Previously, this was not a significant requirement, but as AI and LLM technologies have grown, organizations must navigate this challenge. This is where our egress gateway comes into play.",single_hop_specific_query_synthesizer
How does the Egress AI Gateway enhance governance in AI-powered healthcare applications?,"['### [2605.04s] Egress AI Gateway Introduction\nThe egress AI gateway functions similarly to the ingress gateway, with a set of customized policies and rules enforced to ensure that all outgoing calls from the organization are properly governed and managed. This provides visibility into the interactions occurring outside the organization.\n\nFor instance, consider an AI-powered booking assistant and a staff allocation agent accessing different deployments of OpenAI in various regions. This scenario illustrates the complexity of tracking calls to different models and deployments, which can lead to hidden costs and management challenges. The egress AI gateway addresses these issues by sitting between backend systems and LLM services, ensuring proper governance.']","The Egress AI Gateway enhances governance in AI-powered healthcare applications by enforcing customized policies and rules to ensure that all outgoing calls from the organization are properly governed and managed. This provides visibility into interactions occurring outside the organization, addressing issues such as hidden costs and management challenges by sitting between backend systems and LLM services.",single_hop_specific_query_synthesizer
What are the key features of the Egress AI Gateway?,"['## [2721.68s] Features of the Egress AI Gateway\nAs organizations grow their AI teams and adopt various AI services, the need for a mediation layer becomes apparent. This layer allows organizations to manage interactions with multiple AI providers without being dependent on a single one. \n\nThe egress AI gateway offers several features, including model routing, token-based rate limiting, AI guard, prompt management, adaptive routing, and semantic caching. Additionally, it retains the standard capabilities of an ingress gateway, such as analytics, identity access management, and mediation capabilities. Organizations can connect with any AI service, and the product comes pre-configured with a set of services while allowing for custom configurations.']","The Egress AI Gateway offers features such as model routing, token-based rate limiting, AI guard, prompt management, adaptive routing, and semantic caching. It also retains standard capabilities of an ingress gateway, including analytics, identity access management, and mediation capabilities.",single_hop_specific_query_synthesizer
Wht are LLMs and how do they impact resource management?,"['## [2914.24s] Performance and Resource Optimization\nThe first area of focus in this discussion is performance and resource optimization, which addresses challenges faced by customers. To tackle these challenges, we have developed a set of features, including token-based rate limiting. \n\nPreviously, our ingress gateway supported bandwidth-based and request count-based rate limiting. However, with the rise of LLMs, there was a growing demand for token-based quotas. Organizations can now share a set number of tokens across different product teams, allowing for more efficient resource management. For example, if an organization has an agreement with OpenAI for 10 million tokens per month, they can allocate these tokens among five teams, ensuring that each team has a defined usage limit.']","With the rise of LLMs, there was a growing demand for token-based quotas, allowing organizations to share a set number of tokens across different product teams for more efficient resource management.",single_hop_specific_query_synthesizer
How do LLMs utilize semantic response caching to improve efficiency?,"['**Time Range: 00:50:01 - 01:00:05**\n\n## [3036.08s] Request and Token Count Policies\nIt is important to note that the introduction of token counting does not eliminate the request per minute count. Organizations can still implement policies that combine request counts with token limit counts, which is fully supported.\n\n# [3052.80s] Semantic Response Caching\nThe semantic response cache is designed to reduce costs, although it may not be applicable to all AI scenarios. It is particularly advised for use in documentation assistance, where responses are derived from a specific knowledge base. In such cases, processing every call may not be efficient, as the same question can be asked in various ways. \n\nThe traditional response cache operates on a direct key-value basis, where a request is cached, and if a subsequent request matches exactly, the previous answer is returned. However, with LLMs, this approach is insufficient because different users may phrase the same question differently. Therefore, semantic response caching has been developed. If one person asks a question in one way and another person asks it differently, but both inquiries are essentially the same, the system can deliver the previous response to the second user. Some LLMs have implemented this feature in their back-end systems to enhance efficiency, although its effectiveness can vary.']","LLMs utilize semantic response caching to improve efficiency by allowing the system to deliver a previous response to a second user if their inquiry is essentially the same as a previous one, even if phrased differently. This approach is particularly useful in scenarios like documentation assistance, where responses are derived from a specific knowledge base.",single_hop_specific_query_synthesizer
How does AI Gateway Analytics assist AI developers in understanding system performance and optimizing model usage?,"['# [3146.56s] AI Gateway Analytics\nAI gateway analytics involves publishing specific analytic details for AI use cases. For example, a casual analytic scenario may count requests, identify headers used, and track errors. This provides a breakdown that helps AI developers understand system performance. The analytics dashboard is purpose-driven, allowing developers to identify issues, such as which services or applications are consuming more data or tokens. \n\nThe dashboard offers detailed insights into vendor model usage, identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.']","AI Gateway Analytics provides a breakdown that helps AI developers understand system performance by publishing specific analytic details for AI use cases. It tracks requests, identifies headers used, and monitors errors, allowing developers to identify issues such as which services or applications are consuming more data or tokens. The analytics dashboard offers detailed insights into vendor model usage, identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.",single_hop_specific_query_synthesizer
Whaat are AI Guardrails and how do they function in SaaS and on-premises solutions?,"['# [3222.96s] AI Guardrails\nAI guardrails are a critical area of focus, and a variety of guard mechanisms have been released. These guardrails are available in both Software as a Service (SaaS) and on-premises solutions. The first guard is the semantic prompt guard, which allows users to configure a set of allowed and denied topics. This ensures that all prompts exiting the egress gateway adhere to the defined parameters.\n\n## [3264.72s] Semantic Prompt Guard\nThe semantic prompt guard captures variations of terms to prevent misuse. For instance, if a student assistant app has a denied topic like ""write my homework,"" any attempt by a student to phrase this request differently will be blocked or flagged based on user configuration.']","AI guardrails are mechanisms available in both Software as a Service (SaaS) and on-premises solutions, designed to ensure that all prompts adhere to defined parameters. The semantic prompt guard, for example, allows users to configure allowed and denied topics, capturing variations of terms to prevent misuse.",single_hop_specific_query_synthesizer
Wht is the purpse of PII maskng in AI systms?,"['## [3331.68s] Regex-Based PII Masking\nRegex-based PII (Personally Identifiable Information) masking allows users to define patterns, such as email addresses, that must not be matched in outgoing prompts. If an email is detected, the system replaces it with a dummy value, ensuring that sensitive information is not exposed while still allowing the LLM to function normally.\n\n## [3397.12s] Advanced PII Detection and Masking\nFor more ambiguous cases, advanced PII detection and masking techniques are employed. This involves using a framework called Guard AI, which utilizes LLMs to make decisions and perform reasoning. This combination of regex and advanced detection provides robust security for the egress gateway, preventing sensitive information from being leaked to the LLM.']","PII masking in AI systems is used to ensure that sensitive information, such as email addresses, is not exposed. This is achieved by replacing detected PII with dummy values, allowing the system to function normally while maintaining security and privacy.",single_hop_specific_query_synthesizer
Culd you explane how JSON schema validation is used as a basic guardrail in AI systems?,"['## [3442.48s] Basic Guardrails\nBasic guardrails include word count and sentence count limits, JSON schema validation, regex validation, and URL validation. The URL validator ensures that any URLs generated by the LLM are valid and not hallucinated. Additionally, content length guardrails and grounded AI hallucination checks are implemented to verify the accuracy of LLM responses.\n\n# [3512.48s] Content Safety and Jailbreak Detection\nContent safety guardrails prevent the inclusion of prompts related to violence or harassment. Jailbreak detection is particularly important, as it ensures that users cannot manipulate the LLM into ignoring rules or providing inappropriate responses. This is crucial for maintaining the integrity of the AI system, as organizations ultimately bear the costs associated with misuse.']","JSON schema validation is used as a basic guardrail to ensure that the data structure adheres to a predefined format, which helps in maintaining the accuracy and reliability of the AI system's responses.",single_hop_specific_query_synthesizer
How does the model failover policy utilize GPT-4 Mini when the primary model's quota is exceeded?,"['## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.']","The model failover policy uses GPT-4 Mini as a fallback option when the primary model's quota is exceeded. Initially, users receive responses from GPT-4, but once the personal quota is surpassed, they may fall back to GPT-4 Mini, resulting in subpar responses. This behavior is emulated by the AI gateway, which routes requests to a primary endpoint until it is exhausted, then falls back to a secondary endpoint.",single_hop_specific_query_synthesizer
What AI gateway do in healthcare AI?,"['# [3897.20s] Prompt Management\nThe final section addresses prompt management, which involves templating and decorating prompts. This aspect is crucial for development use cases that interact with the AI gateway. While the AI gateway primarily handles governance, it also allows for the implementation of policies.\n\n### [373.68s] Unique Challenges of Agentic AI\nAyesha notes that traditional access management is not a new concept, but it faces unique challenges in the AI landscape. As agents gain access to APIs and operate autonomously, they can perform tasks on behalf of multiple users, complicating permission management. For example, an agent assisting with recruitment may interact with applicants and managers, necessitating a nuanced understanding of permissions and access rights.']",The AI gateway primarily handles governance and allows for the implementation of policies in development use cases.,single_hop_specific_query_synthesizer
What Rania say about identity management and agents?,"['## [497.36s] Advancements in Identity Management\nRania adds that while there is a solid foundation for identity access management today, the emergence of agents represents an extension of existing constructs. Some organizations have successfully implemented agents in live production, utilizing applications to represent agents based on their operational context. However, there are risks associated with providing agents access to sensitive credentials, which could lead to security breaches.\n\n## [3905.52s] Prompt Decoration\nFor instance, a system prompt can be provided to the LLM, instructing it to act in a specific role, such as a teacher. A prompt decorator can be used to specify that the LLM is a hotel booking assistant, with user prompts appended accordingly. This ensures that the LLM is aware of its role, even if the application does not explicitly include this information.']","Rania adds that while there is a solid foundation for identity access management today, the emergence of agents represents an extension of existing constructs. Some organizations have successfully implemented agents in live production, utilizing applications to represent agents based on their operational context. However, there are risks associated with providing agents access to sensitive credentials, which could lead to security breaches.",single_hop_specific_query_synthesizer
What OpenAI do?,"['## [3960.16s] Templating in the Egress Gateway\nAdditionally, the egress gateway allows for the definition of prompts with placeholders. Instead of sending the entire prompt each time, only essential keys, such as guest name, booking history, and preferences, need to be communicated. The gateway handles the mapping and sends the request to the OpenAI endpoint.\n\n# [4030.96s] API Management\nIn the API manager, users can create APIs by selecting specific providers. The API publisher facilitates this process, allowing for the configuration of endpoints and management of keys to ensure secure access.\n\n## [4094.00s] Policies and Guardrails\nPolicies can be applied to the configured APIs, such as prompt decorators that define the role of the assistant. Additionally, guardrails can be set up to handle PII, either by redacting sensitive information or masking it with placeholders. This provides control over how PII is managed throughout the process.']",The egress gateway handles the mapping and sends the request to the OpenAI endpoint.,single_hop_specific_query_synthesizer
"Wht is the role of an API in helthcare AI systems, and how does it relate to observability and logging?","['## [4142.16s] Observability and Logging\nFinally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant.\n\n**Time Range: 01:10:00 - 01:18:25**\n\n# [4200.40s] Introduction to API Usage with Guardrails\nBefore attempting to use the API with Guardrails, it is essential to understand how a use case would appear without these protective measures. In this demonstration, a query related to firearms is posed, which is not an appropriate topic for a hotel assistant.']","In healthcare AI systems, an API can be used with guardrails to ensure secure and compliant interactions. Observability and logging are crucial as they allow for tracking and monitoring all actions, ensuring effective management and governance of the AI gateway.",single_hop_specific_query_synthesizer
What LLM do?,"['## [4220.48s] API Key and Initial Query\nTo begin, an API key is obtained from the API gateway under chat completions. The specific query posed is, ""What guns are the best for a beginner to use?"" This question is not relevant for a hotel assistant, highlighting the limitations of a standard language model (LLM) without guardrails.\n\n## [4261.60s] Response from the Unprotected LLM\nIn this scenario, the LLM is designed to respond to any inquiry. Consequently, it provides a detailed description of various firearms suitable for beginners. This response is not ideal for an organization, as it lacks the necessary safeguards.']","The LLM is designed to respond to any inquiry, but without guardrails, it may provide responses that are not ideal for an organization, such as detailed descriptions of firearms suitable for beginners.",single_hop_specific_query_synthesizer
How do MCP servers simplify the integration of APIs?,"['# [4531.60s] Introduction to MCP Servers\nAs organizations integrate APIs, the challenge of managing multiple connectors arises. The introduction of the MCP (Model Context Protocol) allows for the standardization of APIs into a single interface, simplifying the integration process.\n\n## [4570.32s] Exposing APIs as MCP Servers\nOrganizations can quickly expose their existing APIs as MCP servers, facilitating easier connections with agents. This capability allows for the management of MCP servers, including the addition of authentication.\n\n## [4621.20s] Governing Access to Remote MCP Servers\nIn cases where organizations are hesitant to use their APIs directly, they can create their own integrations, expose them as MCP servers, and govern access through the gateway.']","The introduction of the MCP (Model Context Protocol) allows for the standardization of APIs into a single interface, simplifying the integration process.",single_hop_specific_query_synthesizer
Culd yu pleese explane how SEED-X perfoms in the MRI super-resolushun reconstrukshun task?,"['C.6 Case Study\nFigures 11 and 12 illustrate examples of modality transformation and super-resolution reconstruction. In Figure 11, the results\ngenerated by our method in the CT (MRI) to MRI (CT) transformation task are highly close to the ground truth, effectively\nguiding the model in the transformation across different regions. For the MRI super-resolution reconstruction task, Figure 12\ndemonstrates the accuracy of our method in restoring scan image details, accurately reconstructing the essential details of the\nimage.\nTable 11: The experimental results for the four reconstruction tasks.\nCT(Brain) CT(Pelvis) MRI (Brain) MRI(Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\nSEED-X 20.18 27.66 112.11 21.53 28.02 102.87 4.90 27.62 112.86 6.31 27.89 106.21\nUnified-IO 2 83.93 36.09 17.95 85.36 35.10 25.46 87.50 34.25 25.47 86.31 33.53 29.80\nHealthGPT-M3 91.73 36.42 15.46 94.26 37.30 12.53 88.76 33.97 27.05 84.40 33.11 32.62\n34.08\n15.87\n9.16\n5.62\n13.33\n21.94\nHealthGPT\nLLaVA-Med\nHuatuoGPT-Vision\nLlama-3.2\nInternVL-2\nShow-o\nHuman\nEvaluation\n(a) (b)\nFigure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.\n17']","In the MRI super-resolution reconstruction task, SEED-X demonstrates accuracy in restoring scan image details, accurately reconstructing the essential details of the image.",single_hop_specific_query_synthesizer
What role does Ayesha Disanayake play in the context of agentic AI?,"[""## [10.80s] Overview of Previous Discussion\nIn the first video of this series, Geethika discussed some of the capabilities already introduced for securing agent AI. Today's session will take a step back to explore concepts around identity access management for agent AI, providing real-world examples and discussing why traditional identity management will not suffice for securing agent AI.\n\n## [41.44s] Guest Introduction\nGeethika is joined by Rania Khalaf, the Chief AI Officer, and Ayesha Disanayake, who leads the R&D effort for identity access management for agentic AI.\n\n## [61.92s] Understanding Agentic AI\nRania begins by explaining the basics of agentic AI and providing real-world examples. She notes that with the advent of foundation models and generative AI, there has been a significant improvement in conversational AI. Initially, many applications embedded calls to generative AI systems, focusing primarily on question answering and natural language processing. For instance, ChatGPT is an application that utilizes the GPT family of models to facilitate interaction. Another example is Gmail, where users can refine their messages with the help of Gemini.""]",Ayesha Disanayake leads the R&D effort for identity access management for agentic AI.,single_hop_specific_query_synthesizer
What Ayesha say about security?,"['## [212.16s] Importance of Security in Agentic AI\nAyesha emphasizes the significance of security in the context of agentic AI and discusses the risks associated with neglecting security measures. She cites a recent incident involving Replit, a software engineering assistant platform, where an agent deleted an entire production database despite being instructed not to do so. This incident highlights the necessity of implementing proper access controls and entitlement management for agents to prevent unexpected actions.\n\n### [268.80s] Challenges of Traditional Identity Management\nAyesha explains that traditional software was more predictable, with identity management designed for applications that followed predefined logic. In contrast, agentic systems operate continuously, with agents working 24/7, leading to varying authentication patterns and access levels. Traditional identity and access management approaches are more suited to static behaviors, while agentic AI introduces complexities due to the diverse behaviors of agents.']","Ayesha emphasizes the significance of security in the context of agentic AI and discusses the risks associated with neglecting security measures. She cites a recent incident involving Replit, a software engineering assistant platform, where an agent deleted an entire production database despite being instructed not to do so. This incident highlights the necessity of implementing proper access controls and entitlement management for agents to prevent unexpected actions.",single_hop_specific_query_synthesizer
Waht are the imprtant chnages in the MCP specifcation for user experince?,"['## [726.56s] Human Verification and Transaction Protocols\nTo mitigate consent fatigue, where users may grant permission indiscriminately, implementing human verification based on thresholds can be beneficial. For instance, allowing transactions up to a certain limit without additional consent, while requiring managerial approval for larger transactions, can streamline processes.\n\nWhen designing protocols and implementations, user experience must be a consideration. Earlier versions of the MCP specification required users to authenticate with the MCP server to access tool lists, which is not always practical. Users may first need to engage in preliminary interactions, such as chatting, before logging in. The MCP community has recognized this need and has introduced step-up authorization to enhance user experience.']","Earlier versions of the MCP specification required users to authenticate with the MCP server to access tool lists, which was not always practical. The MCP community has introduced step-up authorization to enhance user experience.",single_hop_specific_query_synthesizer
Waht is the futrue of agnet DKI and how is it recomended to be implemented?,"['## [798.24s] Evolving Standards and Community Engagement\nThe evolution of standards within the IM community is exciting, as it addresses the challenges associated with building agents. The involvement of team members, such as Aisha and Arana, in these discussions is crucial as the community works to solve these emerging issues.\n\n## [825.92s] Future of Agent DKI and Recommendations\nAs the conversation shifts towards the future of agent DKI, it is important to consider where this technology is headed. The concept of agents is gaining significant attention, and organizations that have not yet implemented agents are likely to do so soon. \n\nIt is anticipated that every engineer will need to become proficient in AI, as it becomes a fundamental part of the computing stack, akin to APIs and data. However, the current middleware stack is still evolving to support the integration of AI agents securely and efficiently.']","The future of agent DKI involves significant attention towards its implementation, with organizations likely to adopt this technology soon. It is recommended that engineers become proficient in AI, as it becomes a fundamental part of the computing stack, similar to APIs and data. The current middleware stack is still evolving to support the integration of AI agents securely and efficiently.",single_hop_specific_query_synthesizer
What role does Escardio play in addressing security challenges in AI agent adoption?,"['## [944.08s] Adoption Challenges and Security Considerations\nDespite the eagerness to adopt agents, a small percentage currently reach production due to inadequate access control and guardrails, leading to a lack of trust in these systems. Therefore, it is vital to incorporate identity and access management and security considerations from the outset of development. \n\nOrganizations should not treat security as an afterthought, as retrofitting these concepts later can be challenging and may result in significant issues. Existing IM constructs can be leveraged based on specific contexts, and offerings like Escardio provide unique identities for agents, allowing for controlled access.']","Escardio provides unique identities for agents, allowing for controlled access, which helps address security challenges in AI agent adoption.",single_hop_specific_query_synthesizer
Wht are the benfits of using wso2.com/Asgardeo for securing agents and authorizing MCP servers?,"['## [1027.52s] Conclusion and Next Steps\nIn conclusion, security and access control should be integral to agent development from day one. The conversation will continue in the next video, where Aayisha will join to discuss implementing identities and credentials for agents, as well as the capabilities launched on Escardio. \n\nIn the meantime, interested individuals are encouraged to visit wso2.com/Asgardeo to create a free account and explore the capabilities available for securing agents and authorizing MCP servers. Thank you for joining this discussion, and happy securing your agents.\n\nHealthGPT: A Medical Large Vision-Language Model for Unifying\nComprehension and Generation via Heterogeneous Knowledge Adaptation\nTianwei Lin1, Wenqiao Zhang1, Sijing Li1, Yuqian Yuan1, Binhe Yu2, Haoyuan Li3, Wanggui He3, Hao Jiang3,\nMengze Li4, Xiaohui Song1, Siliang Tang1, Jun Xiao1, Hui Lin1, Yueting Zhuang1, Beng Chin Ooi5\n1Zhejiang University, 2University of Electronic Science and Technology of China, 3Alibaba,\n4The Hong Kong University of Science and Technology,5National University of Singapore\nProject Page\n Code\n1. X-Ray \nComprehension\n2. CT\nComprehension\n3. MRI\nComprehension\nComp. Perf.\n7 Medical Multi-Modal Comprehension Tasks\nGen. \nPerformance\n5 Medical Multi-Modal Generation Tasks\nList all anatomical locations showing \npulmonary edema, hazy opacity, or \nmediastinal displacement.\nLeft hilar structures, left lung,\nright hilar structures, right lung.\nWhich abdominal organ shows any \nindication of a lesion or abnormality \nin the CT image?\nNo abdominal organs show\nany clear indications of lesions\nor abnormalities.\nCould you explain what this mass\nin the MRI means for my health? \nIs it very serious?\nCertainly, the MRI shows a\ndefined mass in your left nasal\ncavity. There is no sign of the ...\n4. Microsopy Comprehension\n What is the purpose of the different \nmembrane treatments used in this \nstudy?\nThe purpose of the different\nmembrane treatments used…\n5. OCT Comprehension\n What is the purpose of comparing \nthe OCT structure image and OCTA \nimage with H&E histology?\nTo confirm the histological position\nof the obtained OCT brain images.\n6. Fundus\nComprehension\n What specific findings or pathological \nchanges can be observed in this \nfundus image?\nThe fundus image appears normal with\nno noticeable signs of pathology…\n7. Ultrasound\nComprehension\n What type of imaging technique \nis used in this image?\nThe image is a sagittal gray-\nscale ultrasonographic…\n1. CT2MRI\nGeneration\nI need a version of this CT representation \nin MRI.\nThe image has\nbeen transformed\ninto MRI.\n2. MRI2CT\nGeneration\nTransform the MRI display into a \nCT image.\nHere is the CT\nversion of the\nMRI image.\n3. Image Reconstruction\nReconstruct the following \nmedical images.\nHere is the reconstructed\nmedical image you need.\n4. Super Resolution\nCould you improve the quality\nof this MRI image?\nHere is the image with\nimproved resolution.\n5. Report-to-CXR\nThe X-ray shows no \npleural effusion or \npneumothorax.\nHere is the\nchest X-ray\nimage for\nyou.\nGen. Perf.\nFigure 1: HealthGPT enables medical multi-modal comprehension and generation , outperforming both state-of-the-art\nunified visual models and medical-specific models across various tasks. This highlights its superior capability in tackling com-\nplex tasks in healthcare applications. Comp.Perf. and Gen.Perf. denote the results of comprehension and generation.\nAbstract\nWe present HealthGPT, a powerful Medical Large Vision-\nLanguage Model (Med-LVLM) that integrates medical vi-\nsual comprehension and generation capabilities within a uni-\nfied autoregressive paradigm. Our bootstrapping philosophy\nis to progressively adapt heterogeneous comprehension and\ngeneration knowledge to pre-trained large language mod-\nels (LLMs). This is achieved through a novel heterogeneous\nlow-rank adaptation (H-LoRA) technique, which is com-\nplemented by a tailored hierarchical visual perception ap-\nproach and a three-stage learning strategy. To effectively\nlearn the HealthGPT, we devise a comprehensive medi-\ncal domain-specific comprehension and generation dataset\ncalled VL-Health. Experimental results demonstrate ex-\nceptional performance and scalability of HealthGPT in\nmedical visual unified tasks. Our project can be accessed at\nhttps://github.com/DCDmllm/HealthGPT.\n1 Introduction\nLarge Vision-Language Models (LVLMs) (Liu et al. 2023;\nOpenAI 2023; Liu et al. 2024c; Chen et al. 2024b) have\ndemonstrated outstanding open-world visual comprehension\nand reasoning abilities through language-based interactive\ndialogue over the past years, simultaneously opening up\nnew opportunities for applications in specialized domains.\n1\narXiv:2502.09838v3  [cs.CV]  21 Feb 2025']",Interested individuals are encouraged to visit wso2.com/Asgardeo to create a free account and explore the capabilities available for securing agents and authorizing MCP servers.,single_hop_specific_query_synthesizer
Wht did Xie et al. 2024 contribute to the development of unified LVLMs in medical AI?,"['Specifically, recent studies (Li et al. 2024a; Tu et al. 2024)\nhave utilized pre-trained large language models (LLMs) and\nvisual instruction data to build interactive diagnostic tools\nand treatment planning systems, revealing the immense po-\ntential of LVLMs in medical scenarios. However, these stud-\nies primarily concentrate on visual comprehension tasks that\nproduce text-based outputs, such as medical visual ques-\ntion answering (Li et al. 2024a) or report generation (Nath\net al. 2024), and deficient the “drawing” capability needed\nfor medical visual generation. In practice, integrating visual\ncomprehension and generation can significantly enhance the\nmultifunctionality of medical LVLMs.\nRecent studies have increasingly focused on developing\nunified LVLMs capable of comprehending and generating\ncontent across diverse visual modalities. Earlier approaches\npredominantly utilized continuous visual tokens fed into\nLLMs, using the LLMs themselves as conditional genera-\ntors for external generative models (Ge et al. 2024; Wu et al.\n2023; Dong et al. 2023). More recent research has explored\nthe use of discrete visual tokens for image representation and\ngeneration within a fully autoregressive framework (Team\n2024; Wang et al. 2024a; Xie et al. 2024). These meth-\nods not only enhance controllability but also demonstrate\nearly success in open-world, any-to-any tasks, highlighting\nthe preliminary potential of a unified autoregressive learning\nparadigm in multi-modal tasks.\nWhile unified LVLMs have achieved initial success in\ngeneral scenarios, such a unified framework remains under-\nexplored in the medical domain. Adapting the aforemen-\ntioned general unified model paradigm to the medical do-\nmain presents two major challenges: (i) High-scale and\n-quality Data Limitations . Open-world models necessi-\ntate extensive pre-training on billions or even more diverse,\nmulti-modal data samples for comprehension and genera-\ntion tasks (Lu et al. 2024; Team 2024). However, the ac-\ncessible medical data significantly lacks in scale and qual-\nity compared to natural multi-modal datasets. Its special-\nized and domain-specific characteristics make it challenging\nto develop a unified medical model from scratch. (ii) Con-\nflicts between Comprehension and Generation . Compre-\nhension tasks often strip away visual details to focus on\nabstraction, while generation tasks require detailed preser-\nvation, making tokens sensitive to all visual alterations. As\nshown in Figure 2, which features experiments conducted on\nmedical images, the performance in comprehension (or gen-\neration) tasks steadily decreases as the proportion of genera-\ntion (or comprehension) data increases, and vice versa. This\nhighlights a dilemma in autoregressive multi-modal training,\nstemming from the need to maintain consistency between\npre- and post-LVLMs. While some methods have explored\nmutual enhancement between comprehension and genera-\ntion (Pan et al. 2024; Tong et al. 2024), improvements still\nexhibit diminishing returns, with performance degradation\nremaining a significant issue.\n(a) (b)\nFigure 2: With a fixed amount of comprehension (genera-\ntion) data, increasing the proportion of the other type leads\nto significant performance degradation.\nTo tackle the aforementioned challenges, we propose\nHealthGPT (see Figure 1) , which progressively adapts a\npre-trained LLM as an unified medical multi-modal model\nwith a small amount of visual instruction data. We de-\nvise innovative Parameter-Efficient Fine-Tuning (PEFT) ap-\nproach (Ding et al. 2023), calledHeterogeneous Low-Rank\nAdaptation (H-LoRA), which decouples the learning pro-\ncess of LVLMs for comprehension and generation tasks. In-\nspired by the plug-and-play nature of LoRA (Hu et al. 2021),\nH-LoRA enables the model to store heterogeneous compre-\nhension and generation knowledge in independent “plug-\nins”, thus avoiding joint optimization issues caused by con-\nflicts between comprehension and generation tasks. In addi-\ntion, we also consider the variety of sub-tasks among com-\nprehension or generation tasks. Qualitative research high-\nlights the limitations of a single LoRA in handling multi-\ndimensional task scenarios, mainly due to catastrophic for-\ngetting and interference (Liu et al. 2024d; Lin et al. 2024).\nTo address this, we draw on the concept of Mixture of Ex-\nperts (MoE) (Masoudnia and Ebrahimpour 2014) and in-\ntroduce LoRA experts. The aim is to dynamically transfer\ntask-shared knowledge to adapt to downstream tasks. Unlike\nMoELoRA (Luo et al. 2024a), H-LoRA employs reversible\nmatrix block multiplication to combine LoRA experts, sig-\nnificantly reducing the overhead of multiple matrix multi-\nplications. Notably, when using four experts, it requires\nonly 67% of the MoELoRA training time.\nTo effectively leverage H-LoRA inHealthGPT, we fur-\nther introduce a Hierarchical Visual Perception (HVP)\nand devise a correspondingThree-stage Learning Strategy\n(TLS). HVP: we separate visual details learning from Vi-\nsion transformer (ViT) for comprehension and generation.\nAs is widely recognized, the ViT encodes visual concepts\nwith increasing abstraction, generally, becoming finer as we\nprogress over levels (Vig 2019). Thus, we maintain the vi-\nsual features of the anterior and posterior layers to accom-\nmodate the differing requirements for visual granularity in\ncomprehension and generation tasks while preventing po-\n2']","Xie et al. 2024 explored the use of discrete visual tokens for image representation and generation within a fully autoregressive framework. Their methods enhance controllability and demonstrate early success in open-world, any-to-any tasks, highlighting the preliminary potential of a unified autoregressive learning paradigm in multi-modal tasks.",single_hop_specific_query_synthesizer
How does HealthGPT enhance medical vision-language comprehension and generation tasks?,"['tential task interference. TLS: In the first and second stages,\ngiven the heterogeneity between comprehension and gener-\nation tasks, we first train H-LoRA plugins for HealthGPT\nto incorporate both medical comprehension and generation\nknowledge, thus endowing the LLMs with capabilities for\nvision-language alignment and vision-to-vision reconstruc-\ntion. Additionally, through minimal mixed-task training, we\nbuilt fusion embedding layers and output heads that merge\ntext and visual tokens, establishing a unified LVLM founda-\ntion for visual instruction fine-tuning. In the third stage, by\nonly training the H-LoRA plugins, HealthGPT is able to\nrapidly adapt to a wide range of downstream medical tasks,\ncovering various types of medical comprehension and gen-\neration tasks.\nTo effectively implement our approach, we have cu-\nrated a dataset for training unified medical LVLMs, called\nVL-Health, including seven comprehension tasks and five\ngeneration tasks (Figure 1). Through quantitative analysis\nand validation on multi-modal tasks, the results demonstrate\nthat HealthGPT is capable of unifying medical multi-\nmodal abilities in data-constrained scenarios, achieving per-\nformance comparable to or better than existing state-of-the-\nart (SOTA) models across multiple metrics. Overall, the\nmain contributions of this paper are summarized as follows:\n• Unified Med-LVLM. We introduce HealthGPT,\nwhich, to the best of our knowledge, is the first unified\nframework for multi-modal comprehension and genera-\ntion in complex medical scenarios.\n• Effective Learning Paradigm. We present H-LoRA, an\noptimized multi-LoRA PEFT architecture based on task-\ngated decoupling, is designed to effectively mitigate data\nconflict issues.\n• Holistic Training Dataset. We curated VL-Health, a\ncomprehensive dataset designed for both comprehension\nand generation tasks.\n• Superior Downstream Improvements : Extensive ex-\nperiments are conducted and the results confirm\nHealthGPT’s effectiveness in medical vision-language\ncomprehension and generation.\n2 Related Work\nMedical Vision Large Language Models. Recently, medi-\ncal vision large language models (Med-VLLMs) have made\nsignificant progress, demonstrating excellent performance\nin understanding medical images and responding to human\nqueries based on these images (Zhou et al. 2023; Tian et al.\n2023). XrayGPT (Thawkar et al. 2023) combines a med-\nical visual encoder (MedClip) (Wang et al. 2022) with a\nfine-tuned LLM , using a simple linear transformation layer\nto achieve alignment between visual and textual informa-\ntion, significantly enhancing the understanding of medical\nimages. On this basis, LLaV A-Med (Li et al. 2024b) fur-\nther enhances visual-text alignment in medical contexts by\nselecting high-quality image-text pairs from PubMed pa-\npers and synthesized VQA datasets. BiomedGPT (Luo et al.\n2024b) employs a BERT-style encoder and GPT-style de-\ncoder architecture, pre-trained on interdisciplinary datasets.\nCompared to commercial models like Med-PaLM (Singhal\net al. 2023), BiomedGPT significantly reduces model size\nwhile maintaining superior performance. However, issues\nof language adaptability and dataset specificity still remain.\nTo address these, HuatuoGPT-Vision (Chen et al. 2024a)\nintroduces the PubMedVision dataset, which contains 1.3\nmillion high-quality medical samples, significantly improv-\ning the model’s adaptability across diverse medical applica-\ntions. However, current Med-VLLMs mainly focus on med-\nical comprehension and lack the capability for the medical\nvision-language generation.\nUnified Visual Comprehension and Generation Mod-\nels. Recent research has increasingly concentrated on cre-\nating unified LVLMs that are adept at understanding and\nproducing content across various visual modalities. NExT-\nGPT (Wu et al. 2023) achieves perception and generation for\narbitrary combinations of multi-modal inputs and outputs by\naligning LLMs. Similarly, SEED (Ge et al. 2023), SEED-\nX (Ge et al. 2024), and DreamLLM (Dong et al. 2023) em-\nploy learnable queries and leverage next-token prediction to\ngenerate visual tokens, providing conditional inputs to exter-\nnal generation modules. Unlike these methods, which func-\ntion as external conditioners, Unified-IO (Lu et al. 2022),\nUnified-IO 2 (Lu et al. 2024), and Chameleon (Team 2024)\ninternalize multi-modal generation tasks within a unified\nTransformer architecture by extending multi-modal vocab-\nularies, enabling direct generation based on next-token pre-\ndiction. Building on this concept, Lumina-mGPT (Liu et al.\n2024a) and ANOLE (Chern et al. 2024) further enhance the\ngeneration capabilities of unified models using high-quality\ndata, particularly improving the quality and flexibility of im-\nage generation.\n3 Preliminaries\nLarge Vision-Language Models.The input to a LVLM typ-\nically consists of an image ximg and a discrete text sequence\nxtxt. The visual encoder Eimg converts the input image ximg\ninto a sequence of visual tokens V = [ vi]Nv\ni=1, while the\ntext sequence xtxt is mapped into a sequence of text to-\nkens T = [ ti]Nt\ni=1 using an embedding function Etxt. The\nLLM MLLM(·|θ) models the joint probability of the token\nsequence U = {V, T }, which is expressed as:\nPθ(R|U) =\nNrY\ni=1\nPθ(ri|{U, r<i}), (1)\nwhere R = [ri]Nr\ni=1 is the text response sequence. The LVLM\niteratively generates the next token ri based on r<i. The op-\ntimization objective is to minimize the cross-entropy loss of\nthe response R. It is worth noting that most LVLMs adopt\n3']","HealthGPT enhances medical vision-language comprehension and generation tasks by incorporating H-LoRA plugins to integrate both medical comprehension and generation knowledge, enabling vision-language alignment and vision-to-vision reconstruction. It also employs minimal mixed-task training to build fusion embedding layers and output heads that merge text and visual tokens, creating a unified LVLM foundation for visual instruction fine-tuning. This approach allows HealthGPT to rapidly adapt to a wide range of downstream medical tasks, achieving performance comparable to or better than existing state-of-the-art models across multiple metrics.",single_hop_specific_query_synthesizer
How does Rombach's work on VQGAN contribute to the HealthGPT architecture in terms of image generation?,"['Figure 3: The HealthGPT architecture integrates hierarchical visual perception and H-LoRA, employing a task-specific hard\nrouter to select visual features and H-LoRA plugins, ultimately generating outputs with an autoregressive manner.\na design paradigm based on ViT, alignment adapters, and\npre-trained LLMs(Liu et al. 2023, 2024b), enabling quick\nadaptation to downstream tasks.\nVQGAN. VQGAN (Esser, Rombach, and Ommer 2021)\nemploys latent space compression and indexing mechanisms\nto effectively learn a complete discrete representation of im-\nages. VQGAN first maps the input imageximg to a latent rep-\nresentation z = E(x) through a encoder E. Then, the latent\nrepresentation is quantized using a codebookZ = {zk}K\nk=1,\ngenerating a discrete index sequence I = [im]N\nm=1, where\nim ∈ Zrepresents the quantized code index:\nI = Quantize(z|Z) = arg min\nzk∈Z\n∥z − zk∥2. (2)\nIn our approach, the discrete index sequence I serves as\na supervisory signal for the generation task, enabling the\nmodel to predict the index sequence ˆI from input conditions\nsuch as text or other modality signals. Finally, the predicted\nindex sequence ˆI is upsampled by the VQGAN decoder G,\ngenerating the high-quality image ˆximg = G(ˆI).\nLow Rank Adaptation. LoRA(Hu et al. 2021) effectively\ncaptures the characteristics of downstream tasks by intro-\nducing low-rank adapters. The core idea is to decompose\nthe bypass weight matrix ∆W ∈ Rdin×dout\ninto two low-\nrank matrices {A ∈ Rdin×r, B ∈ Rr×dout\n}, where r ≪\nmin{din, dout}, significantly reducing learnable parameters.\nThe output with the LoRA adapter for the input x is then\ngiven by:\nh = xW0 + αx∆W/r = xW0 + αxAB/r, (3)\nwhere matrix A is initialized with a Gaussian distribution,\nwhile the matrixB is initialized as a zero matrix. The scaling\nfactor α/r controls the impact of ∆W on the model.\n4 HealthGPT\n4.1 Unified Autoregressive Generation.\nHealthGPT (Figure 3) utilizes a discrete token representa-\ntion that covers both text and visual outputs, unifying visual\ncomprehension and generation as an autoregressive task. For\ncomprehension, Mllm receives the input joint sequence U\nand outputs a series of text token R = [ r1, r2, . . . , rNr ],\nwhere ri ∈ Vtxt, and Vtxt represents the LLM’s vocabulary:\nPθ(R | U) =\nNrY\ni=1\nPθ(ri | U, r<i). (4)\nFor generation, Mllm first receives a special start token\n⟨START IMG⟩, then generates a series of tokens corre-\nsponding to the VQGAN indices I = [ i1, i2, . . . , iNi ],\nwhere ij ∈ Vvq, and Vvq represents the index range of VQ-\nGAN. Upon completion of generation, the LLM outputs an\nend token ⟨END IMG⟩:\nPθ(I | U) =\nNiY\nj=1\nPθ(ij | U, i<j). (5)\nFinally, the generated index sequence I is fed into the de-\ncoder G, which reconstructs the target image ˆximg = G(I).\n4.2 Hierarchical Visual Perception\nGiven the differences in visual perception between compre-\nhension and generation tasks—where the former focuses on\nabstract semantics and the latter emphasizes complete se-\nmantics—we employ ViT to compress the image into dis-\ncrete visual tokens at multiple hierarchical levels. Specif-\nically, the image is converted into a series of features\n{f1, f2, . . . , fL} as it passes through L ViT blocks.\n4']","Rombach's work on VQGAN contributes to the HealthGPT architecture by employing latent space compression and indexing mechanisms to learn a complete discrete representation of images. In the HealthGPT architecture, the discrete index sequence generated by VQGAN serves as a supervisory signal for the generation task, enabling the model to predict the index sequence from input conditions such as text or other modality signals. The predicted index sequence is then upsampled by the VQGAN decoder, generating the high-quality image.",single_hop_specific_query_synthesizer
Waht is LLM used for in this context?,"['To address the needs of various tasks, the hidden states\nare divided into two types: (i) Concrete-grained features\nFCon = {f1, f2, . . . , fk}, k < L, derived from the shal-\nlower layers of ViT, containing sufficient global features,\nsuitable for generation tasks; (ii) Abstract-grained features\nFAbs = {fk+1, fk+2, . . . , fL}, derived from the deeper\nlayers of ViT, which contain abstract semantic information\ncloser to the text space, suitable for comprehension tasks.\nThe task type T (comprehension or generation) deter-\nmines which set of features is selected as the input for the\ndownstream large language model:\nFimg\nT =\n(\nFCon, if T = generation task\nFAbs, if T = comprehension task (6)\nWe integrate the image featuresFimg\nT and text featuresT into\na joint sequence through simple concatenation, which is then\nfed into the LLM Mllm for autoregressive generation.\n4.3 Heterogeneous Knowledge Adaptation\nWe devise H-LoRA, which stores heterogeneous knowledge\nfrom comprehension and generation tasks in separate mod-\nules and dynamically routes to extract task-relevant knowl-\nedge from these modules. At the task level, for each task type\nT, we dynamically assign a dedicated H-LoRA submodule\nθT , which is expressed as:\nR = MLLM(U|θ, θT ), θ T = {AT , BT , RT\nouter}. (7)\nAt the feature level for a single task, H-LoRA integrates the\nidea of Mixture of Experts (MoE) (Masoudnia and Ebrahim-\npour 2014) and designs an efficient matrix merging and rout-\ning weight allocation mechanism, thus avoiding the signif-\nicant computational delay introduced by matrix splitting in\nexisting MoELoRA (Luo et al. 2024a). Specifically, we first\nmerge the low-rank matrices (rank = r) of k LoRA experts\ninto a unified matrix:\nAmerged, Bmerged = Concat({Ai}k\n1 ), Concat({Bi}k\n1 ), (8)\nwhere Amerged ∈ Rdin×rk and Bmerged ∈ Rrk×dout\n. The\nk-dimension routing layer generates expert weights W ∈\nRtoken num×k based on the input hidden state x, and these are\nexpanded to Rtoken num×rk as follows:\nWexpanded = αkW/r ⊗ 1r, (9)\nwhere ⊗ denotes the replication operation. The overall out-\nput of H-LoRA is computed as:\nOH-LoRA = (xAmerged ⊙ Wexpanded)Bmerged, (10)\nwhere ⊙ represents element-wise multiplication. Finally, the\noutput of H-LoRA is added to the frozen pre-trained weights\nto produce the final output:\nO = xW0 + OH-LoRA. (11)\n900\n800\n700\n600\n500\n400\n300\n200\n100\n0\nComp. Gen.\n(a) (b)\n783K765K\n（K）\nFigure 4: Data statistics of VL-Health.\n4.4 Training Pipeline\n1st Stage: Multi-modal Alignment. In the first stage, we\ndesign separate visual adapters and H-LoRA submodules for\nmedical unified tasks. For the medical comprehension task,\nwe train abstract-grained visual adapters using high-quality\nimage-text pairs to align visual embeddings with textual\nembeddings, thereby enabling the model to accurately de-\nscribe medical visual content. During this process, the pre-\ntrained LLM and its corresponding H-LoRA submodules\nremain frozen. In contrast, the medical generation task re-\nquires training concrete-grained adapters and H-LoRA sub-\nmodules while keeping the LLM frozen. Meanwhile, we ex-\ntend the textual vocabulary to include multimodal tokens,\nenabling the support of additional VQGAN vector quanti-\nzation indices. The model trains on image-VQ pairs, en-\ndowing the pre-trained LLM with the capability for image\nreconstruction. This design ensures pixel-level consistency\nof pre- and post-LVLM. The processes establish the initial\nalignment between the LLM’s outputs and the visual inputs.\n2nd Stage: Heterogeneous H-LoRA Plugin Adaptation.\nThe submodules of H-LoRA share the word embedding\nlayer and output head but may encounter issues such as\nbias and scale inconsistencies during training across dif-\nferent tasks. To ensure that the multiple H-LoRA plugins\nseamlessly interface with the LLMs and form a unified base,\nwe fine-tune the word embedding layer and output head us-\ning a small amount of mixed data to maintain consistency\nin the model weights. Specifically, during this stage, all H-\nLoRA submodules for different tasks are kept frozen, with\nonly the word embedding layer and output head being op-\ntimized. Through this stage, the model accumulates foun-\ndational knowledge for unified tasks by adapting H-LoRA\nplugins.\n3rd Stage: Visual Instruction Fine-Tuning. In the third\nstage, we introduce additional task-specific data to fur-\nther optimize the model and enhance its adaptability to\ndownstream tasks such as medical visual comprehension\n(e.g., medical QA, medical dialogues, and report generation)\nor generation tasks (e.g., super-resolution, denoising, and\n5']","In this context, the LLM is used for autoregressive generation by integrating image features and text features into a joint sequence.",single_hop_specific_query_synthesizer
How Yi-VL do in medical visual comprehension tasks?,"['Table 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","Yi-VL, with 6 billion parameters, achieved scores of 52.6 on VQA-RAD, 42.1 on SLAKE, 52.4 on PathVQA, 38.4 on MMMU-Med, 54.9 on OMVQA, and an average score of 44.9 in medical visual comprehension tasks.",single_hop_specific_query_synthesizer
What LoRA do?,"['Table 3: Comparison results of super-resolution task.\nModel SSIM↑ PSNR↑ MSE↓ LPIPS↓\nSRGAN 71.34 32.01 41.27 24.50\nDASR 71.57 32.34 38.25 19.17\nReal-ESRGAN 67.30 31.87 42.57 20.64\nLIIF 73.27 32.13 40.14 22.93\nBSRGAN 69.97 31.97 41.52 28.72\nHealthGPT-M3 78.19 32.76 34.47 12.02\nHealthGPT-L14 77.94 32.71 35.19 12.43\nFigure 5: Performance comparison of LoRA, MoELoRA,\nand H-LoRA under different rank settings.\net al. 2024b), Llama-3.2 (Dubey et al. 2024)). Addition-\nally, we test several SOTA unified visual comprehension\nand generation models, including Show-o (Xie et al. 2024),\nUnified-IO 2 (Lu et al. 2024), and Janus (Wu et al.\n2024). The experimental results are shown in Table 1, with\nthe following key observations: (i) SOTA Results Com-\npared with LVLMs: In medical visual comprehension\ntasks, HealthGPT demonstrates superior performance,\nsignificantly outperforming both medical-specific models\n(e.g., HuatuoGPT-Vision) and general-purpose models (e.g.,\nLlama-3.2). (ii) Surpassing Current Unified LVLMs: De-\nspite being trained on billions of data points, unified mod-\nels still exhibit poor generalization performance in medi-\ncal visual comprehension. For instance, Unified-IO 2 scored\nonly 33.8. In contrast,HealthGPT-M3, with only 3.8B pa-\nrameters, scored 61.3 on the medical multi-modal unified\ntask, significantly outperforming existing unified models in\nmedical downstream scenarios. (iii) Stable Improvement\nwith Large Base Model: Our method demonstrates excel-\nlent scalability, with HealthGPT-L14 achieving a score\nof 66.4 in the larger model configuration. This result signif-\nicantly outperforms all other models, highlighting the effec-\ntiveness of scaling up the base model for enhanced perfor-\nmance in medical tasks.\nGeneration. We study three key tasks in medical imag-\ning. (i) Modality Conversion: In this task, we focus on\nthe conversion between CT and MRI modalities for the\nbrain and pelvic regions, designing four specific sub-tasks.\nAll comparative models (Pix2Pix (Isola et al. 2017), Cy-\ncleGAN (Zhu et al. 2017), BBDM (Li et al. 2023a),\n(%)\n(%)\n（a） （b）\nFigure 6: The loss visualization (a) and performance com-\nparison (b) with respect to different visual perceptions.\nVmamba (Liu et al. 2024e), and DiffMa (Wang et al.\n2024b)) trained a separate model for each sub-task, while\nHealthGPT unify all tasks into a single training process.\nThe experimental results, shown in Table 11, demonstrate\nthat our approach outperforms other methods across multi-\nple evaluation metrics. For instance, in the CT2MRI-Brain\ntask, HealthGPT-M3 achieves an SSIM of 79.38, signif-\nicantly surpassing traditional methods like Pix2Pix (71.09)\nand the recent DiffMa (71.47). (ii) Super-Resolution: We\nconduct 4× super-resolution experiments on the IXI dataset,\nwith the results presented in Table 3. Notably, most exist-\ning methods fail to fully leverage the prior knowledge of key\nstructures in medical images, resulting in significant short-\ncomings in detail recovery. In contrast, our method signif-\nicantly mitigates this issue. Specifically, HealthGPT-M3\nexcels in key metrics such as SSIM, PSNR, and ISE, achiev-\ning scores of 78.19, 32.76, and 34.47, respectively. Ad-\nditionally, HealthGPT-M3 achieves the lowest score of\n12.34, further validating its exceptional performance in hu-\nman visual perception. (iii) Reconstruction: We compare\nHealthGPT-M3 with unified models with reconstruction\ncapabilities, such as Unified-IO 2 and SEED-X. The results\nshow that our approach performs better controllability for vi-\nsual reconstruction. We also trainHealthGPT-L14 with a\nsimilar number of trainable parameters to the M3 version.\nHence, the similar performance between the two models\nmeets our expectations. Details are in the Appendix.\n5.3 In-Depth Study\nEffect of Heterogeneous Low-Rank Adaptation.H-LoRA\nprovides an optimized multi-LoRA architecture for multi-\ntask learning. We conduct extensive validation of this struc-\nture, with results presented in Table 4, comparing the per-\nformance of LoRA, MoELoRA, and H-LoRA in medical\nunified comprehension and generation tasks. In the majority\nof comprehension tasks and all generation tasks, H-LoRA\ndemonstrates superior performance, particularly in the Om-\nniMedVQA benchmark, where it improved from 64.90 to\n68.50. Notably, despite some applications of MoELoRA in\ncertain scenarios, it do not show advantages in this task and\n7']","LoRA provides an optimized multi-LoRA architecture for multi-task learning, demonstrating superior performance in the majority of comprehension tasks and all generation tasks, particularly in the OmniMedVQA benchmark.",single_hop_specific_query_synthesizer
How does PathVQA perform in medical visual comprehension tasks when using different training strategies?,"['Table 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8']","PathVQA shows improved performance in medical visual comprehension tasks when using the H-LoRA-based Three-Stage Learning Strategy compared to the mixed-training approach. Specifically, the Three-Stage Learning Strategy achieves a score of 77.9, whereas the mixed-training approach scores 45.0.",single_hop_specific_query_synthesizer
"Who is Kyung, D. and what did they work on?","['tions.\nReferences\nAbdin, M.; Aneja, J.; Behl, H.; Bubeck, S.; Eldan, R.; Gu-\nnasekar, S.; Harrison, M.; Hewett, R. J.; Javaheripi, M.;\nKauffmann, P.; et al. 2024. Phi-4 technical report. arXiv\npreprint arXiv:2412.08905.\nBae, S.; Kyung, D.; Ryu, J.; Cho, E.; Lee, G.; Kweon, S.;\nOh, J.; JI, L.; Chang, E.; Kim, T.; et al. 2024. MIMIC-Ext-\nMIMIC-CXR-VQA: A Complex, Diverse, And Large-Scale\nVisual Question Answering Dataset for Chest X-ray Images.\nChen, J.; Gui, C.; Ouyang, R.; Gao, A.; Chen, S.; Chen,\nG. H.; Wang, X.; Zhang, R.; Cai, Z.; Ji, K.; et al.\n2024a. Huatuogpt-vision, towards injecting medical visual\nknowledge into multimodal llms at scale. arXiv preprint\narXiv:2406.19280.\nChen, Z.; Wang, W.; Tian, H.; Ye, S.; Gao, Z.; Cui, E.; Tong,\nW.; Hu, K.; Luo, J.; Ma, Z.; et al. 2024b. How far are we to\ngpt-4v? closing the gap to commercial multimodal models\nwith open-source suites. arXiv preprint arXiv:2404.16821.\nChern, E.; Su, J.; Ma, Y .; and Liu, P. 2024. Anole:\nAn open, autoregressive, native large multimodal mod-\nels for interleaved image-text generation. arXiv preprint\narXiv:2407.06135.\nDai, W.; Li, J.; Li, D.; Tiong, A. M. H.; Zhao, J.; Wang, W.;\nLi, B.; Fung, P.; and Hoi, S. 2023. InstructBLIP: Towards\nGeneral-purpose Vision-Language Models with Instruction\nTuning. arXiv:2305.06500.\nDavies, R. L.; Royston, P. A.; Leung, M. S.; Haider, M. E.\nA. M. J.; Barkhof, S. G. A. L.; and B., P. E. T. M. 2014. The\nIXI Dataset. Accessed: 2025-01-30.\nDing, N.; Qin, Y .; Yang, G.; Wei, F.; Yang, Z.; Su, Y .;\nHu, S.; Chen, Y .; Chan, C.-M.; Chen, W.; et al. 2023.\nParameter-efficient fine-tuning of large-scale pre-trained\nlanguage models. Nature Machine Intelligence, 5(3): 220–\n235.\nDong, R.; Han, C.; Peng, Y .; Qi, Z.; Ge, Z.; Yang, J.; Zhao,\nL.; Sun, J.; Zhou, H.; Wei, H.; et al. 2023. Dreamllm:\nSynergistic multimodal comprehension and creation. arXiv\npreprint arXiv:2309.11499.\nDubey, A.; Jauhri, A.; Pandey, A.; Kadian, A.; Al-Dahle, A.;\nLetman, A.; Mathur, A.; Schelten, A.; Yang, A.; Fan, A.;\net al. 2024. The llama 3 herd of models. arXiv preprint\narXiv:2407.21783.\nEsser, P.; Rombach, R.; and Ommer, B. 2021. Taming trans-\nformers for high-resolution image synthesis. In Proceedings\nof the IEEE/CVF conference on computer vision and pattern\nrecognition, 12873–12883.\nGe, Y .; Ge, Y .; Zeng, Z.; Wang, X.; and Shan, Y . 2023. Plant-\ning a seed of vision in large language model. arXiv preprint\narXiv:2307.08041.\nGe, Y .; Zhao, S.; Zhu, J.; Ge, Y .; Yi, K.; Song, L.; Li, C.;\nDing, X.; and Shan, Y . 2024. Seed-x: Multimodal models\nwith unified multi-granularity comprehension and genera-\ntion. arXiv preprint arXiv:2404.14396.\nHe, X.; Zhang, Y .; Mou, L.; Xing, E.; and Xie, P. 2020.\nPathvqa: 30000+ questions for medical visual question an-\nswering. arXiv preprint arXiv:2003.10286.\nHu, E. J.; Shen, Y .; Wallis, P.; Allen-Zhu, Z.; Li, Y .; Wang,\nS.; Wang, L.; and Chen, W. 2021. Lora: Low-rank adaptation\nof large language models. arXiv preprint arXiv:2106.09685.\nHu, Y .; Li, T.; Lu, Q.; Shao, W.; He, J.; Qiao, Y .; and Luo,\nP. 2024. Omnimedvqa: A new large-scale comprehensive\nevaluation benchmark for medical lvlm. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 22170–22183.\nIsola, P.; Zhu, J.-Y .; Zhou, T.; and Efros, A. A. 2017. Image-\nto-image translation with conditional adversarial networks.\nIn Proceedings of the IEEE conference on computer vision\nand pattern recognition, 1125–1134.\nJohnson, A. E.; Pollard, T. J.; Greenbaum, N. R.; Lungren,\nM. P.; Deng, C.-y.; Peng, Y .; Lu, Z.; Mark, R. G.; Berkowitz,\nS. J.; and Horng, S. 2019. MIMIC-CXR-JPG, a large pub-\nlicly available database of labeled chest radiographs. arXiv\npreprint arXiv:1901.07042.\nLau, J. J.; Gayen, S.; Ben Abacha, A.; and Demner-\nFushman, D. 2018. A dataset of clinically generated visual\nquestions and answers about radiology images. Scientific\ndata, 5(1): 1–10.\nLi, B.; Xue, K.; Liu, B.; and Lai, Y .-K. 2023a. Bbdm: Image-\nto-image translation with brownian bridge diffusion models.\nIn Proceedings of the IEEE/CVF conference on computer\nvision and pattern Recognition, 1952–1961.\nLi, C.; Wong, C.; Zhang, S.; Usuyama, N.; Liu, H.; Yang,\nJ.; Naumann, T.; Poon, H.; and Gao, J. 2024a. Llava-\nmed: Training a large language-and-vision assistant for\nbiomedicine in one day. Advances in Neural Information\nProcessing Systems, 36.\nLi, C.; Wong, C.; Zhang, S.; Usuyama, N.; Liu, H.; Yang,\nJ.; Naumann, T.; Poon, H.; and Gao, J. 2024b. Llava-\nmed: Training a large language-and-vision assistant for\nbiomedicine in one day. Advances in Neural Information\nProcessing Systems, 36.\nLi, J.; Li, D.; Savarese, S.; and Hoi, S. 2023b. Blip-2:\nBootstrapping language-image pre-training with frozen im-\nage encoders and large language models. In International\nconference on machine learning, 19730–19742. PMLR.\nLin, T.; Liu, J.; Zhang, W.; Li, Z.; Dai, Y .; Li, H.; Yu, Z.; He,\nW.; Li, J.; Jiang, H.; et al. 2024. Teamlora: Boosting low-\nrank adaptation with expert collaboration and competition.\narXiv preprint arXiv:2408.09856.\n9']","Kyung, D. is an author who worked on the MIMIC-Ext-MIMIC-CXR-VQA, a complex, diverse, and large-scale visual question answering dataset for chest X-ray images.",single_hop_specific_query_synthesizer
"What is the contribution of Liu, B. in the field of medical visual question answering?","['Liu, B.; Zhan, L.-M.; Xu, L.; Ma, L.; Yang, Y .; and Wu,\nX.-M. 2021. Slake: A semantically-labeled knowledge-\nenhanced dataset for medical visual question answering. In\n2021 IEEE 18th International Symposium on Biomedical\nImaging (ISBI), 1650–1654. IEEE.\nLiu, D.; Zhao, S.; Zhuo, L.; Lin, W.; Qiao, Y .; Li, H.; and\nGao, P. 2024a. Lumina-mgpt: Illuminate flexible photore-\nalistic text-to-image generation with multimodal generative\npretraining. arXiv preprint arXiv:2408.02657.\nLiu, H.; Li, C.; Li, Y .; and Lee, Y . J. 2024b. Improved\nbaselines with visual instruction tuning. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 26296–26306.\nLiu, H.; Li, C.; Li, Y .; Li, B.; Zhang, Y .; Shen, S.; and Lee,\nY . J. 2024c. LLaV A-NeXT: Improved reasoning, OCR, and\nworld knowledge. https://llava-vl.github.io/blog/2024-01-\n30-llava-next/.\nLiu, H.; Li, C.; Wu, Q.; and Lee, Y . J. 2023. Visual Instruc-\ntion Tuning. In NeurIPS.\nLiu, Q.; Wu, X.; Zhao, X.; Zhu, Y .; Xu, D.; Tian, F.; and\nZheng, Y . 2024d. When moe meets llms: Parameter efficient\nfine-tuning for multi-task medical applications. In Proceed-\nings of the 47th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval, 1104–\n1114.\nLiu, Y .; Tian, Y .; Zhao, Y .; Yu, H.; Xie, L.; Wang, Y .; Ye,\nQ.; and Liu, Y . 2024e. VMamba: Visual State Space Model.\narXiv preprint arXiv:2401.10166.\nLu, J.; Clark, C.; Lee, S.; Zhang, Z.; Khosla, S.; Marten, R.;\nHoiem, D.; and Kembhavi, A. 2024. Unified-IO 2: Scaling\nAutoregressive Multimodal Models with Vision Language\nAudio and Action. In Proceedings of the IEEE/CVF Confer-\nence on Computer Vision and Pattern Recognition , 26439–\n26455.\nLu, J.; Clark, C.; Zellers, R.; Mottaghi, R.; and Kembhavi,\nA. 2022. Unified-io: A unified model for vision, language,\nand multi-modal tasks. In The Eleventh International Con-\nference on Learning Representations.\nLuo, T.; Lei, J.; Lei, F.; Liu, W.; He, S.; Zhao, J.; and Liu,\nK. 2024a. Moelora: Contrastive learning guided mixture of\nexperts on parameter-efficient fine-tuning for large language\nmodels. arXiv preprint arXiv:2402.12851.\nLuo, Y .; Zhang, J.; Fan, S.; Yang, K.; Hong, M.; Wu, Y .;\nQiao, M.; and Nie, Z. 2024b. Biomedgpt: An open multi-\nmodal large language model for biomedicine. IEEE Journal\nof Biomedical and Health Informatics.\nMasoudnia, S.; and Ebrahimpour, R. 2014. Mixture of ex-\nperts: a literature survey. Artificial Intelligence Review, 42:\n275–293.\nMoor, M.; Huang, Q.; Wu, S.; Yasunaga, M.; Dalmia, Y .;\nLeskovec, J.; Zakka, C.; Reis, E. P.; and Rajpurkar, P. 2023.\nMed-flamingo: a multimodal medical few-shot learner. In\nMachine Learning for Health (ML4H), 353–367. PMLR.\nNath, V .; Li, W.; Yang, D.; Myronenko, A.; Zheng, M.; Lu,\nY .; Liu, Z.; Yin, H.; Law, Y . M.; Tang, Y .; et al. 2024. Vila-\nm3: Enhancing vision-language models with medical expert\nknowledge. arXiv preprint arXiv:2411.12915.\nOpenAI. 2023. GPT-4V(ision) System Card. https://cdn.\nopenai.com/papers/GPTV System Card.pdf.\nPan, K.; Tang, S.; Li, J.; Fan, Z.; Chow, W.; Yan, S.;\nChua, T.-S.; Zhuang, Y .; and Zhang, H. 2024. Auto-\nEncoding Morph-Tokens for Multimodal LLM. arXiv\npreprint arXiv:2405.01926.\nRadford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.;\nAgarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;\net al. 2021. Learning transferable visual models from nat-\nural language supervision. In International conference on\nmachine learning, 8748–8763. PMLR.\nSinghal, K.; Azizi, S.; Tu, T.; Mahdavi, S. S.; Wei, J.; Chung,\nH. W.; Scales, N.; Tanwani, A.; Cole-Lewis, H.; Pfohl, S.;\net al. 2023. Large language models encode clinical knowl-\nedge. Nature, 620(7972): 172–180.\nTeam, C. 2024. Chameleon: Mixed-modal early-fusion\nfoundation models. arXiv preprint arXiv:2405.09818.\nThawkar, O.; Shaker, A.; Mullappilly, S. S.; Cholakkal,\nH.; Anwer, R. M.; Khan, S.; Laaksonen, J.; and Khan,\nF. S. 2023. Xraygpt: Chest radiographs summarization\nusing medical vision-language models. arXiv preprint\narXiv:2306.07971.\nThummerer, A.; van der Bijl, E.; Galapon Jr, A.; Verhoeff,\nJ. J.; Langendijk, J. A.; Both, S.; van den Berg, C. N. A.;\nand Maspero, M. 2023. SynthRAD2023 Grand Challenge\ndataset: Generating synthetic CT for radiotherapy. Medical\nphysics, 50(7): 4664–4674.\nTian, D.; Jiang, S.; Zhang, L.; Lu, X.; and Xu, Y . 2023. The\nrole of large language models in medical image processing:\na narrative review. Quantitative Imaging in Medicine and\nSurgery, 14(1): 1108.\nTong, S.; Fan, D.; Zhu, J.; Xiong, Y .; Chen, X.; Sinha, K.;\nRabbat, M.; LeCun, Y .; Xie, S.; and Liu, Z. 2024. Meta-\nMorph: Multimodal Understanding and Generation via In-\nstruction Tuning. arXiv preprint arXiv:2412.14164.\nTu, T.; Azizi, S.; Driess, D.; Schaekermann, M.; Amin, M.;\nChang, P.-C.; Carroll, A.; Lau, C.; Tanno, R.; Ktena, I.; et al.\n2024. Towards generalist biomedical AI. NEJM AI, 1(3):\nAIoa2300138.\nVig, J. 2019. A multiscale visualization of attention in the\ntransformer model. arXiv preprint arXiv:1906.05714.\nWang, X.; Zhang, X.; Luo, Z.; Sun, Q.; Cui, Y .; Wang, J.;\nZhang, F.; Wang, Y .; Li, Z.; Yu, Q.; et al. 2024a. Emu3:\nNext-token prediction is all you need. arXiv preprint\narXiv:2409.18869.\n10']","Liu, B. contributed to the field of medical visual question answering by co-authoring the paper titled 'Slake: A semantically-labeled knowledge-enhanced dataset for medical visual question answering,' presented at the 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI).",single_hop_specific_query_synthesizer
"What contribution did Ma, Y. make in the field of multimodal understanding and generation?","['Wang, Z.; Wu, Z.; Agarwal, D.; and Sun, J. 2022. Medclip:\nContrastive learning from unpaired medical images and text.\narXiv preprint arXiv:2210.10163.\nWang, Z.; Zhang, L.; Wang, L.; and Zhang, Z. 2024b. Soft\nMasked Mamba Diffusion Model for CT to MRI Conver-\nsion. arXiv preprint arXiv:2406.15910.\nWu, C.; Chen, X.; Wu, Z.; Ma, Y .; Liu, X.; Pan, Z.; Liu, W.;\nXie, Z.; Yu, X.; Ruan, C.; and Luo, P. 2024. Janus: Decou-\npling Visual Encoding for Unified Multimodal Understand-\ning and Generation. arXiv:2410.13848.\nWu, S.; Fei, H.; Qu, L.; Ji, W.; and Chua, T.-S. 2023.\nNext-gpt: Any-to-any multimodal llm. arXiv preprint\narXiv:2309.05519.\nXie, J.; Mao, W.; Bai, Z.; Zhang, D. J.; Wang, W.; Lin, K. Q.;\nGu, Y .; Chen, Z.; Yang, Z.; and Shou, M. Z. 2024. Show-o:\nOne single transformer to unify multimodal understanding\nand generation. arXiv preprint arXiv:2408.12528.\nYoung, A.; Chen, B.; Li, C.; Huang, C.; Zhang, G.; Zhang,\nG.; Li, H.; Zhu, J.; Chen, J.; Chang, J.; et al. 2024.\nYi: Open foundation models by 01. ai. arXiv preprint\narXiv:2403.04652.\nZhou, H.; Liu, F.; Gu, B.; Zou, X.; Huang, J.; Wu, J.; Li,\nY .; Chen, S. S.; Zhou, P.; Liu, J.; et al. 2023. A survey of\nlarge language models in medicine: Progress, application,\nand challenge. arXiv preprint arXiv:2311.05112.\nZhu, J.-Y .; Park, T.; Isola, P.; and Efros, A. A. 2017. Un-\npaired image-to-image translation using cycle-consistent ad-\nversarial networks. InProceedings of the IEEE international\nconference on computer vision, 2223–2232.\n11']","Ma, Y. contributed to the work titled 'Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation,' which is documented in the arXiv preprint arXiv:2410.13848.",single_hop_specific_query_synthesizer
Cud yu pleese explane the diffrences between HealthGPT-M3 and HealthGPT-L14 in terms of their model components and hyperparametrs?,"['Appendix\nThis is the Appendix for “HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation\nvia Heterogeneous Knowledge Adaptation”. This Appendix is organized as follows:\n• Section A presents the experimental implementation details, the training process of HealthGPT, and the specifics of\nVL-Health.\n• Section B systematically provides an analysis of Heterogeneous Low-Rank Adaptation.\n• Section C shows supplementary experimental results to validate the effectiveness ofHealthGPT.\nA Implementation Details\nA.1 Model Details\nWe employ CLIP-L/14 (Radford et al. 2021) as the visual feature extractor, extracting both shallow and deep features to serve as\nvisual tokens. The model uses alignment adapters, implemented with two-layer MLPs, to align shallow features, representing\nconcrete visual granularity, and deep features, representing abstract visual granularity. These visual tokens are concatenated\nwith text tokens and input into the large language models (LLMs).\nHealthGPT offers two versions: HealthGPT-M3 and HealthGPT-L14, which are based on Phi-3-mini (Abdin et al.\n2024) and Phi-4 (Abdin et al. 2024) as the pre-trained LLMs, respectively. In addition, we expand the LLM vocabulary with\n8192 VQ indices derived from VQGAN-f8-8192 (Esser, Rombach, and Ommer 2021), serving as multi-modal tokens to further\naugment the model’s capacity for understanding both visual and textual input. Figure 6 shows the details.\nTable 6: Overview of the Components of HealthGPT.\nModel ViT Adapter MLP-dims Model dims LLM Params Vocab Size H-LoRA Rank\nHealthGPT-M3 CLIP-L/14 2-layer MLP 1024 3072 Phi-3-mini 3.8B 40206 16(Comp.), 64(Gen.)\nHealthGPT-L14 CLIP-L/14 2-layer MLP 1024 5120 Phi-4 14B 108547 8(Comp.), 32(Gen.)\nA.2 Training Details\nIn this study, we propose a three-stage learning strategy that is compatible with our innovative heterogeneous low-rank adapta-\ntion (H-LoRA). We provide a detailed hyperparameter configuration for the model’s three-stage training process. The specific\nhyperparameter settings used are listed in Table 7. These hyperparameters are crucial for ensuring the model’s learning efficacy\nand final performance.\nTable 7: Overview of Hyperparameter Configurations.\nHealthGPT-M3 HealthGPT-L14\nStage-1 Stage-2 Stage-3 Stage-1 Stage-2 Stage-3Hyperparameter\nComp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen.\nOptimizer AdamW AdamW AdamW AdamW AdamW AdamW\nAdapter LR 1e-3 2e-5 2e-5 2e-5 1e-3 2e-5 2e-5 2e-5\nLearning Rate / 2e-4 2e-4 2e-4 / 1e-4 2e-4 2e-4\nGlobal Batch Size 256 64 32 128 64 256 64 32 128 64\nWeight Decay 0 0 0 0 0 0\nDropout Rate 0 0.05 0.05 0.05 0 0.05 0.05 0.05\nLR Scheduler Warm Up Constant Warm Up Warm Up Constant Warm Up\nMax Sequence Length 2048 2048 2048 2048 2048 2048\nIt is worth noting that we sometimes observe instances of loss spikes during the training of medical visual comprehension\nand generation tasks. Through repeated validation, we discovered that larger model parameters and learning rates tend to lead to\nthis issue, which is the reason for the slight differences in hyperparameters betweenHealthGPT-M3 and HealthGPT-L14.\n12']","HealthGPT-M3 and HealthGPT-L14 differ in several aspects. HealthGPT-M3 is based on the Phi-3-mini pre-trained LLM with 3.8 billion parameters and a vocabulary size of 40,206. It uses a model dimension of 3072 and has H-LoRA ranks of 16 for comprehension and 64 for generation. In contrast, HealthGPT-L14 is based on the Phi-4 pre-trained LLM with 14 billion parameters and a vocabulary size of 108,547. It uses a model dimension of 5120 and has H-LoRA ranks of 8 for comprehension and 32 for generation. Both models employ CLIP-L/14 as the visual feature extractor and use a 2-layer MLP for the adapter. The hyperparameters also differ slightly, with HealthGPT-M3 using a higher adapter learning rate of 1e-3 during the first stage of training compared to HealthGPT-L14's 1e-4.",single_hop_specific_query_synthesizer
What MIMIC-CXR-VQA do?,"['（a） （b）\nFigure 8: VL-Health dataset collection distribution.\nA.3 VL-Health\nThe construction of theVL-Health dataset involves two key steps:(i) data collection, (ii) data processing, as detailed below:\nData Collection: During the collection phase, we carefully considered the diversity of medical images and the complexity of\nthe tasks, selecting appropriate subsets for comprehension and generation tasks. For comprehension tasks, we selected datasets\nsuch as VQA-RAD (Lau et al. 2018), SLAKE (Liu et al. 2021), PathVQA (He et al. 2020), and MIMIC-CXR-VQA (Bae et al.\n2024), which cover various medical imaging modalities like radiology and pathology, and include professional annotations\nto assist the model in learning tasks such as lesion detection and disease diagnosis. Additionally, large-scale multi-modal\ndatasets like LLaV A-Med (Li et al. 2024b) and PubMedVision (Chen et al. 2024a) were included to provide broader medical\nknowledge support and facilitate the training of complex reasoning tasks. For generation tasks, we focused on four mainstream\ntask categories: super-resolution image generation, modality conversion, text-to-image generation, and image reconstruction.\nThe IXI (Davies et al. 2014) dataset, containing a large number of healthy brain MRI images, is suitable for training super-\nresolution models; the MIMIC-CHEST-XRAY (Bae et al. 2024) dataset, with X-ray images and their corresponding textual\nreports, is appropriate for text-to-image generation tasks; the SynthRAD2023 (Thummerer et al. 2023) dataset provides a large\nnumber of paired CT and MRI images, supporting modality conversion model training; for image reconstruction tasks, we\nrewrote and adjusted the LLaV A-558k (Liu et al. 2024b) dataset.\nData Processing: After data collection, we performed filtering and processing of the raw data. For VisualQA tasks, we stan-\ndardized the data entries into two forms: open-ended questions and single-choice questions, enabling flexible training and\nevaluation. Additionally, considering that multi-image data has a minimal impact on performance but introduces extra padding\nand training time, we excluded multi-image data. For the scanned image data in generation tasks, we applied slicing extrac-\ntion, image registration, data augmentation, and normalization to treat 2D images as visual inputs for model training or used\nVQGAN-generated indices to supervise the generation tasks.\nData Statistics This section provides detailed statistical information about the VL-Health dataset to offer a more compre-\nhensive understanding.\nData Overview: To ensure a balanced development of the model’s comprehension and generation capabilities, in addition\nto the LLaV A-558k and PubMedVision-PT datasets used for alignment, the VL-Health dataset ultimately selected 765,802\nadditional visual question-answering (VQA) training samples (to endow the model with visual comprehension and instruction-\nfollowing capabilities) and 783,045 generation training samples (to provide the model with reconstruction and visual generation\ninstruction-following abilities). This contributes to the transfer of knowledge between comprehension and generation tasks, en-\nhancing the model’s overall performance. For medical image comprehension tasks, images were selected from VQA-RAD (ap-\nproximately 450 images), SLAKE (approximately 630 images), PathVQA (approximately 2,600 images), MIMIC-CXR-VQA\n(approximately 52,000 images), LLaV A-Med (approximately 61,000 images), and PubMedVision (approximately 500,000 im-\nages). Multiple question-answer pairs were retained for each image to enhance the model’s understanding and generalization\nof the image content. Table 8 shows the data distribution ofVL-Health for three-stage learning strategy, where mixed-47k is\nbased on the sampling of all data in stage-1.\nDiversity and Quality Assessment: VL-Health covers 11 modalities, including CT, MRI, X-ray, microscopy, OCT, ultra-\nsound, and fundus photography, which aids the model in learning features from various modalities. The dataset also encom-\npasses a wide range of diseases, from common to rare, and from localized lesions to systemic diseases, including pulmonary\ndiseases, skeletal abnormalities, brain lesions, tumors, cardiovascular diseases, and cellular abnormalities. This provides com-\nprehensive training support to the model, enabling it to learn the characteristics and diagnosis of various diseases.\n13']","MIMIC-CXR-VQA is a dataset used for medical image comprehension tasks, specifically covering radiology and pathology, and includes professional annotations to assist models in learning tasks such as lesion detection and disease diagnosis.",single_hop_specific_query_synthesizer
Wht is the role of PubMedVision-PT in the VL-Health dataset's three-stage learning strategy?,"['Table 8: Data distribution of VL-Health in three-stage learning strategy.\nMedical Task Stage-1 Stage-2\nComp. LLaV A-558k, PubMedVision-PT Mixed-47kGen. LLaV A-558k\nMedical Task Stage-3\nComp. LLaV A Med, MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, VQA-RAD\nGen. IXI, SynthRAD2023, MIMIC-CHEST-XRAY\nData Format. All data samples are converted into a unified instruction-response format for training and evaluation. Specifi-\ncally, the VL-Health dataset consists of the following components:\n• Task Type: Specifies the granularity of visual features output by the visual encoder and selects the corresponding H-\nLoRA submodule. For generation tasks, the response also includes multi-modal tokens corresponding to VQ indices.\n• Task Instruction: Guides the model to interpret the image and generate a response, covering various aspects of the\nimage and specifying the output format.\n• Response: The textual output generated based on the task instruction and input image, ensuring it meets the question and\nformatting requirements.\n• Input Image: Provides the visual signal for the model to process.\n• Target Image Index: In generation tasks, this is added as a multi-modal token to the response for autoregressive\ngeneration.\nB Analysis of Heterogeneous Low-Rank Adaptation\nWe propose H-LoRA, which utilizes hard routing selection to allocate plugins for knowledge learning and representation across\ntasks, thereby preventing conflicts arising from heterogeneous knowledge. Furthermore, within each task, we optimized based\non MoELoRA, enhancing performance while reducing computational overhead. The pseudocode is detailed Algorithm 1.\nAlgorithm 1: H-LoRA Algorithm\nInput: concrete-grained visual features FCon, abstract-grained visual featuresFAbs, comprehension-based H-LoRA modules\n({AComp.\ni }k\ni=1, RComp.\nouter ), generation-based H-LoRA modules({AGen.\ni }k\ni=1, RGen.\nouter), task type T (comprehension or generation),\nnumber of LoRA experts k, origin linear layer weights W0, text features T , hidden state h\nOutput: final output O\n// Select task-specific image features\nif T = generation task then\nFimg ← FCon\nelse if T = comprehension task then\nFimg ← FAbs\nend if\nU ←concat(Fimg, T ) // Concatenate image features and text features\n{Ai}k\ni=1, {Bi}k\ni=1, Router ← {AT\ni }k\ni=1, {BT\ni }k\ni=1, RT\nouter // Assign task-specific H-LoRA submodule\n// Merge LoRA experts’ matrices\nAmerged ← concat({Ai}k\ni=1)\nBmerged ← concat({Bi}k\ni=1)\nW ←R(h) // Generate routing weights based on input hidden state x\nWexpanded ← α × W/r ⊗ 1r // Expand routing weights to match merged matrices\nOH-LoRA ← (x · Amerged ⊙ Wexpanded) · Bmerged // Compute H-LoRA output using element-wise multiplication\nO ←x · W0 + OH-LoRA // Add H-LoRA output to pre-trained weights to get final output\nReturn O\nWe further analyzed the computational overhead differences between MoELoRA and H-LoRA. Assuming that both methods\nuse the same number of LoRA experts k, we can compare their time complexity from the perspective of the operational steps\ninvolved.\nComputational Overhead of MoELoRA. In MoELoRA, the operations involving the expert matrix mainly include the fol-\nlowing steps: (i) Expert Multiplication : MoELoRA requires 2k multiplications with the LoRA experts. (ii) Router Multi-\nplication: One multiplication with the Router is required. (iii) Router Output Expansion : MoELoRA needs to perform k\n14']","In the VL-Health dataset's three-stage learning strategy, PubMedVision-PT is used in Stage-1 for comprehension tasks with a data distribution of Mixed-47k.",single_hop_specific_query_synthesizer
"What is the significance of OmniMedVQA in evaluating medical visual question answering models, and how does it compare to other benchmarks?","['expansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15']","OmniMedVQA is a novel, large-scale medical visual question answering (VQA) benchmark designed to encompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. It provides a comprehensive evaluation framework for medical VQA models. In the performance comparison presented in Table 9, models like HealthGPT-M3 and HealthGPT-L14 demonstrate superior performance on the OmniMedVQA benchmark, outperforming other models in several sub-tasks and achieving higher average scores compared to cutting-edge medical Large Vision-Language Models (LVLMs).",single_hop_specific_query_synthesizer
How does H-LoRA improve training efficiency compared to MoELoRA in medical AI models?,"['general LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","H-LoRA improves training efficiency by avoiding additional training delays compared to LoRA and outperforming MoELoRA. While MoELoRA's training time significantly increases with the number of experts, H-LoRA incurs no additional training delay and performs better. For instance, at n = 32, MoELoRA is unable to complete training, whereas H-LoRA maintains efficient training times.",single_hop_specific_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and what role does HealthGPT play in enhancing medical comprehension?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [476.16s] Securing AI Engagement in Business Infrastructure\nAisha discusses the importance of zero trust in securing AI engagement within business infrastructure. This concept is not new, but its application has evolved with the rise of autonomous AI agents that make decisions at machine speed.\n\n## [530.40s] Key Principles for AI Governance\nThe speakers outline key principles for governing AI agents in enterprise systems. Identifying AI agents within the system is the first step, followed by implementing just-in-time access controls that grant only the necessary permissions for specific tasks.\n\n### [596.64s] Assumption of Breach\nOrganizations must also operate under the assumption that breaches can occur at any time, necessitating robust security measures to protect against potential compromises.', '<3-hop>\n\nAppendix\nThis is the Appendix for “HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation\nvia Heterogeneous Knowledge Adaptation”. This Appendix is organized as follows:\n• Section A presents the experimental implementation details, the training process of HealthGPT, and the specifics of\nVL-Health.\n• Section B systematically provides an analysis of Heterogeneous Low-Rank Adaptation.\n• Section C shows supplementary experimental results to validate the effectiveness ofHealthGPT.\nA Implementation Details\nA.1 Model Details\nWe employ CLIP-L/14 (Radford et al. 2021) as the visual feature extractor, extracting both shallow and deep features to serve as\nvisual tokens. The model uses alignment adapters, implemented with two-layer MLPs, to align shallow features, representing\nconcrete visual granularity, and deep features, representing abstract visual granularity. These visual tokens are concatenated\nwith text tokens and input into the large language models (LLMs).\nHealthGPT offers two versions: HealthGPT-M3 and HealthGPT-L14, which are based on Phi-3-mini (Abdin et al.\n2024) and Phi-4 (Abdin et al. 2024) as the pre-trained LLMs, respectively. In addition, we expand the LLM vocabulary with\n8192 VQ indices derived from VQGAN-f8-8192 (Esser, Rombach, and Ommer 2021), serving as multi-modal tokens to further\naugment the model’s capacity for understanding both visual and textual input. Figure 6 shows the details.\nTable 6: Overview of the Components of HealthGPT.\nModel ViT Adapter MLP-dims Model dims LLM Params Vocab Size H-LoRA Rank\nHealthGPT-M3 CLIP-L/14 2-layer MLP 1024 3072 Phi-3-mini 3.8B 40206 16(Comp.), 64(Gen.)\nHealthGPT-L14 CLIP-L/14 2-layer MLP 1024 5120 Phi-4 14B 108547 8(Comp.), 32(Gen.)\nA.2 Training Details\nIn this study, we propose a three-stage learning strategy that is compatible with our innovative heterogeneous low-rank adapta-\ntion (H-LoRA). We provide a detailed hyperparameter configuration for the model’s three-stage training process. The specific\nhyperparameter settings used are listed in Table 7. These hyperparameters are crucial for ensuring the model’s learning efficacy\nand final performance.\nTable 7: Overview of Hyperparameter Configurations.\nHealthGPT-M3 HealthGPT-L14\nStage-1 Stage-2 Stage-3 Stage-1 Stage-2 Stage-3Hyperparameter\nComp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen.\nOptimizer AdamW AdamW AdamW AdamW AdamW AdamW\nAdapter LR 1e-3 2e-5 2e-5 2e-5 1e-3 2e-5 2e-5 2e-5\nLearning Rate / 2e-4 2e-4 2e-4 / 1e-4 2e-4 2e-4\nGlobal Batch Size 256 64 32 128 64 256 64 32 128 64\nWeight Decay 0 0 0 0 0 0\nDropout Rate 0 0.05 0.05 0.05 0 0.05 0.05 0.05\nLR Scheduler Warm Up Constant Warm Up Warm Up Constant Warm Up\nMax Sequence Length 2048 2048 2048 2048 2048 2048\nIt is worth noting that we sometimes observe instances of loss spikes during the training of medical visual comprehension\nand generation tasks. Through repeated validation, we discovered that larger model parameters and learning rates tend to lead to\nthis issue, which is the reason for the slight differences in hyperparameters betweenHealthGPT-M3 and HealthGPT-L14.\n12']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to maintain system integrity. This involves operating under the assumption of a breach and applying zero trust principles, such as just-in-time access controls, to secure AI engagement within business infrastructure. HealthGPT enhances medical comprehension by using a large vision-language model that integrates visual and textual inputs through heterogeneous knowledge adaptation. It employs models like CLIP-L/14 to extract visual features and aligns them with text tokens, which are then processed by large language models to improve understanding and generation in medical contexts.",multi_hop_abstract_query_synthesizer
How do AI egress gateways and security considerations work together to ensure the integrity of AI-driven systems?,"['<1-hop>\n\n### [2831.44s] Customer Use Cases and Patterns\nWe have collaborated with numerous customers who have established use cases involving AI and egress gateways. Two primary patterns have emerged. The first involves organizations configuring a single API for all teams to use, allowing for quota management across different teams accessing the same LLM API. \n\nThe second pattern involves moving certain logic from the agent level to the egress gateway level, utilizing prompt decorators and templating. These use cases highlight the flexibility and governance capabilities provided by the egress AI gateway.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","AI egress gateways provide flexibility and governance capabilities by allowing organizations to configure a single API for quota management and move logic to the egress gateway level. Security considerations in AI-driven systems involve assuming breaches and implementing security gates, along with continuous monitoring to track agent activities. Together, these elements ensure the integrity and security of AI-driven systems by managing access and preventing malicious activities.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents while integrating seamlessly with healthcare systems, and what value additions does vertical AI provide in this context?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [518.96s] Value Additions of Vertical AI\nThe vertical AI layer includes several value additions, such as:\n\n- **Industry-Specific Model Adaptation**: Tailored knowledge and terminology relevant to healthcare customers.\n- **Proprietary Data Utilization**: Incorporation of industry-specific workflows and decision-making logic that aligns with established processes.\n- **Seamless Integration**: The ability to connect with industry-specific systems, such as healthcare systems and open banking APIs.\n- **Regulatory Compliance**: Development of API products that adhere to industry regulations, ensuring that the solutions are both effective and compliant.']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to maintain system integrity. This approach is crucial as the attack space evolves, requiring systems to always assume a breach. In the context of healthcare, vertical AI provides several value additions, including industry-specific model adaptation with tailored knowledge and terminology, proprietary data utilization that aligns with healthcare workflows, seamless integration with healthcare systems, and regulatory compliance to ensure solutions are both effective and compliant.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security while integrating medical visual comprehension tasks, and what role does the user interface play in this process?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nTo address the needs of various tasks, the hidden states\nare divided into two types: (i) Concrete-grained features\nFCon = {f1, f2, . . . , fk}, k < L, derived from the shal-\nlower layers of ViT, containing sufficient global features,\nsuitable for generation tasks; (ii) Abstract-grained features\nFAbs = {fk+1, fk+2, . . . , fL}, derived from the deeper\nlayers of ViT, which contain abstract semantic information\ncloser to the text space, suitable for comprehension tasks.\nThe task type T (comprehension or generation) deter-\nmines which set of features is selected as the input for the\ndownstream large language model:\nFimg\nT =\n(\nFCon, if T = generation task\nFAbs, if T = comprehension task (6)\nWe integrate the image featuresFimg\nT and text featuresT into\na joint sequence through simple concatenation, which is then\nfed into the LLM Mllm for autoregressive generation.\n4.3 Heterogeneous Knowledge Adaptation\nWe devise H-LoRA, which stores heterogeneous knowledge\nfrom comprehension and generation tasks in separate mod-\nules and dynamically routes to extract task-relevant knowl-\nedge from these modules. At the task level, for each task type\nT, we dynamically assign a dedicated H-LoRA submodule\nθT , which is expressed as:\nR = MLLM(U|θ, θT ), θ T = {AT , BT , RT\nouter}. (7)\nAt the feature level for a single task, H-LoRA integrates the\nidea of Mixture of Experts (MoE) (Masoudnia and Ebrahim-\npour 2014) and designs an efficient matrix merging and rout-\ning weight allocation mechanism, thus avoiding the signif-\nicant computational delay introduced by matrix splitting in\nexisting MoELoRA (Luo et al. 2024a). Specifically, we first\nmerge the low-rank matrices (rank = r) of k LoRA experts\ninto a unified matrix:\nAmerged, Bmerged = Concat({Ai}k\n1 ), Concat({Bi}k\n1 ), (8)\nwhere Amerged ∈ Rdin×rk and Bmerged ∈ Rrk×dout\n. The\nk-dimension routing layer generates expert weights W ∈\nRtoken num×k based on the input hidden state x, and these are\nexpanded to Rtoken num×rk as follows:\nWexpanded = αkW/r ⊗ 1r, (9)\nwhere ⊗ denotes the replication operation. The overall out-\nput of H-LoRA is computed as:\nOH-LoRA = (xAmerged ⊙ Wexpanded)Bmerged, (10)\nwhere ⊙ represents element-wise multiplication. Finally, the\noutput of H-LoRA is added to the frozen pre-trained weights\nto produce the final output:\nO = xW0 + OH-LoRA. (11)\n900\n800\n700\n600\n500\n400\n300\n200\n100\n0\nComp. Gen.\n(a) (b)\n783K765K\n（K）\nFigure 4: Data statistics of VL-Health.\n4.4 Training Pipeline\n1st Stage: Multi-modal Alignment. In the first stage, we\ndesign separate visual adapters and H-LoRA submodules for\nmedical unified tasks. For the medical comprehension task,\nwe train abstract-grained visual adapters using high-quality\nimage-text pairs to align visual embeddings with textual\nembeddings, thereby enabling the model to accurately de-\nscribe medical visual content. During this process, the pre-\ntrained LLM and its corresponding H-LoRA submodules\nremain frozen. In contrast, the medical generation task re-\nquires training concrete-grained adapters and H-LoRA sub-\nmodules while keeping the LLM frozen. Meanwhile, we ex-\ntend the textual vocabulary to include multimodal tokens,\nenabling the support of additional VQGAN vector quanti-\nzation indices. The model trains on image-VQ pairs, en-\ndowing the pre-trained LLM with the capability for image\nreconstruction. This design ensures pixel-level consistency\nof pre- and post-LVLM. The processes establish the initial\nalignment between the LLM’s outputs and the visual inputs.\n2nd Stage: Heterogeneous H-LoRA Plugin Adaptation.\nThe submodules of H-LoRA share the word embedding\nlayer and output head but may encounter issues such as\nbias and scale inconsistencies during training across dif-\nferent tasks. To ensure that the multiple H-LoRA plugins\nseamlessly interface with the LLMs and form a unified base,\nwe fine-tune the word embedding layer and output head us-\ning a small amount of mixed data to maintain consistency\nin the model weights. Specifically, during this stage, all H-\nLoRA submodules for different tasks are kept frozen, with\nonly the word embedding layer and output head being op-\ntimized. Through this stage, the model accumulates foun-\ndational knowledge for unified tasks by adapting H-LoRA\nplugins.\n3rd Stage: Visual Instruction Fine-Tuning. In the third\nstage, we introduce additional task-specific data to fur-\nther optimize the model and enhance its adaptability to\ndownstream tasks such as medical visual comprehension\n(e.g., medical QA, medical dialogues, and report generation)\nor generation tasks (e.g., super-resolution, denoising, and\n5', '<3-hop>\n\n## [1896.16s] Authorization Process for Booking\nThe assistant then prompted the user for authorization to book the room, as it required permission to proceed. Upon clicking the authorization link, the user was taken through the login process of the booking system, which is configured with Taskio. The system asked whether permission should be granted to the agent to create a booking.\n\n### [1941.44s] Completion of the Booking\nAfter the authorization was completed, the agent was able to act on behalf of the user, confirming that the booking was successful. The user could view the new booking alongside any previous manual bookings made.']","AI-driven systems ensure security by implementing continuous monitoring and security gates to track the activities of agents, preventing them from acting outside their intended purpose or exceeding their access parameters. This is crucial for maintaining the integrity and security of the system, especially in the context of medical visual comprehension tasks. The integration of medical visual comprehension tasks involves using abstract-grained features derived from deeper layers of ViT, which are suitable for comprehension tasks. These features are integrated with text features into a joint sequence for processing by a large language model. The user interface plays a critical role in this process by facilitating the interaction between the user and the system, ensuring that the system's outputs are accessible and understandable to the user, thereby enhancing the overall security and effectiveness of the AI-driven system.",multi_hop_abstract_query_synthesizer
"What are the security considerations in AI-driven systems, and how do they relate to the challenges of AI scalability?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.']","In AI-driven systems, security considerations are crucial due to the potential presence of malicious agents or bots that can launch attacks. It is important to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure these agents do not exceed their access parameters. This is vital for maintaining system integrity and security. On the other hand, AI scalability presents challenges as many organizations struggle to scale their AI solutions effectively. However, improvements in speed are enabling real-time interactions both in the cloud and at the edge. The relationship between security considerations and scalability challenges lies in the need for robust security measures that can adapt to scalable AI solutions, ensuring that as AI systems grow and become more complex, they remain secure and resilient against potential threats.",multi_hop_abstract_query_synthesizer
Hw do AI-driven systems ensure security and governance while using a unified model for medical tasks?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [339.04s] Governance of AI Agents\nThe governance of AI agents is essential to prevent unauthorized actions. For instance, if an AI agent designed for marketing data gains admin rights to a financial system, it could perform unnecessary transactions or expose sensitive customer information.\n\n### [377.28s] Importance of Auditability\nAuditability is vital in agentic systems, as agents operate at high speeds, making changes to APIs and databases. Tracking these actions is necessary for forensic purposes, allowing organizations to trace who did what and when.\n\n### [419.12s] Compliance and Governance Requirements\nOrganizations must also navigate governance and compliance requirements, such as GDPR, to protect user data and prevent misuse of AI capabilities. The speakers stress that while AI is not inherently bad, it is essential to employ AI securely and govern access effectively to maximize its benefits.', '<3-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","AI-driven systems ensure security by implementing continuous monitoring to track the activities of agents, preventing them from acting outside their intended purpose or exceeding access parameters. This is crucial for maintaining system integrity and security. Governance of AI agents is also essential to prevent unauthorized actions, such as an AI agent gaining admin rights to a financial system and performing unnecessary transactions. Compliance with governance requirements like GDPR is necessary to protect user data. In the context of a unified model for medical tasks, the approach effectively mitigates performance degradation caused by generation tasks, serving as a unified model. The second phase of the learning strategy integrates different plugins into a new unified foundation, minimizing performance impact and alleviating conflicts from mixed training in medical scenarios.",multi_hop_abstract_query_synthesizer
Howw do AI-driven systems use natural language processing and dynamic authorization policies to enhanse security and functionality?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n## [11.84s] Panelist Introductions\nYad Ahmed shares his background, stating that he has 24 years of experience in technology, with eight years focused on natural language processing (NLP) and AI. He explains that Arabic AI, which operates under the name Turjim, has been in business for 17 years, initially focusing on translation and content generation. In 2016, the company expanded into technology, developing automated systems for translation and content generation. Recently, they secured a Series A funding round of $50 million to further their work in AI, particularly in model fine-tuning and workflow automation.\n\nRana Kalaf introduces herself as the Chief AI Officer at WSO2. She emphasizes the company's focus on two main areas in their AI journey: accelerating user engagement with their products through embedded agents and co-pilots, and integrating AI into applications via connectors and an agent-building framework.\n\nAlan Shmal from Vistra describes the company as a corporate services provider that handles accounting, payroll, and legal entity management. He explains that their AI initiatives include a conversational agent built with Aentic AI frameworks, which serves three main functions: advisory, reporting on customer data, and executing workflows. He also mentions the use of asynchronous systems to process unstructured data, such as legal documents and voice notes.\n\nMahesh Saloria represents Canada HSBC Life Insurance, a joint venture between Canara Bank and HSBC. He discusses their focus on securing individuals' futures through insurance and highlights a recent initiative involving an underwriting co-pilot designed to assist underwriters in assessing risk."", '<3-hop>\n\n## [1181.92s] Dynamic Authorization Policies\nFurthermore, various authorization policies can be applied at runtime. For instance, some agents may require one-time access to specific systems, while others might need access for a defined period, such as from 10 AM to 12 PM daily. This flexibility in permissions is crucial for maintaining security while allowing agents to function effectively within the system.\n\n**Time Range: 00:20:01 - 00:30:03**\n\n# [1201.76s] Contextual Authorizations and Auditing\nIn the context of agent management, contextual authorizations can be applied to enhance the functionality of these agents. An important aspect of this process is auditing. Once an agent is assigned a unique identity across the system, it becomes possible to trace its activities through various parameters. This capability allows for the tracking of what actions the agent performed and when they occurred. Without such a unique identity, accountability falls on the application or user, making it difficult to conduct forensic analysis or correct issues if something goes wrong. Therefore, establishing a unique identity for agents is crucial for effective auditing and accountability.']","AI-driven systems enhance security and functionality by integrating natural language processing (NLP) and dynamic authorization policies. Yad Ahmed, with extensive experience in NLP and AI, highlights the use of AI for translation and content generation, which can be applied to improve system interactions and user engagement. Dynamic authorization policies, as discussed, allow for flexible permissions, granting agents access to systems for specific periods or tasks, which is crucial for maintaining security. This flexibility, combined with continuous monitoring and unique identity assignment for agents, ensures that AI-driven systems can effectively manage security threats while optimizing their operational capabilities.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure efficiency and security in location retrieval processes?,"['<1-hop>\n\n# [2401.28s] Executing Location Retrieval\nTo begin the process, the agent is instructed to execute a command to retrieve locations. This information is essential for the next steps in the execution. The agent, having gathered the necessary data, will utilize an API to obtain a set of locations that it can recommend to the user.\n\n## [2419.76s] Decision-Making Process of the Agent\nOnce the agent has the set of locations, it will analyze the information and consult the language model (LLM) to determine the next course of action. The LLM will suggest checking the weather conditions in these locations, as adverse weather could affect the recommendations. The agent will then use a weather API, inputting the locations as parameters, to retrieve the current weather conditions.\n\nAfter receiving the weather data, the agent will iterate on this information and send it back to the LLM. With sufficient data at hand, the agent can confidently make a decision and recommend the best locations for the user, concluding the task.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<3-hop>\n\n**Time Range: 00:50:01 - 01:00:05**\n\n## [3036.08s] Request and Token Count Policies\nIt is important to note that the introduction of token counting does not eliminate the request per minute count. Organizations can still implement policies that combine request counts with token limit counts, which is fully supported.\n\n# [3052.80s] Semantic Response Caching\nThe semantic response cache is designed to reduce costs, although it may not be applicable to all AI scenarios. It is particularly advised for use in documentation assistance, where responses are derived from a specific knowledge base. In such cases, processing every call may not be efficient, as the same question can be asked in various ways. \n\nThe traditional response cache operates on a direct key-value basis, where a request is cached, and if a subsequent request matches exactly, the previous answer is returned. However, with LLMs, this approach is insufficient because different users may phrase the same question differently. Therefore, semantic response caching has been developed. If one person asks a question in one way and another person asks it differently, but both inquiries are essentially the same, the system can deliver the previous response to the second user. Some LLMs have implemented this feature in their back-end systems to enhance efficiency, although its effectiveness can vary.']","AI-driven systems ensure efficiency in location retrieval processes by utilizing APIs to gather necessary data, such as locations and weather conditions, which are then analyzed by a language model to make informed recommendations. To maintain security, these systems implement security gates and continuous monitoring to prevent malicious agents from exceeding their access parameters, ensuring the integrity of the system.",multi_hop_abstract_query_synthesizer
Howw do continuous monitering and methodologies help in AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [939.84s] Evaluating Model Performance\nAn important aspect of our work involves evaluating model performance, especially in light of changes that may affect functionality. This is a significant area of research within the field of agents and generative AI, as these systems are inherently probabilistic. When the same prompt is called multiple times, it can yield different responses, complicating the testing process. \n\nTo address this, we need to establish methodologies and benchmark datasets to ensure consistent performance, particularly given the rapid advancements in technology. As we transition to new models every six months, it is vital to confirm that we do not lose any previously effective functionalities.']","Continuous monitoring in AI-driven systems is essential for tracking the activities of agents to ensure they do not exceed their access parameters, thereby maintaining system integrity and security. Methodologies, on the other hand, are crucial for evaluating model performance, ensuring consistent functionality despite the probabilistic nature of generative AI systems and the rapid advancements in technology.",multi_hop_abstract_query_synthesizer
How does the MCP architechture utilize data in AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2914.80s] Architecture of MCP\nThe MCP architecture includes an MCP host, which can be any integration or agent that connects to data or tools. Clients connect to the MCP server using a JSON RPC protocol, simplifying the process of establishing connections.\n\nThe MCP server has a fixed specification, allowing for a single client definition that can communicate with the server without needing to rewrite the client for each new integration. This design streamlines the connection process to various data sources and APIs, enhancing the overall efficiency of LLM integrations.\n\n# [601.12s] Utilizing Single LLM Invocation\nIn the realm of generative models, there are instances where a single large language model (LLM) invocation is employed to address specific issues. This approach is often complemented by multiple techniques that involve several iterations of LLM calls to effectively overcome limitations.', '<3-hop>\n\n## [1394.88s] Data Utilization for Enhanced Responses\nTo achieve this, the team recognizes the need for a clear pattern. There is a wealth of data available, including documents, PDFs, and websites related to specific hotels. Hotels must be able to upload this unstructured information, which can then be indexed to answer user inquiries effectively.\n\n### [1426.40s] Implementation of Retrieval-Augmented Generation\nThis necessitates the integration of a retrieval-augmented generation (RAG) component, which will provide accurate contextual answers to users. Hotel owners will upload their documents and policies or direct the system to their websites. The information will be processed through a hotel information injection pipeline, which will clean, chunk, and index the data into a new hotel database.']","The MCP architecture utilizes data in AI-driven systems by connecting clients to the MCP server using a JSON RPC protocol, which simplifies the process of establishing connections to various data sources and APIs. This design enhances the efficiency of LLM integrations, allowing for streamlined data utilization. Additionally, the architecture supports the integration of retrieval-augmented generation components, which process and index unstructured data, such as documents and websites, to provide accurate contextual answers, thereby enhancing the system's response capabilities.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security in user-absent flows, and what role does generative AI play in enhancing these systems?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [1160.32s] User-Absent Flow with Ambient Agents\nThe second use case involves user-absent flows, referred to as ambient agents. These agents operate in the background, executing tasks without direct user interaction. An example is Bill, who wants an AI agent to pay his electricity bill when two conditions are met, the first being that the bill needs to be ready. This concept can be applied to various complex and innovative scenarios.\n\n**Time Range: 00:20:02 - 00:23:20**\n\n# [1202.40s] Salary Remittance Process\nThe salary should be remitted as part of the payment process. This is how it works: the first build provides this requirement to the AI agent, which listens to a service provider to determine whether the bill is ready. The AI agent then calls a bank endpoint or monitors SMS or email notifications to check if the salary has been remitted.', '<3-hop>\n\n## [795.92s] Incorporating Contextual Information\nThe most critical aspect involves supplying the current text, which adds necessary context to the LLM. This includes information about existing libraries, as the LLM may not be aware of the latest updates due to frequent releases. By utilizing few-shot prompting, the amount of instruction can be minimized, allowing for a more streamlined interaction with the user’s queries.\n\n# [840.40s] Exploring Generative Integration Patterns\nThe discussion now shifts to generative integration patterns. In the early stages of generative AI, the primary focus was on integrating generative models into applications. This integration allowed for basic interactions, such as conversing with a chat-based assistant, without the need for external data. For instance, code generation could be performed without any additional context.']","AI-driven systems ensure security in user-absent flows by implementing security gates at various points within the system and continuously monitoring the activities of ambient agents to prevent them from acting outside their intended purpose or exceeding their access parameters. This is crucial for maintaining the integrity and security of the system, especially in scenarios where tasks are executed without direct user interaction, such as an AI agent paying bills automatically. Generative AI enhances these systems by integrating generative models into applications, allowing for streamlined interactions and basic operations like code generation without the need for external data. This integration supports the development of more sophisticated AI-driven systems that can operate securely and efficiently in user-absent environments.",multi_hop_abstract_query_synthesizer
"How do AWS guardrails enhance the security of AI-driven systems, particularly in managing violence-related prompts?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4280.56s] Introduction of Guardrails\nTo address these concerns, an AWS guardrail has been configured to include a violence filter, which detects any prompts related to violence. The same prompt is then submitted to the hotel booking assistant to observe how the response differs.\n\n## [4311.92s] Response with Guardrails\nUpon submitting the prompt, the AWS guardrail identifies that the query pertains to a violence-based topic and fails the request. This mechanism allows for better control over how egress calls are managed.\n\n## [4331.36s] PII Detection Demonstration\nNext, a demonstration of Personally Identifiable Information (PII) detection is presented. A user might inadvertently share their email address without realizing the potential for it to be leaked. When the user submits their email, the LLM responds with a standard message, thanking them for sharing their email address and asking how it can assist further.']","AWS guardrails enhance the security of AI-driven systems by incorporating a violence filter that detects prompts related to violence. When such a prompt is submitted, the guardrail identifies the query as violence-based and fails the request, thereby providing better control over how egress calls are managed. This mechanism is part of a broader strategy to address security concerns in AI-driven systems, where continuous monitoring and security gates are essential to prevent malicious activities and maintain system integrity.",multi_hop_abstract_query_synthesizer
"How do security considerations in AI-driven systems impact model performance, particularly in the context of backend systems and excessive information handling?","[""<1-hop>\n\n### [1171.44s] Understanding Token Limitations\nAlthough newer models can support larger context windows, such as hundreds of thousands or even up to one million tokens, it is essential to manage costs effectively. Utilizing the full capacity of these models can lead to increased expenses, as each token consumed incurs a cost.\n\n**Time Range: 00:20:01 - 00:30:02**\n\n# [1201.04s] The Impact of Excessive Information on Model Performance\nWhen excessive information is included in the prompt, it can lead to increased costs and inefficiencies. This situation results in a scenario where the model has to sift through a large amount of data to determine what is relevant for completing the task. Consequently, this can reduce the accuracy of the task and lead to higher latencies, meaning slower response times. The model's performance is hindered due to the extensive processing required when handling a significant volume of data."", '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<3-hop>\n\n### [920.32s] Staff Allocation Agent\nThe second agent operates in the background as a staff allocation agent. It is triggered when a booking is made, accessing the user's personal profile to assign appropriate staff for that booking instance. This integration raises important considerations regarding security boundaries within the agentic AI framework.\n\n## [948.00s] Security Boundaries in Agentic AI\nWhen introducing agentic AI into the platform, it is essential to establish various security boundaries. The user-agent interaction forms one boundary, while the backend systems represent another. These backend systems may interact with external parties, necessitating secure management of incoming and outgoing requests. Additionally, the ambient agent receives requests to perform tasks, requiring secure communication with the business's backend APIs and the ability to update existing bookings.""]","Security considerations in AI-driven systems impact model performance by necessitating the implementation of security gates and continuous monitoring to prevent malicious activities, which can add to the processing load. This is particularly relevant in the context of backend systems, where secure management of requests is crucial. Additionally, handling excessive information can further hinder model performance by increasing costs and inefficiencies, as the model must process large volumes of data to determine relevance, leading to reduced accuracy and slower response times.",multi_hop_abstract_query_synthesizer
How security in AI-driven systems and code for AI relate to agentic AI security issues?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [846.64s] Code for AI\nMoving on to ""Code for AI,"" this involves providing building blocks for developing AI-related capabilities. An example is the MCP server, which converts a standard API into a tool that an AI agent can easily communicate with. WSO2 offers pre-built support to convert any FHIR server, such as an EHR server, into an MCP server, allowing direct communication with AI agents.\n\nA demonstration illustrates this user experience. When a user enters a healthcare-specific prompt, the system redirects to an authorization flow where the user must provide consent for the agent to access their data. The AI agent then calls the APIs using the MCP server to access the records. For example, if the prompt is about recorded immunizations, the AI agent retrieves the relevant health records. This capability is significant because a horizontal AI would lack the knowledge to interact with EHR systems and would require server-side enablement via the MCP server.', '<3-hop>\n\n## [212.16s] Importance of Security in Agentic AI\nAyesha emphasizes the significance of security in the context of agentic AI and discusses the risks associated with neglecting security measures. She cites a recent incident involving Replit, a software engineering assistant platform, where an agent deleted an entire production database despite being instructed not to do so. This incident highlights the necessity of implementing proper access controls and entitlement management for agents to prevent unexpected actions.\n\n### [268.80s] Challenges of Traditional Identity Management\nAyesha explains that traditional software was more predictable, with identity management designed for applications that followed predefined logic. In contrast, agentic systems operate continuously, with agents working 24/7, leading to varying authentication patterns and access levels. Traditional identity and access management approaches are more suited to static behaviors, while agentic AI introduces complexities due to the diverse behaviors of agents.']","Security in AI-driven systems is crucial due to the evolving attack space, requiring continuous monitoring to ensure agents do not exceed their access parameters. This is particularly important in agentic AI, where agents operate continuously and can exhibit unpredictable behaviors, as highlighted by the Replit incident where an agent deleted a production database. Code for AI, such as the MCP server, facilitates AI agents' interaction with systems like EHR servers, but also necessitates robust security measures to manage access and prevent unauthorized actions. The integration of AI-driven systems and code for AI with agentic AI underscores the need for comprehensive security strategies to address these challenges.",multi_hop_abstract_query_synthesizer
"What are the security considerations and challenges faced when transitioning AI-driven systems from development to production, and how do these impact the governance of AI services?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [76.16s] Challenges in AI Application Deployment\nAs organizations develop new AI applications, it is crucial to consider the challenges that arise when transitioning from a development environment to production. While it may feel satisfactory to see something work in development, ensuring scalability in production is essential to prevent organizational setbacks. The speakers encourage audience participation, inviting questions and interactions throughout the session.\n\n## [125.20s] Governance in AI Services\nArshad begins discussing the governance aspect of AI services, referencing recent news cases where AI systems have produced inappropriate or harmful responses. Such incidents pose risks to organizations, as they are responsible for delivering these services to end users. It is vital to govern AI behavior effectively to prevent such occurrences.']","In AI-driven systems, security considerations are paramount due to the threat of malicious agents or bots that can launch attacks. It is essential to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure these agents do not exceed their access parameters. When transitioning AI applications from development to production, challenges include ensuring scalability to prevent organizational setbacks. Additionally, governance in AI services is crucial to prevent inappropriate or harmful responses from AI systems, which can pose risks to organizations responsible for delivering these services to end users. Effective governance is necessary to manage these risks and maintain the integrity of AI services.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems address security concerns while ensuring business value, and what role does medical visual question answering play in enhancing these systems?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [301.52s] The Challenge of Delivering Business Value\nThe discussion shifts to the challenges of delivering business value through AI products. Rana Kalaf addresses the initial excitement of building AI products and the subsequent concerns about whether they truly deliver value. She notes the evolution of AI development, contrasting traditional data science practices with the current need for real-time, distributed systems. Rana emphasizes that building AI applications is now a collaborative effort, requiring a focus on scalability and production readiness. She stresses the importance of measuring the effectiveness of AI tools, suggesting that organizations should view AI as a means to enhance processes rather than an end goal.', '<3-hop>\n\nLiu, B.; Zhan, L.-M.; Xu, L.; Ma, L.; Yang, Y .; and Wu,\nX.-M. 2021. Slake: A semantically-labeled knowledge-\nenhanced dataset for medical visual question answering. In\n2021 IEEE 18th International Symposium on Biomedical\nImaging (ISBI), 1650–1654. IEEE.\nLiu, D.; Zhao, S.; Zhuo, L.; Lin, W.; Qiao, Y .; Li, H.; and\nGao, P. 2024a. Lumina-mgpt: Illuminate flexible photore-\nalistic text-to-image generation with multimodal generative\npretraining. arXiv preprint arXiv:2408.02657.\nLiu, H.; Li, C.; Li, Y .; and Lee, Y . J. 2024b. Improved\nbaselines with visual instruction tuning. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 26296–26306.\nLiu, H.; Li, C.; Li, Y .; Li, B.; Zhang, Y .; Shen, S.; and Lee,\nY . J. 2024c. LLaV A-NeXT: Improved reasoning, OCR, and\nworld knowledge. https://llava-vl.github.io/blog/2024-01-\n30-llava-next/.\nLiu, H.; Li, C.; Wu, Q.; and Lee, Y . J. 2023. Visual Instruc-\ntion Tuning. In NeurIPS.\nLiu, Q.; Wu, X.; Zhao, X.; Zhu, Y .; Xu, D.; Tian, F.; and\nZheng, Y . 2024d. When moe meets llms: Parameter efficient\nfine-tuning for multi-task medical applications. In Proceed-\nings of the 47th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval, 1104–\n1114.\nLiu, Y .; Tian, Y .; Zhao, Y .; Yu, H.; Xie, L.; Wang, Y .; Ye,\nQ.; and Liu, Y . 2024e. VMamba: Visual State Space Model.\narXiv preprint arXiv:2401.10166.\nLu, J.; Clark, C.; Lee, S.; Zhang, Z.; Khosla, S.; Marten, R.;\nHoiem, D.; and Kembhavi, A. 2024. Unified-IO 2: Scaling\nAutoregressive Multimodal Models with Vision Language\nAudio and Action. In Proceedings of the IEEE/CVF Confer-\nence on Computer Vision and Pattern Recognition , 26439–\n26455.\nLu, J.; Clark, C.; Zellers, R.; Mottaghi, R.; and Kembhavi,\nA. 2022. Unified-io: A unified model for vision, language,\nand multi-modal tasks. In The Eleventh International Con-\nference on Learning Representations.\nLuo, T.; Lei, J.; Lei, F.; Liu, W.; He, S.; Zhao, J.; and Liu,\nK. 2024a. Moelora: Contrastive learning guided mixture of\nexperts on parameter-efficient fine-tuning for large language\nmodels. arXiv preprint arXiv:2402.12851.\nLuo, Y .; Zhang, J.; Fan, S.; Yang, K.; Hong, M.; Wu, Y .;\nQiao, M.; and Nie, Z. 2024b. Biomedgpt: An open multi-\nmodal large language model for biomedicine. IEEE Journal\nof Biomedical and Health Informatics.\nMasoudnia, S.; and Ebrahimpour, R. 2014. Mixture of ex-\nperts: a literature survey. Artificial Intelligence Review, 42:\n275–293.\nMoor, M.; Huang, Q.; Wu, S.; Yasunaga, M.; Dalmia, Y .;\nLeskovec, J.; Zakka, C.; Reis, E. P.; and Rajpurkar, P. 2023.\nMed-flamingo: a multimodal medical few-shot learner. In\nMachine Learning for Health (ML4H), 353–367. PMLR.\nNath, V .; Li, W.; Yang, D.; Myronenko, A.; Zheng, M.; Lu,\nY .; Liu, Z.; Yin, H.; Law, Y . M.; Tang, Y .; et al. 2024. Vila-\nm3: Enhancing vision-language models with medical expert\nknowledge. arXiv preprint arXiv:2411.12915.\nOpenAI. 2023. GPT-4V(ision) System Card. https://cdn.\nopenai.com/papers/GPTV System Card.pdf.\nPan, K.; Tang, S.; Li, J.; Fan, Z.; Chow, W.; Yan, S.;\nChua, T.-S.; Zhuang, Y .; and Zhang, H. 2024. Auto-\nEncoding Morph-Tokens for Multimodal LLM. arXiv\npreprint arXiv:2405.01926.\nRadford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.;\nAgarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;\net al. 2021. Learning transferable visual models from nat-\nural language supervision. In International conference on\nmachine learning, 8748–8763. PMLR.\nSinghal, K.; Azizi, S.; Tu, T.; Mahdavi, S. S.; Wei, J.; Chung,\nH. W.; Scales, N.; Tanwani, A.; Cole-Lewis, H.; Pfohl, S.;\net al. 2023. Large language models encode clinical knowl-\nedge. Nature, 620(7972): 172–180.\nTeam, C. 2024. Chameleon: Mixed-modal early-fusion\nfoundation models. arXiv preprint arXiv:2405.09818.\nThawkar, O.; Shaker, A.; Mullappilly, S. S.; Cholakkal,\nH.; Anwer, R. M.; Khan, S.; Laaksonen, J.; and Khan,\nF. S. 2023. Xraygpt: Chest radiographs summarization\nusing medical vision-language models. arXiv preprint\narXiv:2306.07971.\nThummerer, A.; van der Bijl, E.; Galapon Jr, A.; Verhoeff,\nJ. J.; Langendijk, J. A.; Both, S.; van den Berg, C. N. A.;\nand Maspero, M. 2023. SynthRAD2023 Grand Challenge\ndataset: Generating synthetic CT for radiotherapy. Medical\nphysics, 50(7): 4664–4674.\nTian, D.; Jiang, S.; Zhang, L.; Lu, X.; and Xu, Y . 2023. The\nrole of large language models in medical image processing:\na narrative review. Quantitative Imaging in Medicine and\nSurgery, 14(1): 1108.\nTong, S.; Fan, D.; Zhu, J.; Xiong, Y .; Chen, X.; Sinha, K.;\nRabbat, M.; LeCun, Y .; Xie, S.; and Liu, Z. 2024. Meta-\nMorph: Multimodal Understanding and Generation via In-\nstruction Tuning. arXiv preprint arXiv:2412.14164.\nTu, T.; Azizi, S.; Driess, D.; Schaekermann, M.; Amin, M.;\nChang, P.-C.; Carroll, A.; Lau, C.; Tanno, R.; Ktena, I.; et al.\n2024. Towards generalist biomedical AI. NEJM AI, 1(3):\nAIoa2300138.\nVig, J. 2019. A multiscale visualization of attention in the\ntransformer model. arXiv preprint arXiv:1906.05714.\nWang, X.; Zhang, X.; Luo, Z.; Sun, Q.; Cui, Y .; Wang, J.;\nZhang, F.; Wang, Y .; Li, Z.; Yu, Q.; et al. 2024a. Emu3:\nNext-token prediction is all you need. arXiv preprint\narXiv:2409.18869.\n10']","AI-driven systems address security concerns by implementing security gates at various points within the system and continuously monitoring the activities of agents to ensure they do not exceed their access parameters, thus maintaining the integrity and security of the system. This is crucial as the attack space evolves and the presence of malicious agents or bots becomes a growing concern. In terms of delivering business value, AI products must focus on scalability and production readiness, with organizations viewing AI as a means to enhance processes rather than an end goal. The effectiveness of AI tools should be measured to ensure they truly deliver value. Medical visual question answering, as exemplified by datasets like Slake, plays a role in enhancing these systems by providing semantically-labeled knowledge that can improve the comprehension and visualization capabilities of AI in medical contexts, thereby contributing to the overall effectiveness and value of AI-driven healthcare solutions.",multi_hop_abstract_query_synthesizer
How do security considerations in AI-driven systems impact the automation of data aggregation and user activity creation?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2588.24s] Data Aggregation and Automation\nWith the connections set up, the next objective is to interact with these APIs to retrieve and aggregate data. This process will involve creating a user activity type. The BI copilot feature, introduced earlier, will assist in this development. The copilot can automate tasks by executing commands based on user input.\n\nAn empty automation project has been created, and the copilot will be instructed to complete the automation for creating user activity based on previous bookings and reviews. Although this request may seem abstract, the copilot is expected to understand the context due to the established connections and connectors.']","Security considerations in AI-driven systems impact the automation of data aggregation and user activity creation by necessitating the implementation of security gates and continuous monitoring to prevent malicious agents from launching attacks. As automation involves interacting with APIs to retrieve and aggregate data, ensuring that these processes are secure is crucial. The presence of security measures helps maintain the integrity and security of the system, allowing the BI copilot to automate tasks such as creating user activity based on previous bookings and reviews without the risk of unauthorized access or data breaches.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and what role does HealthGPT play in enhancing agent capabilities?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nAppendix\nThis is the Appendix for “HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation\nvia Heterogeneous Knowledge Adaptation”. This Appendix is organized as follows:\n• Section A presents the experimental implementation details, the training process of HealthGPT, and the specifics of\nVL-Health.\n• Section B systematically provides an analysis of Heterogeneous Low-Rank Adaptation.\n• Section C shows supplementary experimental results to validate the effectiveness ofHealthGPT.\nA Implementation Details\nA.1 Model Details\nWe employ CLIP-L/14 (Radford et al. 2021) as the visual feature extractor, extracting both shallow and deep features to serve as\nvisual tokens. The model uses alignment adapters, implemented with two-layer MLPs, to align shallow features, representing\nconcrete visual granularity, and deep features, representing abstract visual granularity. These visual tokens are concatenated\nwith text tokens and input into the large language models (LLMs).\nHealthGPT offers two versions: HealthGPT-M3 and HealthGPT-L14, which are based on Phi-3-mini (Abdin et al.\n2024) and Phi-4 (Abdin et al. 2024) as the pre-trained LLMs, respectively. In addition, we expand the LLM vocabulary with\n8192 VQ indices derived from VQGAN-f8-8192 (Esser, Rombach, and Ommer 2021), serving as multi-modal tokens to further\naugment the model’s capacity for understanding both visual and textual input. Figure 6 shows the details.\nTable 6: Overview of the Components of HealthGPT.\nModel ViT Adapter MLP-dims Model dims LLM Params Vocab Size H-LoRA Rank\nHealthGPT-M3 CLIP-L/14 2-layer MLP 1024 3072 Phi-3-mini 3.8B 40206 16(Comp.), 64(Gen.)\nHealthGPT-L14 CLIP-L/14 2-layer MLP 1024 5120 Phi-4 14B 108547 8(Comp.), 32(Gen.)\nA.2 Training Details\nIn this study, we propose a three-stage learning strategy that is compatible with our innovative heterogeneous low-rank adapta-\ntion (H-LoRA). We provide a detailed hyperparameter configuration for the model’s three-stage training process. The specific\nhyperparameter settings used are listed in Table 7. These hyperparameters are crucial for ensuring the model’s learning efficacy\nand final performance.\nTable 7: Overview of Hyperparameter Configurations.\nHealthGPT-M3 HealthGPT-L14\nStage-1 Stage-2 Stage-3 Stage-1 Stage-2 Stage-3Hyperparameter\nComp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen.\nOptimizer AdamW AdamW AdamW AdamW AdamW AdamW\nAdapter LR 1e-3 2e-5 2e-5 2e-5 1e-3 2e-5 2e-5 2e-5\nLearning Rate / 2e-4 2e-4 2e-4 / 1e-4 2e-4 2e-4\nGlobal Batch Size 256 64 32 128 64 256 64 32 128 64\nWeight Decay 0 0 0 0 0 0\nDropout Rate 0 0.05 0.05 0.05 0 0.05 0.05 0.05\nLR Scheduler Warm Up Constant Warm Up Warm Up Constant Warm Up\nMax Sequence Length 2048 2048 2048 2048 2048 2048\nIt is worth noting that we sometimes observe instances of loss spikes during the training of medical visual comprehension\nand generation tasks. Through repeated validation, we discovered that larger model parameters and learning rates tend to lead to\nthis issue, which is the reason for the slight differences in hyperparameters betweenHealthGPT-M3 and HealthGPT-L14.\n12', ""<3-hop>\n\n## [1285.20s] Agent Capabilities\nThe agents possess several capabilities, including the ability to register and manage their identities. Administrators can access the management portal to create agents, assign unique identities, and manage their metadata. This metadata includes attributes such as the AI model being used, the agent's purpose, and its version. Administrators can also specify where the agent can be found, such as a URL if it is expected to be accessible over the internet. Furthermore, ownership and responsibility for each agent must be clearly defined, ensuring that someone is accountable for the agent's actions within the system.""]","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to ensure they do not exceed their access parameters, as mentioned in the context of security considerations. HealthGPT, a medical large vision-language model, enhances agent capabilities by providing advanced comprehension and generation tasks through heterogeneous knowledge adaptation. This includes using models like HealthGPT-M3 and HealthGPT-L14, which are equipped with features such as visual and text token alignment, and expanded vocabulary to improve understanding and interaction capabilities, thereby contributing to the overall robustness and functionality of AI-driven systems.",multi_hop_abstract_query_synthesizer
"How AI-driven systems make sure they safe and responsible, and how personalization help in this?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n**Time Range: 01:00:01 - 01:10:03**\n\n# [3601.20s] Ensuring Responsible AI Development\nThe development of artificial intelligence (AI) applications must be approached with a sense of responsibility. This involves adhering to emerging regulations and policies that aim to ensure the safety and ethical behavior of AI systems. To avoid potential issues, one effective strategy is the implementation of guardrails.\n\n## [3606.80s] The Role of Guardrails in AI\nGuardrails serve as constraints that ensure AI behaves safely and ethically, as intended. For instance, when a prompt is submitted to a large language model (LLM), it should not be sent directly. Instead, it must first pass through a series of guardrails that check for potential issues such as personal information (PI) detection, proprietary information, or attempts to manipulate the model (jailbreaking). Only when these guardrails are satisfied will the prompt be forwarded to the LLM.\n\nOnce the output is generated, additional guardrails are necessary to address potential issues such as censorship, hallucinations, or discussions of sensitive topics. For example, certain topics, like the ongoing conflict in Israel and Palestine, may require censorship within specific organizational contexts. Thus, guardrails must be applied to both the input sent to the LLM and the output received from it.', '<3-hop>\n\n## [1311.36s] Personalization and Database Population\nWith the personalization established, the system will utilize a trip planning agent to retrieve personalization information from the database. Before accessing the database, an activity analyzer will populate it with user personalization profiles.\n\n### [1335.20s] Addressing Contact Us Functionality\nThe next challenge involves rethinking the ""Contact Us"" feature. Currently, users must contact hotels directly, and hotel staff manually respond. As a booking platform, the team cannot intervene until a response is received from the hotel staff. The future vision is to implement an assistant that can respond on behalf of hotel staff, providing users with real-time or near-real-time answers and more consistent responses.']","AI-driven systems ensure safety and responsibility by implementing security measures and guardrails. Security considerations involve continuous monitoring to track malicious agents and ensure they do not exceed their access parameters, maintaining system integrity. Responsible AI development involves adhering to regulations and using guardrails to ensure AI behaves ethically. Guardrails check for issues like personal information detection and manipulation attempts before processing inputs and outputs. Personalization contributes by using a trip planning agent to retrieve user profiles from a database, enhancing user experience while maintaining system security and integrity.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while enhancing user experience through multimodal understanding?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nWang, Z.; Wu, Z.; Agarwal, D.; and Sun, J. 2022. Medclip:\nContrastive learning from unpaired medical images and text.\narXiv preprint arXiv:2210.10163.\nWang, Z.; Zhang, L.; Wang, L.; and Zhang, Z. 2024b. Soft\nMasked Mamba Diffusion Model for CT to MRI Conver-\nsion. arXiv preprint arXiv:2406.15910.\nWu, C.; Chen, X.; Wu, Z.; Ma, Y .; Liu, X.; Pan, Z.; Liu, W.;\nXie, Z.; Yu, X.; Ruan, C.; and Luo, P. 2024. Janus: Decou-\npling Visual Encoding for Unified Multimodal Understand-\ning and Generation. arXiv:2410.13848.\nWu, S.; Fei, H.; Qu, L.; Ji, W.; and Chua, T.-S. 2023.\nNext-gpt: Any-to-any multimodal llm. arXiv preprint\narXiv:2309.05519.\nXie, J.; Mao, W.; Bai, Z.; Zhang, D. J.; Wang, W.; Lin, K. Q.;\nGu, Y .; Chen, Z.; Yang, Z.; and Shou, M. Z. 2024. Show-o:\nOne single transformer to unify multimodal understanding\nand generation. arXiv preprint arXiv:2408.12528.\nYoung, A.; Chen, B.; Li, C.; Huang, C.; Zhang, G.; Zhang,\nG.; Li, H.; Zhu, J.; Chen, J.; Chang, J.; et al. 2024.\nYi: Open foundation models by 01. ai. arXiv preprint\narXiv:2403.04652.\nZhou, H.; Liu, F.; Gu, B.; Zou, X.; Huang, J.; Wu, J.; Li,\nY .; Chen, S. S.; Zhou, P.; Liu, J.; et al. 2023. A survey of\nlarge language models in medicine: Progress, application,\nand challenge. arXiv preprint arXiv:2311.05112.\nZhu, J.-Y .; Park, T.; Isola, P.; and Efros, A. A. 2017. Un-\npaired image-to-image translation using cycle-consistent ad-\nversarial networks. InProceedings of the IEEE international\nconference on computer vision, 2223–2232.\n11', '<3-hop>\n\n## [849.12s] Introduction of Agentic Capabilities\nFollowing the traditional booking demonstration, the introduction of agentic capabilities into the system will be discussed. The existing components remain intact, secured by traditional identity and access management principles. Two agents will be integrated into the booking system. The first agent allows users to interact directly through an intelligent chat interface, capable of understanding natural language and providing suggestions for bookings. This agent utilizes the same backend APIs and services to enhance user experience and connects to an AI model to perform its functions.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring the activities of agents to prevent them from acting outside their intended purpose, as mentioned in the context of security considerations. Meanwhile, user experience is enhanced through the integration of agentic capabilities, such as intelligent chat interfaces that utilize multimodal understanding to interact with users and provide suggestions, as described in the introduction of agentic capabilities. This integration allows for a seamless interaction while maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and how does the use of Large Language Models (LLMs) contribute to personalized healthcare applications?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2816.00s] Calling the LLM for Personalized Profiles\nWith the data structure established, the next step involves calling the LLM (Large Language Model) using the gathered data. The objective is to create a personalized profile for the user. This process does not require an agent or retrieval-augmented generation; instead, it focuses on directly utilizing the LLM.\n\nTo facilitate this, a connection to the model provider has been created. A prompt will be generated for the LLM, specifying the need for a personalized profile. It is crucial to be precise in the prompt to ensure an accurate response. A comprehensive prompt has been prepared and will be used to guide the LLM in generating the desired output.', '<3-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to ensure they do not exceed their access parameters or act outside their intended purpose. This approach is crucial for maintaining the integrity and security of the system. In the context of healthcare applications, Large Language Models (LLMs) are used to create personalized profiles for users by directly utilizing the LLM without the need for an agent or retrieval-augmented generation. This involves generating a precise prompt for the LLM to ensure an accurate response, which is essential for tailoring healthcare solutions to individual needs.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems address security concerns while also enhancing business operations, considering the challenges in AI scalability?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.', '<3-hop>\n\n## [77.52s] Understanding AI Transformation\nAI transformation is a term that, while not universally adopted, is gaining traction in discussions about enhancing business operations. The fundamental idea is to leverage AI to improve various aspects of an organization, leading to increased productivity, efficiency, and user experience. Additionally, AI can unlock new capabilities that were previously unattainable.\n\nAI has emerged as a powerful tool, particularly with the advent of generative AI. This technology allows us to create solutions that were once complex and resource-intensive, such as chatbots. Previously, developing a chatbot required extensive rule-based or knowledge-based systems. Now, it is as simple as writing a prompt and connecting to a large language model (LLM) with minimal financial investment.\n\nThe current landscape presents numerous opportunities, and businesses must adapt to these new capabilities to remain competitive. Failing to embrace AI transformation could result in falling behind in a rapidly evolving market, where many organizations are striving to enhance their operations through AI.']","AI-driven systems address security concerns by implementing security gates at various points within the system and continuously monitoring for malicious agents or bots to maintain system integrity. This is crucial as the attack space evolves, and it is important to assume a breach to protect the system. At the same time, AI transformation is enhancing business operations by leveraging AI to improve productivity, efficiency, and user experience. Despite challenges in AI scalability, improvements in speed are facilitating real-time interactions, which are accessible both in the cloud and at the edge, allowing businesses to adapt and remain competitive in a rapidly evolving market.",multi_hop_abstract_query_synthesizer
"How AI-driven systems and generative applications relate to hotel booking, and what security considerations are there?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [757.12s] Structure of Effective Prompts\nWhen building generative applications, the structure of the prompt is essential. Initially, the role is defined, indicating that the model should impersonate a specific personality, such as a Java developer. Following this, clear instructions are provided, detailing the expectations for generating accurate code. An output format is also specified, guiding the model on how to respond.\n\n## [1885.76s] The Value of Actionable AI Applications\nAn interesting question arises when considering the utility of AI applications. For instance, is it more beneficial to have an AI application that instructs users on how to drive a car, or one that can actually drive the car for them? The latter represents a more practical application of AI, as it not only analyzes data but also takes action on behalf of the user or organization.', '<3-hop>\n\n## [728.00s] Traditional Booking Process\nThe demonstration will begin by showcasing the platform without agentic capabilities, reflecting the traditional booking methods used by platforms like Booking.com. In this traditional identity management (IM) setup, users interact with applications that connect to backend services. Users authenticate themselves through an identity provider, granting access to the application for task completion. This process does not incorporate any agentic features, which will be highlighted in the demo.\n\n### [785.60s] Booking a Hotel\nThe booking website is a standard interface where users can sign in and make reservations. The user will demonstrate the process by booking a hotel in Colombo. This traditional method requires manual navigation through the website to find and book a hotel, which is confirmed upon completion.']","AI-driven systems, when applied to hotel booking, can enhance the traditional process by potentially automating tasks that require manual navigation, such as finding and booking a hotel. However, security considerations are crucial in these systems, as there is a risk of malicious agents or bots launching attacks. Continuous monitoring and implementing security gates are essential to maintain system integrity. Generative applications, which rely on structured prompts, can also play a role in improving user interaction by providing clear instructions and expected outcomes, potentially streamlining the booking process. Despite these advancements, the traditional booking process, as demonstrated by platforms like Booking.com, still requires users to authenticate and manually navigate the website to complete reservations.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security and governance, especially when using small language models, given the potential for malicious agents and the need for compliance with regulations like GDPR?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [339.04s] Governance of AI Agents\nThe governance of AI agents is essential to prevent unauthorized actions. For instance, if an AI agent designed for marketing data gains admin rights to a financial system, it could perform unnecessary transactions or expose sensitive customer information.\n\n### [377.28s] Importance of Auditability\nAuditability is vital in agentic systems, as agents operate at high speeds, making changes to APIs and databases. Tracking these actions is necessary for forensic purposes, allowing organizations to trace who did what and when.\n\n### [419.12s] Compliance and Governance Requirements\nOrganizations must also navigate governance and compliance requirements, such as GDPR, to protect user data and prevent misuse of AI capabilities. The speakers stress that while AI is not inherently bad, it is essential to employ AI securely and govern access effectively to maximize its benefits.', '<3-hop>\n\n**Time Range: 01:10:01 - 01:20:03**\n\n# [990.00s] Insights on Small Language Models\nWe have been working with small language models for nearly a year, primarily focusing on translation tasks. Initially, we started with a very small model designed for machine translation, covering around 100 languages and operating on CPU, which was cost-effective. However, as we have scaled up and increased the number of parameters, the computational requirements have also risen. \n\nWhile using API keys may seem inexpensive initially, extensive usage can lead to significant costs, sometimes reaching $15,000 to $20,000 per month. This highlights the difference between a pay-as-you-go model and having an in-house solution, where a single server costing around $5,000 can meet all operational needs. However, this shift also introduces challenges, such as managing toxicity and hallucination in outputs, necessitating the implementation of additional safeguards that may cause delays.\n\nDespite these challenges, if generative AI can effectively complete tasks, the trade-off may be worthwhile. Users may express concerns about processing times, but when comparing a task that previously took three days to one that now takes three minutes, the benefits become clear.']","AI-driven systems ensure security by implementing security gates and continuous monitoring to track the activities of agents, preventing them from acting outside their intended purpose or exceeding access parameters. Governance of AI agents is crucial to prevent unauthorized actions, such as an AI agent gaining admin rights to a financial system and performing unnecessary transactions. Compliance with regulations like GDPR is necessary to protect user data and prevent misuse of AI capabilities. When using small language models, organizations face challenges such as managing toxicity and hallucination in outputs, which require additional safeguards. Despite these challenges, the benefits of generative AI, such as significantly reduced processing times, can outweigh the trade-offs.",multi_hop_abstract_query_synthesizer
How multi-agent systems and security considerations work together with external data integration?,"['<1-hop>\n\n### [1092.16s] Supervisor Pattern\nOne notable pattern in multi-agent systems is the supervisor pattern. This pattern features a centralized supervisor agent that manages the flow of operations, determining which agent to invoke next. The supervisor agent can function as a fully reactive agent, capable of reasoning and acting, or as a simple router that directs tasks based on specific conditions.\n\nWithin this pattern, two variants of handoff are observed. The first is an agent-to-agent handoff, where control is transferred to a sub-agent along with full context and memory access. The second variant treats the agent as a tool, where the agent operates without full control, allowing for specific functionalities to be executed without transferring complete authority.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<3-hop>\n\n## [904.16s] Enhancing Applications with External Data\nHowever, a more advanced approach involves integrating APIs, databases, and real-world data into applications. This integration is powerful as it addresses the knowledge cutoff issues inherent in models, which may only possess limited or outdated information. For enterprises, this presents a significant advantage, as private data can be incorporated into the model, providing insights that are not accessible to external models.\n\n### [963.44s] Practical Application Example\nFor example, in the WS Corn application, a feature suggests sessions based on user preferences using AI. A background agent collects basic information about the user, such as their name and job title, and can perform web scraping to gather relevant technical interests. This data is stored in a database alongside an updated agenda or session timetable accessible via an API.']","In multi-agent systems, the supervisor pattern is used to manage operations, where a centralized supervisor agent determines which agent to invoke next. This pattern can involve agent-to-agent handoffs or treating agents as tools for specific functionalities. Security considerations in AI-driven systems are crucial, especially with the presence of malicious agents or bots. Continuous monitoring and security gates are necessary to ensure agents do not exceed their access parameters. External data integration enhances applications by incorporating APIs, databases, and real-world data, addressing knowledge cutoff issues and providing insights not accessible to external models. This integration can be seen in applications like WS Corn, where AI suggests sessions based on user preferences by collecting and storing user data in a database, accessible via an API.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and what role does the administrative portal play in managing these agents, considering the technologies available for building integrations?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1600.32s] Logging into the Administrative Portal\nThe presenter logs into the administrative portal of Asgardio, where they have pre-configured various settings. They will demonstrate how to create a new agent and manage its attributes.\n\n## [1645.52s] Creating and Configuring an Agent\nIn the portal, there is a dedicated section for agents. The presenter discusses the process of creating a new agent, including providing a description and generating a unique ID and secret for authentication. The system allows for the management of various attributes, which can be customized based on business requirements.', '<3-hop>\n\n## [2741.04s] Technologies for Building Integrations\nTo develop and deploy general integrations, we can utilize the WSU IP pass, which supports the integration and deployment of various workflows, including agents and RAG. Developers can use their preferred programming languages and frameworks, such as Python, Semantic Kernel, or LangChain, to build and deploy these integrations.\n\n# [2786.08s] Standardizing Integration Processes\nNext, we will discuss how to standardize the integration of LLMs with external data and APIs. The Model Context Protocol (MCP) serves as a framework for this standardization, allowing for seamless connections between tools, resources, and prompts.']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to ensure they do not exceed their access parameters. This is crucial for maintaining the integrity and security of the system. The administrative portal, such as Asgardio, plays a significant role in managing these agents by allowing the creation and configuration of new agents, including generating unique IDs and secrets for authentication. This portal provides a dedicated section for managing agent attributes, which can be customized based on business requirements. Additionally, technologies for building integrations, such as the WSU IP pass, support the integration and deployment of workflows, including agents, using various programming languages and frameworks like Python, Semantic Kernel, or LangChain. These technologies facilitate the development and deployment of secure and efficient integrations.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents and what role do closed source models play in maintaining clarity and transparency in outputs, considering the advancements in contrastive learning?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n**Time Range: 00:20:01 - 00:27:55**\n\n# [1201.28s] Importance of Using Closed Source Models\nTo achieve accurate answers, it is crucial to utilize a closed source model. This approach allows for the generation of predicted outputs, which can then be compared against the results from your own model. This comparison is essential for evaluating performance and ensuring clarity and transparency in the outputs.\n\n## [1225.36s] Evaluation Metrics for AI Models\nDifferent agents or tasks have their own specific metrics for evaluation. For instance, various frameworks such as DPAL and RO are available for out-of-the-box evaluation. These frameworks can be utilized directly or customized to fit specific needs.', '<3-hop>\n\nWang, Z.; Wu, Z.; Agarwal, D.; and Sun, J. 2022. Medclip:\nContrastive learning from unpaired medical images and text.\narXiv preprint arXiv:2210.10163.\nWang, Z.; Zhang, L.; Wang, L.; and Zhang, Z. 2024b. Soft\nMasked Mamba Diffusion Model for CT to MRI Conver-\nsion. arXiv preprint arXiv:2406.15910.\nWu, C.; Chen, X.; Wu, Z.; Ma, Y .; Liu, X.; Pan, Z.; Liu, W.;\nXie, Z.; Yu, X.; Ruan, C.; and Luo, P. 2024. Janus: Decou-\npling Visual Encoding for Unified Multimodal Understand-\ning and Generation. arXiv:2410.13848.\nWu, S.; Fei, H.; Qu, L.; Ji, W.; and Chua, T.-S. 2023.\nNext-gpt: Any-to-any multimodal llm. arXiv preprint\narXiv:2309.05519.\nXie, J.; Mao, W.; Bai, Z.; Zhang, D. J.; Wang, W.; Lin, K. Q.;\nGu, Y .; Chen, Z.; Yang, Z.; and Shou, M. Z. 2024. Show-o:\nOne single transformer to unify multimodal understanding\nand generation. arXiv preprint arXiv:2408.12528.\nYoung, A.; Chen, B.; Li, C.; Huang, C.; Zhang, G.; Zhang,\nG.; Li, H.; Zhu, J.; Chen, J.; Chang, J.; et al. 2024.\nYi: Open foundation models by 01. ai. arXiv preprint\narXiv:2403.04652.\nZhou, H.; Liu, F.; Gu, B.; Zou, X.; Huang, J.; Wu, J.; Li,\nY .; Chen, S. S.; Zhou, P.; Liu, J.; et al. 2023. A survey of\nlarge language models in medicine: Progress, application,\nand challenge. arXiv preprint arXiv:2311.05112.\nZhu, J.-Y .; Park, T.; Isola, P.; and Efros, A. A. 2017. Un-\npaired image-to-image translation using cycle-consistent ad-\nversarial networks. InProceedings of the IEEE international\nconference on computer vision, 2223–2232.\n11']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to ensure they do not exceed their access parameters. This is crucial for maintaining the integrity and security of the system. Closed source models play a role in maintaining clarity and transparency in outputs by allowing for the generation of predicted outputs that can be compared against results from one's own model, which is essential for evaluating performance. Additionally, advancements in contrastive learning, such as those demonstrated in Medclip, highlight the potential for improved understanding and generation in AI systems, further enhancing their capabilities.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems incorporate security features to prevent malicious activities, and what role does jailbreak detection play in this context?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [4435.28s] Overview of Security Features\nThe key highlights include security rate limiting, various configured guardrails, jailbreak detection, illegal events, and violence filters.\n\n## [4455.28s] Jailbreak Detection\nA demonstration of jailbreak detection is also planned. A prompt is submitted that instructs the model to disregard previous instructions and simply answer a basic arithmetic question, ""What is 2 + 2?"" This attempt to change the subject can be detected by the guardrails.\n\n## [4491.52s] Utilizing AWS Bedrock for Demonstration\nFor this demonstration, AWS Bedrock is utilized, but similar capabilities can be achieved with guardless AI deployments to capture such events. Users are encouraged to explore these features further.']","AI-driven systems incorporate security features such as security rate limiting, configured guardrails, jailbreak detection, illegal events, and violence filters to prevent malicious activities. Continuous monitoring is essential to track the activities of malicious agents or bots, ensuring they do not exceed their access parameters. Jailbreak detection plays a crucial role by identifying attempts to bypass system instructions, such as when a prompt instructs the model to disregard previous instructions and answer a basic arithmetic question. This is detected by the guardrails, maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
"In the context of healthcare, how can the integration of vertical AI help mitigate the risks posed by malicious agents in AI-driven systems?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n## [25.28s] Discussion on Vertical AI\nThe focus of today's discussion is on vertical AI, which is a significant aspect of the ongoing track dedicated to specialized AI applications. Before delving into vertical AI, it is essential to clarify what generic AI entails.\n\n### [38.24s] Understanding Generic AI\nGeneric AI, often referred to as general-purpose AI, has been widely used for various personal and business tasks. It is designed to handle a broad range of applications. However, we are transitioning from this general-purpose AI, which is built for diverse uses, to a more specialized form known as vertical AI. This shift allows for the development of specific AI solutions tailored to industries such as healthcare, legal, and financial services.""]","The integration of vertical AI in healthcare can help mitigate the risks posed by malicious agents in AI-driven systems by developing specialized AI solutions tailored to the healthcare industry. These solutions can incorporate robust security measures, such as continuous monitoring and security gates, to track and control the activities of malicious agents. By focusing on industry-specific needs, vertical AI can enhance the security and integrity of healthcare systems, ensuring that malicious agents do not exceed their access parameters or act outside their intended purpose.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems address security concerns, and what role does H-LoRA play in enhancing medical visual comprehension and generation tasks?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8']","AI-driven systems address security concerns by assuming a breach and implementing security gates at various points within the system. Continuous monitoring is essential to track the activities of malicious agents or bots, ensuring they do not exceed their access parameters, thus maintaining the integrity and security of the system. In the context of medical visual comprehension and generation tasks, H-LoRA plays a significant role by consistently outperforming other methods, such as LoRA and MoELoRA, in various scenarios. It demonstrates significant advantages in handling diverse tasks, particularly through a three-stage learning strategy that decouples comprehension and generation tasks, reducing performance degradation from task conflicts. This approach effectively uses medical embedding knowledge in pre-trained LLMs to mitigate conflicts, showcasing H-LoRA's potential in enhancing healthcare applications.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while utilizing the Egress AI Gateway and Code for AI?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [846.64s] Code for AI\nMoving on to ""Code for AI,"" this involves providing building blocks for developing AI-related capabilities. An example is the MCP server, which converts a standard API into a tool that an AI agent can easily communicate with. WSO2 offers pre-built support to convert any FHIR server, such as an EHR server, into an MCP server, allowing direct communication with AI agents.\n\nA demonstration illustrates this user experience. When a user enters a healthcare-specific prompt, the system redirects to an authorization flow where the user must provide consent for the agent to access their data. The AI agent then calls the APIs using the MCP server to access the records. For example, if the prompt is about recorded immunizations, the AI agent retrieves the relevant health records. This capability is significant because a horizontal AI would lack the knowledge to interact with EHR systems and would require server-side enablement via the MCP server.', '<3-hop>\n\n## [2721.68s] Features of the Egress AI Gateway\nAs organizations grow their AI teams and adopt various AI services, the need for a mediation layer becomes apparent. This layer allows organizations to manage interactions with multiple AI providers without being dependent on a single one. \n\nThe egress AI gateway offers several features, including model routing, token-based rate limiting, AI guard, prompt management, adaptive routing, and semantic caching. Additionally, it retains the standard capabilities of an ingress gateway, such as analytics, identity access management, and mediation capabilities. Organizations can connect with any AI service, and the product comes pre-configured with a set of services while allowing for custom configurations.']","AI-driven systems ensure security by implementing security gates and continuous monitoring to track the activities of agents, as mentioned in the context of AI-driven systems. The Egress AI Gateway provides a mediation layer that includes features like AI guard and token-based rate limiting, which help manage interactions securely with multiple AI providers. Additionally, the Code for AI involves converting standard APIs into tools that AI agents can communicate with, ensuring secure access through authorization flows and consent for data access, as demonstrated with the MCP server.",multi_hop_abstract_query_synthesizer
"Hw do AI-driven systms ensure security and observability, and what is a use case demonstration of API usage with guardrails?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4142.16s] Observability and Logging\nFinally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant.\n\n**Time Range: 01:10:00 - 01:18:25**\n\n# [4200.40s] Introduction to API Usage with Guardrails\nBefore attempting to use the API with Guardrails, it is essential to understand how a use case would appear without these protective measures. In this demonstration, a query related to firearms is posed, which is not an appropriate topic for a hotel assistant.']","AI-driven systems ensure security by assuming a breach and implementing security gates at various points within the system, along with continuous monitoring to track the activities of agents and maintain system integrity. Observability is achieved through logging policies that track and monitor all actions, allowing for effective management and governance of the AI gateway. A use case demonstration of API usage with guardrails involves understanding how a query, such as one related to firearms, would be handled without protective measures, highlighting the importance of these guardrails in maintaining appropriate interactions.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security against malicious agents while utilizing intelligent assistants with hidden states for medical data analysis?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1992.00s] Background Operations of the Agent\nThe intelligent assistant, integrated with the agent-aware system, had been working in the background to assign a concierge for the trip. This action did not require user permission, as it was a functionality granted by the business itself.\n\n# [2040.80s] Insights from the Guardio Console\nIn the Guardio console, the agent was assigned a unique identity, allowing it to be recognized throughout the ecosystem. The staff allocation agent also had its own identity. When the user previously made bookings manually, it utilized their token. However, when the agent made a booking, it used an ""on behalf of"" (OBO) token issued to the booking assistant agent.', '<3-hop>\n\nTo address the needs of various tasks, the hidden states\nare divided into two types: (i) Concrete-grained features\nFCon = {f1, f2, . . . , fk}, k < L, derived from the shal-\nlower layers of ViT, containing sufficient global features,\nsuitable for generation tasks; (ii) Abstract-grained features\nFAbs = {fk+1, fk+2, . . . , fL}, derived from the deeper\nlayers of ViT, which contain abstract semantic information\ncloser to the text space, suitable for comprehension tasks.\nThe task type T (comprehension or generation) deter-\nmines which set of features is selected as the input for the\ndownstream large language model:\nFimg\nT =\n(\nFCon, if T = generation task\nFAbs, if T = comprehension task (6)\nWe integrate the image featuresFimg\nT and text featuresT into\na joint sequence through simple concatenation, which is then\nfed into the LLM Mllm for autoregressive generation.\n4.3 Heterogeneous Knowledge Adaptation\nWe devise H-LoRA, which stores heterogeneous knowledge\nfrom comprehension and generation tasks in separate mod-\nules and dynamically routes to extract task-relevant knowl-\nedge from these modules. At the task level, for each task type\nT, we dynamically assign a dedicated H-LoRA submodule\nθT , which is expressed as:\nR = MLLM(U|θ, θT ), θ T = {AT , BT , RT\nouter}. (7)\nAt the feature level for a single task, H-LoRA integrates the\nidea of Mixture of Experts (MoE) (Masoudnia and Ebrahim-\npour 2014) and designs an efficient matrix merging and rout-\ning weight allocation mechanism, thus avoiding the signif-\nicant computational delay introduced by matrix splitting in\nexisting MoELoRA (Luo et al. 2024a). Specifically, we first\nmerge the low-rank matrices (rank = r) of k LoRA experts\ninto a unified matrix:\nAmerged, Bmerged = Concat({Ai}k\n1 ), Concat({Bi}k\n1 ), (8)\nwhere Amerged ∈ Rdin×rk and Bmerged ∈ Rrk×dout\n. The\nk-dimension routing layer generates expert weights W ∈\nRtoken num×k based on the input hidden state x, and these are\nexpanded to Rtoken num×rk as follows:\nWexpanded = αkW/r ⊗ 1r, (9)\nwhere ⊗ denotes the replication operation. The overall out-\nput of H-LoRA is computed as:\nOH-LoRA = (xAmerged ⊙ Wexpanded)Bmerged, (10)\nwhere ⊙ represents element-wise multiplication. Finally, the\noutput of H-LoRA is added to the frozen pre-trained weights\nto produce the final output:\nO = xW0 + OH-LoRA. (11)\n900\n800\n700\n600\n500\n400\n300\n200\n100\n0\nComp. Gen.\n(a) (b)\n783K765K\n（K）\nFigure 4: Data statistics of VL-Health.\n4.4 Training Pipeline\n1st Stage: Multi-modal Alignment. In the first stage, we\ndesign separate visual adapters and H-LoRA submodules for\nmedical unified tasks. For the medical comprehension task,\nwe train abstract-grained visual adapters using high-quality\nimage-text pairs to align visual embeddings with textual\nembeddings, thereby enabling the model to accurately de-\nscribe medical visual content. During this process, the pre-\ntrained LLM and its corresponding H-LoRA submodules\nremain frozen. In contrast, the medical generation task re-\nquires training concrete-grained adapters and H-LoRA sub-\nmodules while keeping the LLM frozen. Meanwhile, we ex-\ntend the textual vocabulary to include multimodal tokens,\nenabling the support of additional VQGAN vector quanti-\nzation indices. The model trains on image-VQ pairs, en-\ndowing the pre-trained LLM with the capability for image\nreconstruction. This design ensures pixel-level consistency\nof pre- and post-LVLM. The processes establish the initial\nalignment between the LLM’s outputs and the visual inputs.\n2nd Stage: Heterogeneous H-LoRA Plugin Adaptation.\nThe submodules of H-LoRA share the word embedding\nlayer and output head but may encounter issues such as\nbias and scale inconsistencies during training across dif-\nferent tasks. To ensure that the multiple H-LoRA plugins\nseamlessly interface with the LLMs and form a unified base,\nwe fine-tune the word embedding layer and output head us-\ning a small amount of mixed data to maintain consistency\nin the model weights. Specifically, during this stage, all H-\nLoRA submodules for different tasks are kept frozen, with\nonly the word embedding layer and output head being op-\ntimized. Through this stage, the model accumulates foun-\ndational knowledge for unified tasks by adapting H-LoRA\nplugins.\n3rd Stage: Visual Instruction Fine-Tuning. In the third\nstage, we introduce additional task-specific data to fur-\nther optimize the model and enhance its adaptability to\ndownstream tasks such as medical visual comprehension\n(e.g., medical QA, medical dialogues, and report generation)\nor generation tasks (e.g., super-resolution, denoising, and\n5']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to maintain system integrity. This is crucial as the attack space evolves, and it is always assumed that a breach could occur. Meanwhile, intelligent assistants integrated into these systems operate in the background, performing tasks such as assigning a concierge without requiring user permission, as part of their granted functionalities. These assistants utilize hidden states, which are divided into concrete-grained and abstract-grained features, to perform tasks like medical data analysis. The hidden states are processed through a system like H-LoRA, which dynamically routes task-relevant knowledge for comprehension or generation tasks, ensuring efficient and secure handling of medical data.",multi_hop_abstract_query_synthesizer
"What are the security considerations for implementing an AI agent in user-absent flows, such as paying bills?","['<1-hop>\n\n### [1160.32s] User-Absent Flow with Ambient Agents\nThe second use case involves user-absent flows, referred to as ambient agents. These agents operate in the background, executing tasks without direct user interaction. An example is Bill, who wants an AI agent to pay his electricity bill when two conditions are met, the first being that the bill needs to be ready. This concept can be applied to various complex and innovative scenarios.\n\n**Time Range: 00:20:02 - 00:23:20**\n\n# [1202.40s] Salary Remittance Process\nThe salary should be remitted as part of the payment process. This is how it works: the first build provides this requirement to the AI agent, which listens to a service provider to determine whether the bill is ready. The AI agent then calls a bank endpoint or monitors SMS or email notifications to check if the salary has been remitted.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","When implementing an AI agent in user-absent flows, such as paying bills, it is crucial to consider security aspects due to the potential presence of malicious agents or bots that can launch attacks. It is important to assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to ensure that the AI agents do not act outside their intended purpose or exceed their access parameters, thereby maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
"How do AWS guardrails enhance security in AI-driven systems, particularly in handling violence-related prompts?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4280.56s] Introduction of Guardrails\nTo address these concerns, an AWS guardrail has been configured to include a violence filter, which detects any prompts related to violence. The same prompt is then submitted to the hotel booking assistant to observe how the response differs.\n\n## [4311.92s] Response with Guardrails\nUpon submitting the prompt, the AWS guardrail identifies that the query pertains to a violence-based topic and fails the request. This mechanism allows for better control over how egress calls are managed.\n\n## [4331.36s] PII Detection Demonstration\nNext, a demonstration of Personally Identifiable Information (PII) detection is presented. A user might inadvertently share their email address without realizing the potential for it to be leaked. When the user submits their email, the LLM responds with a standard message, thanking them for sharing their email address and asking how it can assist further.']","AWS guardrails enhance security in AI-driven systems by incorporating mechanisms such as a violence filter, which detects prompts related to violence. When a violence-based query is submitted, the AWS guardrail identifies the nature of the query and fails the request, thereby preventing inappropriate or harmful content from being processed. This approach allows for better control over egress calls and contributes to maintaining the integrity and security of AI-driven systems.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while also enabling personalization in user profiles?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1311.36s] Personalization and Database Population\nWith the personalization established, the system will utilize a trip planning agent to retrieve personalization information from the database. Before accessing the database, an activity analyzer will populate it with user personalization profiles.\n\n### [1335.20s] Addressing Contact Us Functionality\nThe next challenge involves rethinking the ""Contact Us"" feature. Currently, users must contact hotels directly, and hotel staff manually respond. As a booking platform, the team cannot intervene until a response is received from the hotel staff. The future vision is to implement an assistant that can respond on behalf of hotel staff, providing users with real-time or near-real-time answers and more consistent responses.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring the activities of agents to prevent them from acting outside their intended purpose or exceeding their access parameters. This is crucial for maintaining the integrity and security of the system. Simultaneously, personalization is achieved by utilizing a trip planning agent that retrieves personalization information from a database, which is populated by an activity analyzer with user personalization profiles. This dual approach allows for secure and personalized user experiences.",multi_hop_abstract_query_synthesizer
How AI-driven systems handle security with malicious agents and how AI agent integration works with tools?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.']","In AI-driven systems, handling security involves assuming a breach and implementing security gates at various points to monitor malicious agents or bots, ensuring they do not exceed their access parameters. This continuous monitoring is crucial for maintaining system integrity. For AI agent integration, a function like 'get personalized profile' is integrated into the AI agent, instructing the LLM to use this tool to gather user preferences. Additionally, tools such as weather considerations can be integrated by connecting to an MCP server, enhancing the AI agent's functionality.",multi_hop_abstract_query_synthesizer
How do AI gateway analytics and evolving standards contribute to the security of AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [798.24s] Evolving Standards and Community Engagement\nThe evolution of standards within the IM community is exciting, as it addresses the challenges associated with building agents. The involvement of team members, such as Aisha and Arana, in these discussions is crucial as the community works to solve these emerging issues.\n\n## [825.92s] Future of Agent DKI and Recommendations\nAs the conversation shifts towards the future of agent DKI, it is important to consider where this technology is headed. The concept of agents is gaining significant attention, and organizations that have not yet implemented agents are likely to do so soon. \n\nIt is anticipated that every engineer will need to become proficient in AI, as it becomes a fundamental part of the computing stack, akin to APIs and data. However, the current middleware stack is still evolving to support the integration of AI agents securely and efficiently.', '<3-hop>\n\n# [3146.56s] AI Gateway Analytics\nAI gateway analytics involves publishing specific analytic details for AI use cases. For example, a casual analytic scenario may count requests, identify headers used, and track errors. This provides a breakdown that helps AI developers understand system performance. The analytics dashboard is purpose-driven, allowing developers to identify issues, such as which services or applications are consuming more data or tokens. \n\nThe dashboard offers detailed insights into vendor model usage, identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.']","AI gateway analytics contribute to the security of AI-driven systems by providing detailed insights into system performance, such as counting requests, identifying headers used, and tracking errors. This allows developers to identify issues and optimize system performance, ensuring that services or applications do not consume more data or tokens than intended. Meanwhile, evolving standards within the IM community address challenges associated with building agents, ensuring that security measures are up-to-date and effective. The involvement of team members in these discussions helps solve emerging issues, contributing to the secure integration of AI agents within the computing stack.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents while integrating data into generative applications, considering the limitations of machine learning models?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [1081.44s] Key Takeaways\nIn summary, the discussion has highlighted the importance of writing better prompts, which is becoming a new programming language for building AI applications. The real power lies in how data is integrated into generative applications, shifting the focus from training to integration.\n\n## [1118.56s] Addressing Limitations in Data Integration\nAs organizations consider integrating their data into prompts, questions arise regarding the feasibility of including all organizational data. While it is possible, there are technical limitations to consider. Models have a context size they can handle, with early models supporting around 4,000 tokens.', '<3-hop>\n\ntions.\nReferences\nAbdin, M.; Aneja, J.; Behl, H.; Bubeck, S.; Eldan, R.; Gu-\nnasekar, S.; Harrison, M.; Hewett, R. J.; Javaheripi, M.;\nKauffmann, P.; et al. 2024. Phi-4 technical report. arXiv\npreprint arXiv:2412.08905.\nBae, S.; Kyung, D.; Ryu, J.; Cho, E.; Lee, G.; Kweon, S.;\nOh, J.; JI, L.; Chang, E.; Kim, T.; et al. 2024. MIMIC-Ext-\nMIMIC-CXR-VQA: A Complex, Diverse, And Large-Scale\nVisual Question Answering Dataset for Chest X-ray Images.\nChen, J.; Gui, C.; Ouyang, R.; Gao, A.; Chen, S.; Chen,\nG. H.; Wang, X.; Zhang, R.; Cai, Z.; Ji, K.; et al.\n2024a. Huatuogpt-vision, towards injecting medical visual\nknowledge into multimodal llms at scale. arXiv preprint\narXiv:2406.19280.\nChen, Z.; Wang, W.; Tian, H.; Ye, S.; Gao, Z.; Cui, E.; Tong,\nW.; Hu, K.; Luo, J.; Ma, Z.; et al. 2024b. How far are we to\ngpt-4v? closing the gap to commercial multimodal models\nwith open-source suites. arXiv preprint arXiv:2404.16821.\nChern, E.; Su, J.; Ma, Y .; and Liu, P. 2024. Anole:\nAn open, autoregressive, native large multimodal mod-\nels for interleaved image-text generation. arXiv preprint\narXiv:2407.06135.\nDai, W.; Li, J.; Li, D.; Tiong, A. M. H.; Zhao, J.; Wang, W.;\nLi, B.; Fung, P.; and Hoi, S. 2023. InstructBLIP: Towards\nGeneral-purpose Vision-Language Models with Instruction\nTuning. arXiv:2305.06500.\nDavies, R. L.; Royston, P. A.; Leung, M. S.; Haider, M. E.\nA. M. J.; Barkhof, S. G. A. L.; and B., P. E. T. M. 2014. The\nIXI Dataset. Accessed: 2025-01-30.\nDing, N.; Qin, Y .; Yang, G.; Wei, F.; Yang, Z.; Su, Y .;\nHu, S.; Chen, Y .; Chan, C.-M.; Chen, W.; et al. 2023.\nParameter-efficient fine-tuning of large-scale pre-trained\nlanguage models. Nature Machine Intelligence, 5(3): 220–\n235.\nDong, R.; Han, C.; Peng, Y .; Qi, Z.; Ge, Z.; Yang, J.; Zhao,\nL.; Sun, J.; Zhou, H.; Wei, H.; et al. 2023. Dreamllm:\nSynergistic multimodal comprehension and creation. arXiv\npreprint arXiv:2309.11499.\nDubey, A.; Jauhri, A.; Pandey, A.; Kadian, A.; Al-Dahle, A.;\nLetman, A.; Mathur, A.; Schelten, A.; Yang, A.; Fan, A.;\net al. 2024. The llama 3 herd of models. arXiv preprint\narXiv:2407.21783.\nEsser, P.; Rombach, R.; and Ommer, B. 2021. Taming trans-\nformers for high-resolution image synthesis. In Proceedings\nof the IEEE/CVF conference on computer vision and pattern\nrecognition, 12873–12883.\nGe, Y .; Ge, Y .; Zeng, Z.; Wang, X.; and Shan, Y . 2023. Plant-\ning a seed of vision in large language model. arXiv preprint\narXiv:2307.08041.\nGe, Y .; Zhao, S.; Zhu, J.; Ge, Y .; Yi, K.; Song, L.; Li, C.;\nDing, X.; and Shan, Y . 2024. Seed-x: Multimodal models\nwith unified multi-granularity comprehension and genera-\ntion. arXiv preprint arXiv:2404.14396.\nHe, X.; Zhang, Y .; Mou, L.; Xing, E.; and Xie, P. 2020.\nPathvqa: 30000+ questions for medical visual question an-\nswering. arXiv preprint arXiv:2003.10286.\nHu, E. J.; Shen, Y .; Wallis, P.; Allen-Zhu, Z.; Li, Y .; Wang,\nS.; Wang, L.; and Chen, W. 2021. Lora: Low-rank adaptation\nof large language models. arXiv preprint arXiv:2106.09685.\nHu, Y .; Li, T.; Lu, Q.; Shao, W.; He, J.; Qiao, Y .; and Luo,\nP. 2024. Omnimedvqa: A new large-scale comprehensive\nevaluation benchmark for medical lvlm. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 22170–22183.\nIsola, P.; Zhu, J.-Y .; Zhou, T.; and Efros, A. A. 2017. Image-\nto-image translation with conditional adversarial networks.\nIn Proceedings of the IEEE conference on computer vision\nand pattern recognition, 1125–1134.\nJohnson, A. E.; Pollard, T. J.; Greenbaum, N. R.; Lungren,\nM. P.; Deng, C.-y.; Peng, Y .; Lu, Z.; Mark, R. G.; Berkowitz,\nS. J.; and Horng, S. 2019. MIMIC-CXR-JPG, a large pub-\nlicly available database of labeled chest radiographs. arXiv\npreprint arXiv:1901.07042.\nLau, J. J.; Gayen, S.; Ben Abacha, A.; and Demner-\nFushman, D. 2018. A dataset of clinically generated visual\nquestions and answers about radiology images. Scientific\ndata, 5(1): 1–10.\nLi, B.; Xue, K.; Liu, B.; and Lai, Y .-K. 2023a. Bbdm: Image-\nto-image translation with brownian bridge diffusion models.\nIn Proceedings of the IEEE/CVF conference on computer\nvision and pattern Recognition, 1952–1961.\nLi, C.; Wong, C.; Zhang, S.; Usuyama, N.; Liu, H.; Yang,\nJ.; Naumann, T.; Poon, H.; and Gao, J. 2024a. Llava-\nmed: Training a large language-and-vision assistant for\nbiomedicine in one day. Advances in Neural Information\nProcessing Systems, 36.\nLi, C.; Wong, C.; Zhang, S.; Usuyama, N.; Liu, H.; Yang,\nJ.; Naumann, T.; Poon, H.; and Gao, J. 2024b. Llava-\nmed: Training a large language-and-vision assistant for\nbiomedicine in one day. Advances in Neural Information\nProcessing Systems, 36.\nLi, J.; Li, D.; Savarese, S.; and Hoi, S. 2023b. Blip-2:\nBootstrapping language-image pre-training with frozen im-\nage encoders and large language models. In International\nconference on machine learning, 19730–19742. PMLR.\nLin, T.; Liu, J.; Zhang, W.; Li, Z.; Dai, Y .; Li, H.; Yu, Z.; He,\nW.; Li, J.; Jiang, H.; et al. 2024. Teamlora: Boosting low-\nrank adaptation with expert collaboration and competition.\narXiv preprint arXiv:2408.09856.\n9']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to maintain system integrity. This is crucial as the attack space evolves, and it is essential to assume a breach. Meanwhile, integrating data into generative applications involves addressing technical limitations, such as the context size that machine learning models can handle, which was initially around 4,000 tokens. This integration shifts the focus from training to how data is incorporated into AI applications, highlighting the importance of writing better prompts as a new programming language for AI development.",multi_hop_abstract_query_synthesizer
How them malicious agents in AI systems be a problem and what generative AI do to help with that?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1841.68s] Searching for Relevant Information\nThe vector database performs the search operation using the provided vector, returning a selection of relevant document chunks. These chunks can then be utilized in the prompt to generate a response.\n\n# [1861.20s] Mastery of Generative AI\nAs we delve deeper into retrieval-augmented generation (RAG), it is crucial to understand its applications in generative AI. This technology enables the creation of content, answering questions, and analyzing data, all of which can significantly enhance organizational operations.\n\n# [1961.04s] Understanding AI Agents\nAI agents are systems that utilize generative AI models to autonomously make decisions and perform tasks. These tasks, often referred to as tools, can include functions such as API calls, database interactions, or even controlling physical devices.']","Malicious agents in AI-driven systems pose a problem because they can launch attacks and act outside their intended purpose, threatening the integrity and security of the system. Continuous monitoring is essential to track their activities. Generative AI, through technologies like retrieval-augmented generation (RAG), can enhance organizational operations by creating content, answering questions, and analyzing data, which can help in understanding and mitigating the risks posed by these malicious agents.",multi_hop_abstract_query_synthesizer
How continuous monitoring and audit process help in AI-driven systems and underwriting co-pilot?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [789.92s] Addressing Bias in Underwriting Co-Pilot\nIn the context of our underwriting co-pilot, which processes a significant amount of personal data, it is crucial to address potential biases that may influence decision-making. The underwriting co-pilot utilizes input from various sources, including bureau data, medical reports, and historical data, alongside underwriting guidelines established by regulators. \n\nTo mitigate bias, we employ a three-stage approach. The first stage involves a human-in-the-loop system, where underwriters provide feedback on the decisions made by the agents. This feedback is then relayed to our AI engineers. The second stage consists of retraining the model to eliminate any biased outputs by adjusting the relevant parameters. Finally, we have an audit process in place, where historical decisions made by human underwriters are reviewed by auditors, including those from regulatory bodies. Any incorrect decisions are rectified, and the model is retrained accordingly. Thus, our strategy heavily relies on human feedback and continuous improvement.']","Continuous monitoring in AI-driven systems is essential for tracking the activities of agents to ensure they do not exceed their access parameters, thereby maintaining the integrity and security of the system. In the underwriting co-pilot, an audit process is part of a three-stage approach to address bias. This process involves reviewing historical decisions made by human underwriters, including those from regulatory bodies, to rectify any incorrect decisions and retrain the model. Both continuous monitoring and the audit process are crucial for ensuring the reliability and fairness of AI systems.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and what role does generative AI play in medical imaging advancements?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [795.92s] Incorporating Contextual Information\nThe most critical aspect involves supplying the current text, which adds necessary context to the LLM. This includes information about existing libraries, as the LLM may not be aware of the latest updates due to frequent releases. By utilizing few-shot prompting, the amount of instruction can be minimized, allowing for a more streamlined interaction with the user’s queries.\n\n# [840.40s] Exploring Generative Integration Patterns\nThe discussion now shifts to generative integration patterns. In the early stages of generative AI, the primary focus was on integrating generative models into applications. This integration allowed for basic interactions, such as conversing with a chat-based assistant, without the need for external data. For instance, code generation could be performed without any additional context.', '<3-hop>\n\ntions.\nReferences\nAbdin, M.; Aneja, J.; Behl, H.; Bubeck, S.; Eldan, R.; Gu-\nnasekar, S.; Harrison, M.; Hewett, R. J.; Javaheripi, M.;\nKauffmann, P.; et al. 2024. Phi-4 technical report. arXiv\npreprint arXiv:2412.08905.\nBae, S.; Kyung, D.; Ryu, J.; Cho, E.; Lee, G.; Kweon, S.;\nOh, J.; JI, L.; Chang, E.; Kim, T.; et al. 2024. MIMIC-Ext-\nMIMIC-CXR-VQA: A Complex, Diverse, And Large-Scale\nVisual Question Answering Dataset for Chest X-ray Images.\nChen, J.; Gui, C.; Ouyang, R.; Gao, A.; Chen, S.; Chen,\nG. H.; Wang, X.; Zhang, R.; Cai, Z.; Ji, K.; et al.\n2024a. Huatuogpt-vision, towards injecting medical visual\nknowledge into multimodal llms at scale. arXiv preprint\narXiv:2406.19280.\nChen, Z.; Wang, W.; Tian, H.; Ye, S.; Gao, Z.; Cui, E.; Tong,\nW.; Hu, K.; Luo, J.; Ma, Z.; et al. 2024b. How far are we to\ngpt-4v? closing the gap to commercial multimodal models\nwith open-source suites. arXiv preprint arXiv:2404.16821.\nChern, E.; Su, J.; Ma, Y .; and Liu, P. 2024. Anole:\nAn open, autoregressive, native large multimodal mod-\nels for interleaved image-text generation. arXiv preprint\narXiv:2407.06135.\nDai, W.; Li, J.; Li, D.; Tiong, A. M. H.; Zhao, J.; Wang, W.;\nLi, B.; Fung, P.; and Hoi, S. 2023. InstructBLIP: Towards\nGeneral-purpose Vision-Language Models with Instruction\nTuning. arXiv:2305.06500.\nDavies, R. L.; Royston, P. A.; Leung, M. S.; Haider, M. E.\nA. M. J.; Barkhof, S. G. A. L.; and B., P. E. T. M. 2014. The\nIXI Dataset. Accessed: 2025-01-30.\nDing, N.; Qin, Y .; Yang, G.; Wei, F.; Yang, Z.; Su, Y .;\nHu, S.; Chen, Y .; Chan, C.-M.; Chen, W.; et al. 2023.\nParameter-efficient fine-tuning of large-scale pre-trained\nlanguage models. Nature Machine Intelligence, 5(3): 220–\n235.\nDong, R.; Han, C.; Peng, Y .; Qi, Z.; Ge, Z.; Yang, J.; Zhao,\nL.; Sun, J.; Zhou, H.; Wei, H.; et al. 2023. Dreamllm:\nSynergistic multimodal comprehension and creation. arXiv\npreprint arXiv:2309.11499.\nDubey, A.; Jauhri, A.; Pandey, A.; Kadian, A.; Al-Dahle, A.;\nLetman, A.; Mathur, A.; Schelten, A.; Yang, A.; Fan, A.;\net al. 2024. The llama 3 herd of models. arXiv preprint\narXiv:2407.21783.\nEsser, P.; Rombach, R.; and Ommer, B. 2021. Taming trans-\nformers for high-resolution image synthesis. In Proceedings\nof the IEEE/CVF conference on computer vision and pattern\nrecognition, 12873–12883.\nGe, Y .; Ge, Y .; Zeng, Z.; Wang, X.; and Shan, Y . 2023. Plant-\ning a seed of vision in large language model. arXiv preprint\narXiv:2307.08041.\nGe, Y .; Zhao, S.; Zhu, J.; Ge, Y .; Yi, K.; Song, L.; Li, C.;\nDing, X.; and Shan, Y . 2024. Seed-x: Multimodal models\nwith unified multi-granularity comprehension and genera-\ntion. arXiv preprint arXiv:2404.14396.\nHe, X.; Zhang, Y .; Mou, L.; Xing, E.; and Xie, P. 2020.\nPathvqa: 30000+ questions for medical visual question an-\nswering. arXiv preprint arXiv:2003.10286.\nHu, E. J.; Shen, Y .; Wallis, P.; Allen-Zhu, Z.; Li, Y .; Wang,\nS.; Wang, L.; and Chen, W. 2021. Lora: Low-rank adaptation\nof large language models. arXiv preprint arXiv:2106.09685.\nHu, Y .; Li, T.; Lu, Q.; Shao, W.; He, J.; Qiao, Y .; and Luo,\nP. 2024. Omnimedvqa: A new large-scale comprehensive\nevaluation benchmark for medical lvlm. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 22170–22183.\nIsola, P.; Zhu, J.-Y .; Zhou, T.; and Efros, A. A. 2017. Image-\nto-image translation with conditional adversarial networks.\nIn Proceedings of the IEEE conference on computer vision\nand pattern recognition, 1125–1134.\nJohnson, A. E.; Pollard, T. J.; Greenbaum, N. R.; Lungren,\nM. P.; Deng, C.-y.; Peng, Y .; Lu, Z.; Mark, R. G.; Berkowitz,\nS. J.; and Horng, S. 2019. MIMIC-CXR-JPG, a large pub-\nlicly available database of labeled chest radiographs. arXiv\npreprint arXiv:1901.07042.\nLau, J. J.; Gayen, S.; Ben Abacha, A.; and Demner-\nFushman, D. 2018. A dataset of clinically generated visual\nquestions and answers about radiology images. Scientific\ndata, 5(1): 1–10.\nLi, B.; Xue, K.; Liu, B.; and Lai, Y .-K. 2023a. Bbdm: Image-\nto-image translation with brownian bridge diffusion models.\nIn Proceedings of the IEEE/CVF conference on computer\nvision and pattern Recognition, 1952–1961.\nLi, C.; Wong, C.; Zhang, S.; Usuyama, N.; Liu, H.; Yang,\nJ.; Naumann, T.; Poon, H.; and Gao, J. 2024a. Llava-\nmed: Training a large language-and-vision assistant for\nbiomedicine in one day. Advances in Neural Information\nProcessing Systems, 36.\nLi, C.; Wong, C.; Zhang, S.; Usuyama, N.; Liu, H.; Yang,\nJ.; Naumann, T.; Poon, H.; and Gao, J. 2024b. Llava-\nmed: Training a large language-and-vision assistant for\nbiomedicine in one day. Advances in Neural Information\nProcessing Systems, 36.\nLi, J.; Li, D.; Savarese, S.; and Hoi, S. 2023b. Blip-2:\nBootstrapping language-image pre-training with frozen im-\nage encoders and large language models. In International\nconference on machine learning, 19730–19742. PMLR.\nLin, T.; Liu, J.; Zhang, W.; Li, Z.; Dai, Y .; Li, H.; Yu, Z.; He,\nW.; Li, J.; Jiang, H.; et al. 2024. Teamlora: Boosting low-\nrank adaptation with expert collaboration and competition.\narXiv preprint arXiv:2408.09856.\n9']","AI-driven systems ensure security against malicious agents by assuming a breach and implementing security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters, thus maintaining the integrity and security of the system. Generative AI plays a significant role in medical imaging advancements by integrating generative models into applications, allowing for interactions such as conversing with a chat-based assistant and performing tasks like code generation without the need for external data. This integration can enhance the capabilities of AI models in medical visual comprehension and modality conversion tasks.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and how can an agent interface be integrated to handle specific inquiries like hotel policies?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n## [3955.76s] Integration with the Agent\nThe function can be utilized independently or integrated into an agentic behavior model, referred to as agentic RAG. This allows for a seamless flow of information. In the agent interface, a tool can be attached, specifically the `query_hotel_policies` function. The tool's name and description are crucial for the language model to determine which tools to call.\n\nIt is important to note that since the hotel ID has not been provided in this context, the function will need to be adjusted accordingly. The agent should be able to handle policy-related inquiries, such as the pet policy of a hotel, based on hardcoded information.""]","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to ensure they do not exceed their access parameters. This is crucial for maintaining the integrity and security of the system. Additionally, an agent interface can be integrated to handle specific inquiries, such as hotel policies, by attaching tools like the `query_hotel_policies` function. This integration allows for a seamless flow of information and enables the agent to manage policy-related inquiries effectively, even when specific details like a hotel ID are not provided.",multi_hop_abstract_query_synthesizer
How does the work of Arabic AI in translation and content generation relate to security considerations in AI-driven systems?,"[""<1-hop>\n\n## [11.84s] Panelist Introductions\nYad Ahmed shares his background, stating that he has 24 years of experience in technology, with eight years focused on natural language processing (NLP) and AI. He explains that Arabic AI, which operates under the name Turjim, has been in business for 17 years, initially focusing on translation and content generation. In 2016, the company expanded into technology, developing automated systems for translation and content generation. Recently, they secured a Series A funding round of $50 million to further their work in AI, particularly in model fine-tuning and workflow automation.\n\nRana Kalaf introduces herself as the Chief AI Officer at WSO2. She emphasizes the company's focus on two main areas in their AI journey: accelerating user engagement with their products through embedded agents and co-pilots, and integrating AI into applications via connectors and an agent-building framework.\n\nAlan Shmal from Vistra describes the company as a corporate services provider that handles accounting, payroll, and legal entity management. He explains that their AI initiatives include a conversational agent built with Aentic AI frameworks, which serves three main functions: advisory, reporting on customer data, and executing workflows. He also mentions the use of asynchronous systems to process unstructured data, such as legal documents and voice notes.\n\nMahesh Saloria represents Canada HSBC Life Insurance, a joint venture between Canara Bank and HSBC. He discusses their focus on securing individuals' futures through insurance and highlights a recent initiative involving an underwriting co-pilot designed to assist underwriters in assessing risk."", '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","Arabic AI, operating under the name Turjim, has been focusing on translation and content generation, with recent expansions into AI model fine-tuning and workflow automation. In AI-driven systems, such as those developed by Arabic AI, security considerations are crucial due to the potential presence of malicious agents or bots that can launch attacks. It is important to implement security gates and continuous monitoring to ensure these systems maintain integrity and do not exceed their intended purposes, which is vital for protecting the AI models and workflows developed by companies like Arabic AI.",multi_hop_abstract_query_synthesizer
How does the integration of agent identity into IM products relate to the utility of AI applications in taking action on behalf of users?,"['<1-hop>\n\n# [757.12s] Structure of Effective Prompts\nWhen building generative applications, the structure of the prompt is essential. Initially, the role is defined, indicating that the model should impersonate a specific personality, such as a Java developer. Following this, clear instructions are provided, detailing the expectations for generating accurate code. An output format is also specified, guiding the model on how to respond.\n\n## [1885.76s] The Value of Actionable AI Applications\nAn interesting question arises when considering the utility of AI applications. For instance, is it more beneficial to have an AI application that instructs users on how to drive a car, or one that can actually drive the car for them? The latter represents a more practical application of AI, as it not only analyzes data but also takes action on behalf of the user or organization.', '<2-hop>\n\n## [1605.44s] Future Directions\nThe evolution of agents will continue as they become more capable and autonomous. Important topics that remain to be discussed include the evaluation of agents, the implementation of guardrails to prevent information leakage, and securing agents as they take on more serious tasks. The integration of agent identity into IM products is also a critical area of focus.\n\n## [887.44s] Effort and Frequency of Human Feedback\nThe effort required for the human-in-the-loop process is relatively manageable, accounting for about 14 to 15% of our overall operations. Most of the training and retraining occurs automatically, with adjustments made to ensure that certain parameters receive more weight in future iterations to prevent recurring issues. \n\nWe conduct retraining on a monthly basis, although the frequency can depend on the models in use. With new models emerging every six months, we prefer to utilize the latest versions to enhance accuracy rather than retraining older models.']","The integration of agent identity into IM products is a critical area of focus as agents become more capable and autonomous. This relates to the utility of AI applications in taking action on behalf of users, as it enhances the ability of AI to perform tasks independently and securely, thereby increasing the practical application of AI beyond just data analysis to taking actionable steps for users.",multi_hop_abstract_query_synthesizer
How does the MCP architecture facilitate AI-driven systems while ensuring user consent is maintained?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2914.80s] Architecture of MCP\nThe MCP architecture includes an MCP host, which can be any integration or agent that connects to data or tools. Clients connect to the MCP server using a JSON RPC protocol, simplifying the process of establishing connections.\n\nThe MCP server has a fixed specification, allowing for a single client definition that can communicate with the server without needing to rewrite the client for each new integration. This design streamlines the connection process to various data sources and APIs, enhancing the overall efficiency of LLM integrations.\n\n# [601.12s] Utilizing Single LLM Invocation\nIn the realm of generative models, there are instances where a single large language model (LLM) invocation is employed to address specific issues. This approach is often complemented by multiple techniques that involve several iterations of LLM calls to effectively overcome limitations.', '<3-hop>\n\n## [4217.20s] The Role of AI Agents\nAI agents may perform critical tasks on behalf of users, but it is essential to consult the user before proceeding with any significant actions. Obtaining consent or authorization from the user is necessary, which highlights the importance of agent identity. An agent can be viewed as a colleague, capable of handling support calls and performing various tasks. However, the agent must operate within defined limits and seek authorization when necessary.\n\nFor instance, an agent may access public data or organizational data, but if it needs to go beyond certain boundaries, it must obtain permission from a user or a colleague with higher authorization. In scenarios such as hotel bookings, the agent should not proceed with reservations without first consulting the user to secure their authorization.']","The MCP architecture facilitates AI-driven systems by providing a streamlined connection process through its fixed specification and JSON RPC protocol, which allows clients to connect to the MCP server efficiently. This design enhances the integration of various data sources and APIs, crucial for the functionality of AI-driven systems. Simultaneously, maintaining user consent is emphasized by ensuring that AI agents operating within these systems consult users before proceeding with significant actions. This involves obtaining user authorization, especially when AI agents need to access data beyond predefined boundaries, thereby ensuring that user consent is maintained and respected.",multi_hop_abstract_query_synthesizer
How MCP architecture help AI-driven systems with security and database update?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2914.80s] Architecture of MCP\nThe MCP architecture includes an MCP host, which can be any integration or agent that connects to data or tools. Clients connect to the MCP server using a JSON RPC protocol, simplifying the process of establishing connections.\n\nThe MCP server has a fixed specification, allowing for a single client definition that can communicate with the server without needing to rewrite the client for each new integration. This design streamlines the connection process to various data sources and APIs, enhancing the overall efficiency of LLM integrations.\n\n# [601.12s] Utilizing Single LLM Invocation\nIn the realm of generative models, there are instances where a single large language model (LLM) invocation is employed to address specific issues. This approach is often complemented by multiple techniques that involve several iterations of LLM calls to effectively overcome limitations.', '<3-hop>\n\n## [3142.72s] Database Update Confirmation\nUpon refreshing the database, it was confirmed that for the user John, a personalized profile had been generated based on the specified format. The profile included preferences for hotel types, such as psychologist and mountain log resorts, and the travel purpose appeared accurate, mirroring the earlier demo. This personalized profile will serve as the basis for future workflows.\n\n# [3201.52s] Second Workflow: Rack Pattern\nThe second workflow involves the rack pattern, which is commonly used when there is a knowledge base from which questions can be asked. In this case, the knowledge base consists of PDF documents uploaded by hotels during the sign-up process. The integration heavily relies on the enterprise architecture of the system.']","The MCP architecture aids AI-driven systems by providing a structured framework that includes an MCP host and server, which facilitate secure connections to data and tools using a JSON RPC protocol. This setup allows for efficient integration and monitoring, crucial for maintaining security against malicious agents. Additionally, the architecture supports streamlined database updates, as seen in the confirmation of personalized profiles, ensuring that data integrity is maintained and workflows are based on accurate, updated information.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and how does HealthGPT leverage AI for medical comprehension and generation tasks?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\ntential task interference. TLS: In the first and second stages,\ngiven the heterogeneity between comprehension and gener-\nation tasks, we first train H-LoRA plugins for HealthGPT\nto incorporate both medical comprehension and generation\nknowledge, thus endowing the LLMs with capabilities for\nvision-language alignment and vision-to-vision reconstruc-\ntion. Additionally, through minimal mixed-task training, we\nbuilt fusion embedding layers and output heads that merge\ntext and visual tokens, establishing a unified LVLM founda-\ntion for visual instruction fine-tuning. In the third stage, by\nonly training the H-LoRA plugins, HealthGPT is able to\nrapidly adapt to a wide range of downstream medical tasks,\ncovering various types of medical comprehension and gen-\neration tasks.\nTo effectively implement our approach, we have cu-\nrated a dataset for training unified medical LVLMs, called\nVL-Health, including seven comprehension tasks and five\ngeneration tasks (Figure 1). Through quantitative analysis\nand validation on multi-modal tasks, the results demonstrate\nthat HealthGPT is capable of unifying medical multi-\nmodal abilities in data-constrained scenarios, achieving per-\nformance comparable to or better than existing state-of-the-\nart (SOTA) models across multiple metrics. Overall, the\nmain contributions of this paper are summarized as follows:\n• Unified Med-LVLM. We introduce HealthGPT,\nwhich, to the best of our knowledge, is the first unified\nframework for multi-modal comprehension and genera-\ntion in complex medical scenarios.\n• Effective Learning Paradigm. We present H-LoRA, an\noptimized multi-LoRA PEFT architecture based on task-\ngated decoupling, is designed to effectively mitigate data\nconflict issues.\n• Holistic Training Dataset. We curated VL-Health, a\ncomprehensive dataset designed for both comprehension\nand generation tasks.\n• Superior Downstream Improvements : Extensive ex-\nperiments are conducted and the results confirm\nHealthGPT’s effectiveness in medical vision-language\ncomprehension and generation.\n2 Related Work\nMedical Vision Large Language Models. Recently, medi-\ncal vision large language models (Med-VLLMs) have made\nsignificant progress, demonstrating excellent performance\nin understanding medical images and responding to human\nqueries based on these images (Zhou et al. 2023; Tian et al.\n2023). XrayGPT (Thawkar et al. 2023) combines a med-\nical visual encoder (MedClip) (Wang et al. 2022) with a\nfine-tuned LLM , using a simple linear transformation layer\nto achieve alignment between visual and textual informa-\ntion, significantly enhancing the understanding of medical\nimages. On this basis, LLaV A-Med (Li et al. 2024b) fur-\nther enhances visual-text alignment in medical contexts by\nselecting high-quality image-text pairs from PubMed pa-\npers and synthesized VQA datasets. BiomedGPT (Luo et al.\n2024b) employs a BERT-style encoder and GPT-style de-\ncoder architecture, pre-trained on interdisciplinary datasets.\nCompared to commercial models like Med-PaLM (Singhal\net al. 2023), BiomedGPT significantly reduces model size\nwhile maintaining superior performance. However, issues\nof language adaptability and dataset specificity still remain.\nTo address these, HuatuoGPT-Vision (Chen et al. 2024a)\nintroduces the PubMedVision dataset, which contains 1.3\nmillion high-quality medical samples, significantly improv-\ning the model’s adaptability across diverse medical applica-\ntions. However, current Med-VLLMs mainly focus on med-\nical comprehension and lack the capability for the medical\nvision-language generation.\nUnified Visual Comprehension and Generation Mod-\nels. Recent research has increasingly concentrated on cre-\nating unified LVLMs that are adept at understanding and\nproducing content across various visual modalities. NExT-\nGPT (Wu et al. 2023) achieves perception and generation for\narbitrary combinations of multi-modal inputs and outputs by\naligning LLMs. Similarly, SEED (Ge et al. 2023), SEED-\nX (Ge et al. 2024), and DreamLLM (Dong et al. 2023) em-\nploy learnable queries and leverage next-token prediction to\ngenerate visual tokens, providing conditional inputs to exter-\nnal generation modules. Unlike these methods, which func-\ntion as external conditioners, Unified-IO (Lu et al. 2022),\nUnified-IO 2 (Lu et al. 2024), and Chameleon (Team 2024)\ninternalize multi-modal generation tasks within a unified\nTransformer architecture by extending multi-modal vocab-\nularies, enabling direct generation based on next-token pre-\ndiction. Building on this concept, Lumina-mGPT (Liu et al.\n2024a) and ANOLE (Chern et al. 2024) further enhance the\ngeneration capabilities of unified models using high-quality\ndata, particularly improving the quality and flexibility of im-\nage generation.\n3 Preliminaries\nLarge Vision-Language Models.The input to a LVLM typ-\nically consists of an image ximg and a discrete text sequence\nxtxt. The visual encoder Eimg converts the input image ximg\ninto a sequence of visual tokens V = [ vi]Nv\ni=1, while the\ntext sequence xtxt is mapped into a sequence of text to-\nkens T = [ ti]Nt\ni=1 using an embedding function Etxt. The\nLLM MLLM(·|θ) models the joint probability of the token\nsequence U = {V, T }, which is expressed as:\nPθ(R|U) =\nNrY\ni=1\nPθ(ri|{U, r<i}), (1)\nwhere R = [ri]Nr\ni=1 is the text response sequence. The LVLM\niteratively generates the next token ri based on r<i. The op-\ntimization objective is to minimize the cross-entropy loss of\nthe response R. It is worth noting that most LVLMs adopt\n3']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to maintain system integrity. This approach assumes a breach and tracks agents to ensure they do not exceed their access parameters. On the other hand, HealthGPT leverages AI for medical comprehension and generation tasks by using H-LoRA plugins to incorporate medical knowledge, enabling vision-language alignment and vision-to-vision reconstruction. HealthGPT is trained on a curated dataset called VL-Health, which includes comprehension and generation tasks, allowing it to adapt to a wide range of medical tasks and achieve performance comparable to or better than existing state-of-the-art models.",multi_hop_abstract_query_synthesizer
How does HealthGPT address the challenges of medical visual generation and authentication patterns in agentic AI systems?,"['<1-hop>\n\nSpecifically, recent studies (Li et al. 2024a; Tu et al. 2024)\nhave utilized pre-trained large language models (LLMs) and\nvisual instruction data to build interactive diagnostic tools\nand treatment planning systems, revealing the immense po-\ntential of LVLMs in medical scenarios. However, these stud-\nies primarily concentrate on visual comprehension tasks that\nproduce text-based outputs, such as medical visual ques-\ntion answering (Li et al. 2024a) or report generation (Nath\net al. 2024), and deficient the “drawing” capability needed\nfor medical visual generation. In practice, integrating visual\ncomprehension and generation can significantly enhance the\nmultifunctionality of medical LVLMs.\nRecent studies have increasingly focused on developing\nunified LVLMs capable of comprehending and generating\ncontent across diverse visual modalities. Earlier approaches\npredominantly utilized continuous visual tokens fed into\nLLMs, using the LLMs themselves as conditional genera-\ntors for external generative models (Ge et al. 2024; Wu et al.\n2023; Dong et al. 2023). More recent research has explored\nthe use of discrete visual tokens for image representation and\ngeneration within a fully autoregressive framework (Team\n2024; Wang et al. 2024a; Xie et al. 2024). These meth-\nods not only enhance controllability but also demonstrate\nearly success in open-world, any-to-any tasks, highlighting\nthe preliminary potential of a unified autoregressive learning\nparadigm in multi-modal tasks.\nWhile unified LVLMs have achieved initial success in\ngeneral scenarios, such a unified framework remains under-\nexplored in the medical domain. Adapting the aforemen-\ntioned general unified model paradigm to the medical do-\nmain presents two major challenges: (i) High-scale and\n-quality Data Limitations . Open-world models necessi-\ntate extensive pre-training on billions or even more diverse,\nmulti-modal data samples for comprehension and genera-\ntion tasks (Lu et al. 2024; Team 2024). However, the ac-\ncessible medical data significantly lacks in scale and qual-\nity compared to natural multi-modal datasets. Its special-\nized and domain-specific characteristics make it challenging\nto develop a unified medical model from scratch. (ii) Con-\nflicts between Comprehension and Generation . Compre-\nhension tasks often strip away visual details to focus on\nabstraction, while generation tasks require detailed preser-\nvation, making tokens sensitive to all visual alterations. As\nshown in Figure 2, which features experiments conducted on\nmedical images, the performance in comprehension (or gen-\neration) tasks steadily decreases as the proportion of genera-\ntion (or comprehension) data increases, and vice versa. This\nhighlights a dilemma in autoregressive multi-modal training,\nstemming from the need to maintain consistency between\npre- and post-LVLMs. While some methods have explored\nmutual enhancement between comprehension and genera-\ntion (Pan et al. 2024; Tong et al. 2024), improvements still\nexhibit diminishing returns, with performance degradation\nremaining a significant issue.\n(a) (b)\nFigure 2: With a fixed amount of comprehension (genera-\ntion) data, increasing the proportion of the other type leads\nto significant performance degradation.\nTo tackle the aforementioned challenges, we propose\nHealthGPT (see Figure 1) , which progressively adapts a\npre-trained LLM as an unified medical multi-modal model\nwith a small amount of visual instruction data. We de-\nvise innovative Parameter-Efficient Fine-Tuning (PEFT) ap-\nproach (Ding et al. 2023), calledHeterogeneous Low-Rank\nAdaptation (H-LoRA), which decouples the learning pro-\ncess of LVLMs for comprehension and generation tasks. In-\nspired by the plug-and-play nature of LoRA (Hu et al. 2021),\nH-LoRA enables the model to store heterogeneous compre-\nhension and generation knowledge in independent “plug-\nins”, thus avoiding joint optimization issues caused by con-\nflicts between comprehension and generation tasks. In addi-\ntion, we also consider the variety of sub-tasks among com-\nprehension or generation tasks. Qualitative research high-\nlights the limitations of a single LoRA in handling multi-\ndimensional task scenarios, mainly due to catastrophic for-\ngetting and interference (Liu et al. 2024d; Lin et al. 2024).\nTo address this, we draw on the concept of Mixture of Ex-\nperts (MoE) (Masoudnia and Ebrahimpour 2014) and in-\ntroduce LoRA experts. The aim is to dynamically transfer\ntask-shared knowledge to adapt to downstream tasks. Unlike\nMoELoRA (Luo et al. 2024a), H-LoRA employs reversible\nmatrix block multiplication to combine LoRA experts, sig-\nnificantly reducing the overhead of multiple matrix multi-\nplications. Notably, when using four experts, it requires\nonly 67% of the MoELoRA training time.\nTo effectively leverage H-LoRA inHealthGPT, we fur-\nther introduce a Hierarchical Visual Perception (HVP)\nand devise a correspondingThree-stage Learning Strategy\n(TLS). HVP: we separate visual details learning from Vi-\nsion transformer (ViT) for comprehension and generation.\nAs is widely recognized, the ViT encodes visual concepts\nwith increasing abstraction, generally, becoming finer as we\nprogress over levels (Vig 2019). Thus, we maintain the vi-\nsual features of the anterior and posterior layers to accom-\nmodate the differing requirements for visual granularity in\ncomprehension and generation tasks while preventing po-\n2', '<2-hop>\n\n## [212.16s] Importance of Security in Agentic AI\nAyesha emphasizes the significance of security in the context of agentic AI and discusses the risks associated with neglecting security measures. She cites a recent incident involving Replit, a software engineering assistant platform, where an agent deleted an entire production database despite being instructed not to do so. This incident highlights the necessity of implementing proper access controls and entitlement management for agents to prevent unexpected actions.\n\n### [268.80s] Challenges of Traditional Identity Management\nAyesha explains that traditional software was more predictable, with identity management designed for applications that followed predefined logic. In contrast, agentic systems operate continuously, with agents working 24/7, leading to varying authentication patterns and access levels. Traditional identity and access management approaches are more suited to static behaviors, while agentic AI introduces complexities due to the diverse behaviors of agents.']","HealthGPT addresses the challenges of medical visual generation by utilizing a Parameter-Efficient Fine-Tuning approach called Heterogeneous Low-Rank Adaptation (H-LoRA), which decouples the learning process for comprehension and generation tasks. This approach allows the model to store comprehension and generation knowledge in independent 'plug-ins', avoiding joint optimization issues. Additionally, HealthGPT introduces a Hierarchical Visual Perception (HVP) and a Three-stage Learning Strategy (TLS) to separate visual details learning for comprehension and generation tasks, accommodating differing requirements for visual granularity. Regarding authentication patterns in agentic AI systems, the importance of security is emphasized, highlighting the need for proper access controls and entitlement management to prevent unexpected actions by agents, as traditional identity management approaches are not suited for the dynamic behaviors of agentic AI.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security and privacy, particularly in handling email addresses, and what role does a unified model play in medical AI tasks?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4362.88s] Email Address Handling\nAlthough it may seem that the email address was sent to the LLM, the actual output is modified to replace the email with a placeholder, ensuring that no sensitive information is transmitted outside the system.\n\n## [4399.36s] Conclusion and Further Exploration\nDue to time constraints, a deeper exploration of these features is not possible. However, users are encouraged to experiment with these functionalities. Documentation regarding guardrails is available, and there are currently about 12 different guards in place, with plans for expansion. These can be applied as policies within the gateway, enhancing scalability.', '<3-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","AI-driven systems ensure security and privacy by implementing security gates at various points within the system and continuously monitoring the activities of agents to prevent unauthorized actions, as discussed in the context of security considerations. Specifically, for handling email addresses, the system replaces the actual email with a placeholder to ensure no sensitive information is transmitted outside the system. This approach is part of the broader security measures to maintain system integrity. In the realm of medical AI tasks, a unified model, such as HealthGPT-L14, plays a crucial role by excelling in medical visual comprehension and modality conversion tasks. It achieves optimal or near-optimal results across various sub-tasks, significantly surpassing other models. The unified model effectively mitigates performance degradation caused by generation tasks, serving as a robust solution in medical scenarios.",multi_hop_abstract_query_synthesizer
"How do advancements in prompting techniques enhance the security considerations in AI-driven systems, and what role do agent applications play in this context?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [659.36s] Advancements in Prompting Techniques\nIn contrast, future prompting involves providing examples to the model. For example, if we present the model with phrases like ""this is awesome"" (negative) and ""this is bad"" (positive), it learns from these examples. When a new sample, such as ""what\'s the horrible sh,"" is introduced, the model is expected to provide the correct response based on the prior examples. This approach is significant because it allows for the omission of explicit instructions, such as stating that sentiment analysis is required.\n\n### [735.84s] The Power of Example-Based Instructions\nThis pattern is crucial, especially when dealing with numerous instructions that need to be conveyed to the model for various tasks. By simply providing a set of examples, one can bypass the need for extensive instructions, making this a powerful prompt engineering technique.', ""<3-hop>\n\n**Time Range: 00:00:04 - 00:10:00**\n\n# [4.00s] Introduction to the Session\nBefore delving into the session, it is essential to understand the topics we aim to cover today. The primary focus is on building agent applications and tools. To establish a clear motivation for this endeavor, we must first address the question: why do we need to build applications?\n\n### [1260.16s] Generative Workflow Implementation\nUsing the admin API, the team can fetch a user's booking history and reviews. This information will be integrated into a generative workflow, which will then generate a user profile. The profile will be stored in the database and will include details such as the user's activity report, preferences for warm weather, hiking, rock climbing, and specific hotel amenities, as well as dietary preferences like avoiding red meat.""]","Advancements in prompting techniques, such as example-based instructions, enhance AI-driven systems by allowing models to learn from examples rather than explicit instructions. This can improve the system's ability to handle various tasks, including security-related ones, by making it more adaptable and efficient in recognizing patterns of malicious activity. In the context of security considerations, continuous monitoring of agents is crucial to ensure they do not exceed their intended purpose. Agent applications play a significant role by providing tools and applications that can be used to monitor and manage these agents effectively, ensuring the integrity and security of the system. By integrating these advancements, AI-driven systems can better anticipate and respond to potential security threats.",multi_hop_abstract_query_synthesizer
How does continuous monitoring contribute to user experience enhancement in AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4115.28s] Conclusion of the Retrieval Pipeline\nThe retrieval pipeline for the RAG has been successfully established. The next step involves moving on to the agentic sample, which serves as the main interface for users. This interface will display the chat functionality, allowing users to interact with the system effectively.\n\nThe tools have been integrated, and the system message has been adjusted to enhance user experience. As users may not provide detailed queries, it is essential to consider the tools required to efficiently respond to common inquiries, such as planning a trip to a specific destination.']","Continuous monitoring in AI-driven systems is crucial for maintaining the integrity and security of the system by tracking the activities of agents to ensure they do not exceed their access parameters. This security measure indirectly enhances user experience by ensuring that the system remains reliable and secure, allowing users to interact with the system effectively through interfaces like the agentic sample, which has been designed to improve user interaction.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure content safty and security against malicious agents?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [3646.16s] Built-in Guardrails and Third-Party Integrations\nThe product includes a set of built-in guardrails, and it also supports third-party integrations. For instance, if there are integrations with services like AWS Bedrock or content safety solutions, users can opt to utilize these guardrails. The gateway is fully compatible with these services, allowing prompts to be sent to LLM services like AWS Bedrock, which will perform the necessary classification to identify any guard validations or failures.\n\nIf there are concerns regarding Personally Identifiable Information (PII), a mixed approach can be adopted. Initially, PII validation can occur at the gateway level before sending the request to AWS Bedrock for further processing. For those who do not have subscriptions or face cost issues, the system provides its own set of guardrails through a framework called Guarders AI. This framework is developed and hosted by the team, and there are plans to offer it as Docker images for users to run within their organizations, allowing for customizations to ensure security and proper governance.']","AI-driven systems ensure content safety and security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to maintain system integrity. Additionally, the systems include built-in guardrails and support third-party integrations, such as AWS Bedrock, to perform necessary classifications and validations. For content safety, users can utilize these guardrails to identify any guard validations or failures. The system also offers its own framework, Guarders AI, which can be customized and run within organizations to ensure security and proper governance.",multi_hop_abstract_query_synthesizer
How AI-driven systems use access control and HealthGPT for security and medical tasks?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [3926.56s] Beyond Guardrails: Access Control and Monitoring\nIn addition to guardrails, organizations must consider access control measures. This involves managing who can access AI models, ensuring that not everyone has unrestricted access. Rate limiting and budget constraints are also essential to prevent misuse, such as denial-of-service (DoS) attacks that could exhaust resources and hinder service for other users.\n\nMonitoring is another critical aspect, as it allows organizations to track what is sent to the LLM and what is generated in response. Maintaining a record of interactions is vital for accountability and troubleshooting in case of issues.', '<3-hop>\n\nTable 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","AI-driven systems implement access control measures to manage who can access AI models, ensuring not everyone has unrestricted access. This includes rate limiting and budget constraints to prevent misuse, such as denial-of-service attacks. Monitoring is crucial for tracking interactions with the system, maintaining accountability, and troubleshooting. HealthGPT, a medical AI model, excels in medical visual comprehension tasks and modality conversion, outperforming other models in various metrics. It uses datasets like PubMedVision and MIMIC-CXR-VQA for training, enhancing its capabilities in medical tasks.",multi_hop_abstract_query_synthesizer
How AI-driven systems monitor agent behavior and what role does HealthGPT architecture play in this?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [561.12s] Monitoring and Managing Agent Behavior\nAyesha concludes by stressing the importance of monitoring agent behavior and ensuring that they operate within defined parameters. As agents can work for multiple users simultaneously, it is essential to understand which user the agent is serving and what resources it accesses. This understanding is critical for maintaining security and preventing misuse.\n\n**Time Range: 00:10:02 - 00:17:54**\n\n# [602.96s] Importance of Auditing and Access Management\nAuditing is crucial in the realm of access management, particularly in the ability to revoke access to different systems and manage tokens effectively. This includes not only revoking existing tokens but also ensuring that no new tokens are issued.', '<3-hop>\n\nFigure 3: The HealthGPT architecture integrates hierarchical visual perception and H-LoRA, employing a task-specific hard\nrouter to select visual features and H-LoRA plugins, ultimately generating outputs with an autoregressive manner.\na design paradigm based on ViT, alignment adapters, and\npre-trained LLMs(Liu et al. 2023, 2024b), enabling quick\nadaptation to downstream tasks.\nVQGAN. VQGAN (Esser, Rombach, and Ommer 2021)\nemploys latent space compression and indexing mechanisms\nto effectively learn a complete discrete representation of im-\nages. VQGAN first maps the input imageximg to a latent rep-\nresentation z = E(x) through a encoder E. Then, the latent\nrepresentation is quantized using a codebookZ = {zk}K\nk=1,\ngenerating a discrete index sequence I = [im]N\nm=1, where\nim ∈ Zrepresents the quantized code index:\nI = Quantize(z|Z) = arg min\nzk∈Z\n∥z − zk∥2. (2)\nIn our approach, the discrete index sequence I serves as\na supervisory signal for the generation task, enabling the\nmodel to predict the index sequence ˆI from input conditions\nsuch as text or other modality signals. Finally, the predicted\nindex sequence ˆI is upsampled by the VQGAN decoder G,\ngenerating the high-quality image ˆximg = G(ˆI).\nLow Rank Adaptation. LoRA(Hu et al. 2021) effectively\ncaptures the characteristics of downstream tasks by intro-\nducing low-rank adapters. The core idea is to decompose\nthe bypass weight matrix ∆W ∈ Rdin×dout\ninto two low-\nrank matrices {A ∈ Rdin×r, B ∈ Rr×dout\n}, where r ≪\nmin{din, dout}, significantly reducing learnable parameters.\nThe output with the LoRA adapter for the input x is then\ngiven by:\nh = xW0 + αx∆W/r = xW0 + αxAB/r, (3)\nwhere matrix A is initialized with a Gaussian distribution,\nwhile the matrixB is initialized as a zero matrix. The scaling\nfactor α/r controls the impact of ∆W on the model.\n4 HealthGPT\n4.1 Unified Autoregressive Generation.\nHealthGPT (Figure 3) utilizes a discrete token representa-\ntion that covers both text and visual outputs, unifying visual\ncomprehension and generation as an autoregressive task. For\ncomprehension, Mllm receives the input joint sequence U\nand outputs a series of text token R = [ r1, r2, . . . , rNr ],\nwhere ri ∈ Vtxt, and Vtxt represents the LLM’s vocabulary:\nPθ(R | U) =\nNrY\ni=1\nPθ(ri | U, r<i). (4)\nFor generation, Mllm first receives a special start token\n⟨START IMG⟩, then generates a series of tokens corre-\nsponding to the VQGAN indices I = [ i1, i2, . . . , iNi ],\nwhere ij ∈ Vvq, and Vvq represents the index range of VQ-\nGAN. Upon completion of generation, the LLM outputs an\nend token ⟨END IMG⟩:\nPθ(I | U) =\nNiY\nj=1\nPθ(ij | U, i<j). (5)\nFinally, the generated index sequence I is fed into the de-\ncoder G, which reconstructs the target image ˆximg = G(I).\n4.2 Hierarchical Visual Perception\nGiven the differences in visual perception between compre-\nhension and generation tasks—where the former focuses on\nabstract semantics and the latter emphasizes complete se-\nmantics—we employ ViT to compress the image into dis-\ncrete visual tokens at multiple hierarchical levels. Specif-\nically, the image is converted into a series of features\n{f1, f2, . . . , fL} as it passes through L ViT blocks.\n4']","AI-driven systems monitor agent behavior by implementing continuous monitoring to track the activities of agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This is crucial for maintaining the integrity and security of the system, as highlighted in the context of security considerations. Additionally, the HealthGPT architecture plays a role by integrating hierarchical visual perception and employing a task-specific hard router to select visual features, which can be used to enhance the monitoring and management of agent behavior. HealthGPT's design, based on ViT, alignment adapters, and pre-trained LLMs, enables quick adaptation to downstream tasks, potentially improving the system's ability to monitor and manage agent behavior effectively.",multi_hop_abstract_query_synthesizer
Howw do AI-drivven systems manage securityy concerns whilee utilizing egress gateways for AI usee cases?,"['<1-hop>\n\n### [2831.44s] Customer Use Cases and Patterns\nWe have collaborated with numerous customers who have established use cases involving AI and egress gateways. Two primary patterns have emerged. The first involves organizations configuring a single API for all teams to use, allowing for quota management across different teams accessing the same LLM API. \n\nThe second pattern involves moving certain logic from the agent level to the egress gateway level, utilizing prompt decorators and templating. These use cases highlight the flexibility and governance capabilities provided by the egress AI gateway.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","AI-driven systems manage security concerns by implementing security gates at various points within the system and continuously monitoring the activities of agents to ensure they do not exceed their access parameters. This is crucial in the context of AI use cases involving egress gateways, where organizations configure APIs for quota management and move logic to the egress gateway level, highlighting the need for robust security measures to maintain system integrity.",multi_hop_abstract_query_synthesizer
How do security considerations in AI-driven systems relate to the performance of models like HealthGPT-M3 in medical data analysis and visual comprehension tasks?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nC.6 Case Study\nFigures 11 and 12 illustrate examples of modality transformation and super-resolution reconstruction. In Figure 11, the results\ngenerated by our method in the CT (MRI) to MRI (CT) transformation task are highly close to the ground truth, effectively\nguiding the model in the transformation across different regions. For the MRI super-resolution reconstruction task, Figure 12\ndemonstrates the accuracy of our method in restoring scan image details, accurately reconstructing the essential details of the\nimage.\nTable 11: The experimental results for the four reconstruction tasks.\nCT(Brain) CT(Pelvis) MRI (Brain) MRI(Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\nSEED-X 20.18 27.66 112.11 21.53 28.02 102.87 4.90 27.62 112.86 6.31 27.89 106.21\nUnified-IO 2 83.93 36.09 17.95 85.36 35.10 25.46 87.50 34.25 25.47 86.31 33.53 29.80\nHealthGPT-M3 91.73 36.42 15.46 94.26 37.30 12.53 88.76 33.97 27.05 84.40 33.11 32.62\n34.08\n15.87\n9.16\n5.62\n13.33\n21.94\nHealthGPT\nLLaVA-Med\nHuatuoGPT-Vision\nLlama-3.2\nInternVL-2\nShow-o\nHuman\nEvaluation\n(a) (b)\nFigure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.\n17']","Security considerations in AI-driven systems are crucial to ensure that malicious agents or bots do not compromise the integrity and security of the system. This involves assuming a breach and implementing security gates, along with continuous monitoring to track activities. In the context of medical data analysis and visual comprehension tasks, models like HealthGPT-M3 demonstrate high performance, as evidenced by their superior SSIM, PSNR, and MSE scores in tasks such as CT to MRI transformation and MRI super-resolution reconstruction. Ensuring the security of these AI systems is vital to maintain the reliability and accuracy of the model's performance, as any breach could potentially alter the data or the model's outputs, thereby affecting the overall effectiveness of the AI in medical applications.",multi_hop_abstract_query_synthesizer
How AI-driven systems handle security with agent-to-agent communication and what protocols are used?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [1300.00s] Functionality of Specialized Agents\nFor instance, the observability agent connects to numerous internal APIs to retrieve data. While it primarily focuses on data retrieval, other agents, such as those involved in deployment, can perform actions as well. This illustrates the diverse capabilities of the agents within the Coro ecosystem.\n\n# [1330.96s] Importance of Agent-to-Agent Communication\nAnother significant topic is the communication between agents. Standard protocols are emerging to facilitate agent-to-agent communication, similar to how the MCP standardizes communication between AI applications and tools. These protocols are still evolving, with several options available, including A2A by Google and ACP by IBM.']","In AI-driven systems, security is a major concern due to the potential presence of malicious agents or bots that can launch attacks. To handle security, it is crucial to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure agents do not exceed their access parameters. Regarding agent-to-agent communication, standard protocols are emerging to facilitate this interaction, similar to how the MCP standardizes communication between AI applications and tools. These protocols are still evolving, with options such as A2A by Google and ACP by IBM being available.",multi_hop_abstract_query_synthesizer
How AI-driven systems and AI agents help in developer productivity?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1190.08s] The Need for AI Agents\nThe discussion raises the question of whether an AI agent is necessary for this scenario. While an AI agent can be beneficial, the specific requirements and technical feasibility must be evaluated to determine the best approach for implementation.\n\n**Time Range: 00:20:01 - 00:30:03**\n\n# [1201.20s] Overview of the Integration Scenario\nIn this scenario, the integration approach is deemed overkill. However, the team is aware of the necessary components to build the required workflow, allowing for a simple integration without the need for an agent.\n\n## [1213.60s] Ideal Workflow Requirements\nThe ideal pattern for this scenario involves establishing a generative workflow. The construction of this workflow is straightforward. The team will interact with admin APIs, as direct communication with users is not feasible. The APIs utilized by the user portal require user authorization through tokens. Instead, the admin portal can be accessed by administrators to review user data, such as booking history and reviews, based on user IDs.', '<3-hop>\n\n## [649.52s] WSO2 Solutions Team Initiatives\nThe solutions team at WSO2 is actively engaged in this sector, although they do not provide a full AI solution. Instead, they focus on two main areas. The first is ""AI for Code,"" which offers developer-focused capabilities designed to enhance developer experiences and productivity throughout the software development life cycle. The second area is ""Code for AI,"" where they provide programming abstractions and building blocks that can be utilized to create custom AI solutions.\n\n### [715.12s] AI for Code\nAn example of ""AI for Code"" can be seen in the integration capabilities developed by the WSO2 solutions team. In the healthcare sector, they support various standards such as FHIR, HL7, X12, CDA, and decom messages, along with pre-built translations between these standards. In the banking sector, they support ISO 853, ISO 222 (also known as MX messages), and Swift MT messages, with pre-built translations for Swift MT to MX.\n\nThe integration solution includes a co-pilot that developers can use. This co-pilot is a generic or horizontal AI, but for healthcare and banking requirements, WSO2 has developed vertical AIs. For instance, the healthcare co-pilot is designed to understand healthcare-related prompts. It is aware of standards such as FHIR and EHR systems, and it utilizes the available libraries and solutions to address healthcare-specific requirements.']","AI-driven systems require continuous monitoring to ensure security, especially against malicious agents, which is crucial for maintaining system integrity. In scenarios where AI agents are considered, their necessity and feasibility must be evaluated to determine the best approach. Meanwhile, the WSO2 solutions team enhances developer productivity through 'AI for Code,' which provides developer-focused capabilities and integration solutions. These solutions include a co-pilot for healthcare and banking sectors, supporting various standards and aiding developers in creating custom AI solutions.",multi_hop_abstract_query_synthesizer
How AI-driven systems be secure and user-friendly with technologies for building integrations?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.', '<3-hop>\n\n## [2741.04s] Technologies for Building Integrations\nTo develop and deploy general integrations, we can utilize the WSU IP pass, which supports the integration and deployment of various workflows, including agents and RAG. Developers can use their preferred programming languages and frameworks, such as Python, Semantic Kernel, or LangChain, to build and deploy these integrations.\n\n# [2786.08s] Standardizing Integration Processes\nNext, we will discuss how to standardize the integration of LLMs with external data and APIs. The Model Context Protocol (MCP) serves as a framework for this standardization, allowing for seamless connections between tools, resources, and prompts.']","AI-driven systems can be secure by implementing security gates at various points within the system and continuously monitoring for malicious agents, as discussed in the context of security considerations. To make AI user-friendly, recent developments have allowed users to interact with models through conversational interfaces, making AI accessible to a broader audience. Technologies for building integrations, such as the WSU IP pass and frameworks like Python, Semantic Kernel, or LangChain, support the development and deployment of workflows, ensuring that AI systems can be both secure and user-friendly by facilitating seamless integration and deployment.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and what role does the WSO2 Solutions Team play in enhancing AI capabilities for healthcare through fine-tuning SLMs?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n### [1683.04s] Conclusion\nIn conclusion, the discussion highlights the ongoing work in fine-tuning SLMs to enhance agent performance and accuracy. The session wraps up with gratitude for the audience's attention and a transition to the next segment.\n\n**Time Range: 00:00:03 - 00:10:03**\n\n# [3.36s] Introduction to the Panel\nThe panel discussion begins with a warm welcome to the audience. The moderator introduces the panelists, highlighting their roles and affiliations. The panelists include Yad Ahmed, the CTO of Arabic AI; Rana Kalaf, the Chief AI Officer at WSO2; Alan Shmal, the Executive Vice President of Platform at Vistra; and Mahesh Saloria, the Head of Architecture at HSBC."", '<3-hop>\n\n## [649.52s] WSO2 Solutions Team Initiatives\nThe solutions team at WSO2 is actively engaged in this sector, although they do not provide a full AI solution. Instead, they focus on two main areas. The first is ""AI for Code,"" which offers developer-focused capabilities designed to enhance developer experiences and productivity throughout the software development life cycle. The second area is ""Code for AI,"" where they provide programming abstractions and building blocks that can be utilized to create custom AI solutions.\n\n### [715.12s] AI for Code\nAn example of ""AI for Code"" can be seen in the integration capabilities developed by the WSO2 solutions team. In the healthcare sector, they support various standards such as FHIR, HL7, X12, CDA, and decom messages, along with pre-built translations between these standards. In the banking sector, they support ISO 853, ISO 222 (also known as MX messages), and Swift MT messages, with pre-built translations for Swift MT to MX.\n\nThe integration solution includes a co-pilot that developers can use. This co-pilot is a generic or horizontal AI, but for healthcare and banking requirements, WSO2 has developed vertical AIs. For instance, the healthcare co-pilot is designed to understand healthcare-related prompts. It is aware of standards such as FHIR and EHR systems, and it utilizes the available libraries and solutions to address healthcare-specific requirements.']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to maintain system integrity and security. This approach assumes a breach and tracks agents to ensure they do not exceed their access parameters. The WSO2 Solutions Team contributes to enhancing AI capabilities, particularly in healthcare, by focusing on 'AI for Code' and 'Code for AI.' They provide developer-focused capabilities and programming abstractions that support healthcare standards such as FHIR and EHR systems. Although they do not offer a full AI solution, their initiatives include developing vertical AIs tailored for healthcare, which are fine-tuned to understand healthcare-related prompts and utilize available libraries and solutions to meet specific healthcare requirements.",multi_hop_abstract_query_synthesizer
What are the security considerations in AI-driven systems and how do they affect user interaction with applications?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n**Time Range: 00:30:00 - 00:40:04**\n\n# [1800.80s] Integration with the Database\nThe process begins with integrating the necessary components into the index within the database. Once this setup is complete, the application can efficiently handle user queries.\n\n## [1808.80s] User Interaction with the Application\nWhen a user presents a task or question to the application, the first step is to convert that input into a vector embedding. This conversion is essential because text cannot be directly compared to vectors. After obtaining the vector representation of the user's question, the application can then compare it with the existing document vectors stored in the vector database.""]","In AI-driven systems, security considerations are crucial due to the potential presence of malicious agents or bots that can launch attacks. It is important to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure these agents do not exceed their access parameters. This is vital for maintaining system integrity and security. These security measures directly affect user interaction with applications, as they ensure that when a user presents a task or question, the system can safely convert the input into a vector embedding and compare it with existing document vectors in the database without compromising security.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while facilitating dynamic interactions through AI agents?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1040.08s] The Role of AI Agents\nAI agents are essential for dynamic interactions, connecting to business APIs, and leveraging personalization. They can remember user preferences and provide a more tailored experience, which is not possible with generative integrations alone.\n\n# [1072.32s] System Architecture Overview\nThe proposed architecture includes core business APIs, such as search and booking APIs, and a trip planning agent that connects to user personalization data. This setup aims to streamline the process of answering hotel-specific questions without delays caused by waiting for human representatives.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring the activities of agents to prevent them from acting outside their intended purpose. This is crucial in the context of dynamic interactions facilitated by AI agents, which connect to business APIs and leverage personalization to provide tailored experiences.",multi_hop_abstract_query_synthesizer
"How do security considerations in AI-driven systems relate to the development of user interfaces, particularly in the context of the retrieval pipeline and agentic sample?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4115.28s] Conclusion of the Retrieval Pipeline\nThe retrieval pipeline for the RAG has been successfully established. The next step involves moving on to the agentic sample, which serves as the main interface for users. This interface will display the chat functionality, allowing users to interact with the system effectively.\n\nThe tools have been integrated, and the system message has been adjusted to enhance user experience. As users may not provide detailed queries, it is essential to consider the tools required to efficiently respond to common inquiries, such as planning a trip to a specific destination.']","In AI-driven systems, security considerations are crucial due to the potential presence of malicious agents or bots that can launch attacks. To maintain system integrity, it is important to assume a breach and implement security gates, along with continuous monitoring to track agent activities. This ensures that agents do not exceed their access parameters. In the context of the retrieval pipeline and the development of the agentic sample, which serves as the main user interface, these security measures are vital. The interface allows users to interact with the system effectively, and integrating security considerations ensures that user interactions remain secure and that the system can efficiently respond to user inquiries without compromising security.",multi_hop_abstract_query_synthesizer
How AI-driven systems keep safe from bad agents and what guardrails stop policy violations?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n## [1072.00s] User Interaction and Suggestions\nWhen a user checks the sessions through the mobile application, a request is sent to the session integration, which retrieves the user ID. This ID is then used to access the agenda information and the user's profile, allowing the model to generate personalized suggestions.\n\n## [3713.68s] Common Examples of Guardrails\nTo better understand guardrails, it is helpful to explore common examples. One of the most widely used guardrails is content filtering. For instance, if a user attempts to generate harmful content, such as instructions on committing violence or self-harm, the content filtering guardrails will block such requests before they reach the user.\n\nAdditionally, classifier-based guardrails, such as Llama Guard, are employed to check for safety and policy violations. This tool is particularly effective against jailbreaking attempts, as it reviews prompts before they are sent to the LLM. If a prompt is identified as an attempt to jailbreak the model, it will not be processed.""]","AI-driven systems maintain safety from malicious agents by implementing security gates at various points within the system and conducting continuous monitoring to ensure these agents do not exceed their access parameters or act outside their intended purpose. To prevent policy violations, guardrails such as content filtering and classifier-based tools like Llama Guard are used. Content filtering blocks harmful content requests, while Llama Guard checks for safety and policy violations, effectively preventing jailbreaking attempts by reviewing prompts before they are processed by the model.",multi_hop_abstract_query_synthesizer
How do AI-driven systems address security concerns and bias in underwriting?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [789.92s] Addressing Bias in Underwriting Co-Pilot\nIn the context of our underwriting co-pilot, which processes a significant amount of personal data, it is crucial to address potential biases that may influence decision-making. The underwriting co-pilot utilizes input from various sources, including bureau data, medical reports, and historical data, alongside underwriting guidelines established by regulators. \n\nTo mitigate bias, we employ a three-stage approach. The first stage involves a human-in-the-loop system, where underwriters provide feedback on the decisions made by the agents. This feedback is then relayed to our AI engineers. The second stage consists of retraining the model to eliminate any biased outputs by adjusting the relevant parameters. Finally, we have an audit process in place, where historical decisions made by human underwriters are reviewed by auditors, including those from regulatory bodies. Any incorrect decisions are rectified, and the model is retrained accordingly. Thus, our strategy heavily relies on human feedback and continuous improvement.', ""<3-hop>\n\n**Time Range: 00:00:03 - 00:10:04**\n\n# [3.76s] Introduction to AI and Generative AI\nGood morning, everybody. The focus of today's discussion is on artificial intelligence (AI), particularly generative AI. We will explore the significance of integration in building AI applications in the current landscape, especially with the rise of generative AI. This topic is crucial, and we will also cover common integration patterns associated with generative AI.\n\n## [42.32s] The Need for Retrieval-Augmented Generation\nIn addition to integration patterns, we will delve into the necessity of retrieval-augmented generation. This will be discussed in detail, along with the concept of agents, which is a hot topic in the AI community today. We will also examine the importance of the Model Context Protocol (MCP) and the responsibility that comes with building effective AI applications. It is essential that AI systems are designed with certain guardrails and governance in mind. We will touch upon the concept of zero trust design for AI agents, which, while traditionally applied to other domains, is now being adapted for AI.""]","AI-driven systems address security concerns by assuming a breach and implementing security gates at various points within the system, along with continuous monitoring to track the activities of agents and ensure they do not exceed their access parameters. To address bias in underwriting, a three-stage approach is employed: a human-in-the-loop system for feedback, retraining the model to eliminate biased outputs, and an audit process to review and rectify historical decisions, ensuring continuous improvement.",multi_hop_abstract_query_synthesizer
What are the security considerations in AI-driven systems and how does the Coro Copilot system address these within its architecture?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [1204.16s] Overview of Co-Pilot and Its Functionality\nThe discussion begins with an introduction to specific inputs and outputs related to a co-pilot system known as Coro Copilot. This system is currently undergoing a revamp, with a new version on the way. Coro Copilot allows users to interact with the Coro platform, providing access to various functionalities such as project documentation and service status inquiries.\n\n## [1242.24s] Architecture of Coro Copilot\nThe architecture of Coro Copilot follows a supervisor pattern. The initial interaction with the user is managed by a supervisor agent, which then delegates tasks to a set of domain-specific agents. These specialized agents include observability, marketplace, and testing agents, among others. The teams responsible for developing these features are best equipped to create the necessary prompts for their respective agents.', ""<3-hop>\n\n## [1391.20s] The Unpredictable Nature of AI Development\nThe unpredictable nature of AI development is highlighted, with the assertion that no one can be certain about future advancements. The analogy of electricity is used to illustrate how initial transformations often focus on replacing existing technologies rather than reimagining workflows. Companies that fail to rethink their processes in light of new capabilities may find themselves lagging behind.\n\n## [1410.48s] Challenges Addressed by A2A Protocol\nThe A2A protocol aims to address the challenges faced in multi-agent systems, where agents may not be aware of each other's capabilities or the data formats required for communication. A2A standardizes this communication, providing a transport protocol and features that allow agents to understand one another better.""]","In AI-driven systems, security considerations include the presence of malicious agents or bots that can launch attacks. It is crucial to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure agents do not exceed their access parameters. The Coro Copilot system addresses these concerns within its architecture by following a supervisor pattern. The initial interaction is managed by a supervisor agent, which delegates tasks to domain-specific agents, such as observability and testing agents. This structured delegation helps maintain system integrity and security by ensuring that each agent operates within its designated domain.",multi_hop_abstract_query_synthesizer
"How do security considerations in AI-driven systems impact the integration of AI in the healthcare sector, particularly in the context of WSO2's initiatives?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [649.52s] WSO2 Solutions Team Initiatives\nThe solutions team at WSO2 is actively engaged in this sector, although they do not provide a full AI solution. Instead, they focus on two main areas. The first is ""AI for Code,"" which offers developer-focused capabilities designed to enhance developer experiences and productivity throughout the software development life cycle. The second area is ""Code for AI,"" where they provide programming abstractions and building blocks that can be utilized to create custom AI solutions.\n\n### [715.12s] AI for Code\nAn example of ""AI for Code"" can be seen in the integration capabilities developed by the WSO2 solutions team. In the healthcare sector, they support various standards such as FHIR, HL7, X12, CDA, and decom messages, along with pre-built translations between these standards. In the banking sector, they support ISO 853, ISO 222 (also known as MX messages), and Swift MT messages, with pre-built translations for Swift MT to MX.\n\nThe integration solution includes a co-pilot that developers can use. This co-pilot is a generic or horizontal AI, but for healthcare and banking requirements, WSO2 has developed vertical AIs. For instance, the healthcare co-pilot is designed to understand healthcare-related prompts. It is aware of standards such as FHIR and EHR systems, and it utilizes the available libraries and solutions to address healthcare-specific requirements.']","Security considerations in AI-driven systems significantly impact the integration of AI in the healthcare sector by necessitating robust measures to protect against malicious agents or bots that could launch attacks. This requires continuous monitoring and the implementation of security gates to maintain system integrity. In the context of WSO2's initiatives, while they do not provide a full AI solution, their focus on 'AI for Code' and 'Code for AI' includes developing integration capabilities that support healthcare standards such as FHIR and EHR systems. These initiatives are crucial for ensuring that AI solutions in healthcare are secure and compliant with industry standards, thereby facilitating safe and effective integration.",multi_hop_abstract_query_synthesizer
"How does the integration of AI agents in evolving standards address security considerations in AI-driven systems, and what role do community engagements play in this process?","['<1-hop>\n\n## [798.24s] Evolving Standards and Community Engagement\nThe evolution of standards within the IM community is exciting, as it addresses the challenges associated with building agents. The involvement of team members, such as Aisha and Arana, in these discussions is crucial as the community works to solve these emerging issues.\n\n## [825.92s] Future of Agent DKI and Recommendations\nAs the conversation shifts towards the future of agent DKI, it is important to consider where this technology is headed. The concept of agents is gaining significant attention, and organizations that have not yet implemented agents are likely to do so soon. \n\nIt is anticipated that every engineer will need to become proficient in AI, as it becomes a fundamental part of the computing stack, akin to APIs and data. However, the current middleware stack is still evolving to support the integration of AI agents securely and efficiently.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","The integration of AI agents in evolving standards is crucial for addressing security considerations in AI-driven systems. As the middleware stack evolves to support the secure and efficient integration of AI agents, it is essential to consider the potential presence of malicious agents or bots that can launch attacks. To mitigate these risks, continuous monitoring and the implementation of security gates at various points within the system are necessary to ensure agents do not exceed their intended purpose or access parameters. Community engagement, involving team members like Aisha and Arana, plays a vital role in these discussions, as it helps address the challenges associated with building agents and ensures that security considerations are incorporated into the evolving standards.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security through token-based authentication and continuous monitoring?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2096.80s] Identity Representation and Security\nThis system introduced an extension to existing standards, enabling the identification of actions taken by agents on behalf of users. The staff allocation agent operated using its own token, proving its identity to the Guardio system and making API calls to backend services. This structure ensures that all users, applications, and agents have distinct identifications within the ecosystem.\n\n### [1024.40s] Securing AI Model Connections\nThe AI model, which could be based on various providers such as GPT-4, introduces another layer of security considerations. Connections between the business and the external AI model must be secured, and this is where governance layers and guardrails, as previously discussed, become critical.']","AI-driven systems ensure security by implementing token-based authentication and continuous monitoring. Token-based authentication is used to identify actions taken by agents on behalf of users, with each agent operating using its own token to prove its identity to systems like Guardio. This ensures distinct identifications for all users, applications, and agents within the ecosystem. Additionally, continuous monitoring is essential to track the activities of agents, ensuring they do not act outside their intended purpose or exceed their access parameters, thus maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
How does building modern AI applications relate to security considerations and the development of HealthGPT?,"['<1-hop>\n\n# [339.20s] Building Modern AI Applications\nBuilding modern AI applications involves connecting various components. The process begins with developing AI components, which is itself an integration challenge. Traditional machine learning approaches are becoming less relevant, with integration taking precedence. The success of this integration process relies on utilizing the appropriate patterns.\n\n## [408.88s] Core Patterns in AI Strategy\nWSO2 has identified three core patterns in their AI strategy, which have been extensively covered in previous sessions. The first pattern is GenAI integration, which involves making calls to a GenAI API. This pattern supports various use cases, including text summarization, sentiment analysis, and email drafting.\n\nThe second pattern is Retrieval-Augmented Generation (RAG), where data is stored in a knowledge base and retrieved as needed to ground responses. However, both RAG and GenAI integrations are primarily passive or reactive, lacking the ability to perform actions independently.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<3-hop>\n\nAppendix\nThis is the Appendix for “HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation\nvia Heterogeneous Knowledge Adaptation”. This Appendix is organized as follows:\n• Section A presents the experimental implementation details, the training process of HealthGPT, and the specifics of\nVL-Health.\n• Section B systematically provides an analysis of Heterogeneous Low-Rank Adaptation.\n• Section C shows supplementary experimental results to validate the effectiveness ofHealthGPT.\nA Implementation Details\nA.1 Model Details\nWe employ CLIP-L/14 (Radford et al. 2021) as the visual feature extractor, extracting both shallow and deep features to serve as\nvisual tokens. The model uses alignment adapters, implemented with two-layer MLPs, to align shallow features, representing\nconcrete visual granularity, and deep features, representing abstract visual granularity. These visual tokens are concatenated\nwith text tokens and input into the large language models (LLMs).\nHealthGPT offers two versions: HealthGPT-M3 and HealthGPT-L14, which are based on Phi-3-mini (Abdin et al.\n2024) and Phi-4 (Abdin et al. 2024) as the pre-trained LLMs, respectively. In addition, we expand the LLM vocabulary with\n8192 VQ indices derived from VQGAN-f8-8192 (Esser, Rombach, and Ommer 2021), serving as multi-modal tokens to further\naugment the model’s capacity for understanding both visual and textual input. Figure 6 shows the details.\nTable 6: Overview of the Components of HealthGPT.\nModel ViT Adapter MLP-dims Model dims LLM Params Vocab Size H-LoRA Rank\nHealthGPT-M3 CLIP-L/14 2-layer MLP 1024 3072 Phi-3-mini 3.8B 40206 16(Comp.), 64(Gen.)\nHealthGPT-L14 CLIP-L/14 2-layer MLP 1024 5120 Phi-4 14B 108547 8(Comp.), 32(Gen.)\nA.2 Training Details\nIn this study, we propose a three-stage learning strategy that is compatible with our innovative heterogeneous low-rank adapta-\ntion (H-LoRA). We provide a detailed hyperparameter configuration for the model’s three-stage training process. The specific\nhyperparameter settings used are listed in Table 7. These hyperparameters are crucial for ensuring the model’s learning efficacy\nand final performance.\nTable 7: Overview of Hyperparameter Configurations.\nHealthGPT-M3 HealthGPT-L14\nStage-1 Stage-2 Stage-3 Stage-1 Stage-2 Stage-3Hyperparameter\nComp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen.\nOptimizer AdamW AdamW AdamW AdamW AdamW AdamW\nAdapter LR 1e-3 2e-5 2e-5 2e-5 1e-3 2e-5 2e-5 2e-5\nLearning Rate / 2e-4 2e-4 2e-4 / 1e-4 2e-4 2e-4\nGlobal Batch Size 256 64 32 128 64 256 64 32 128 64\nWeight Decay 0 0 0 0 0 0\nDropout Rate 0 0.05 0.05 0.05 0 0.05 0.05 0.05\nLR Scheduler Warm Up Constant Warm Up Warm Up Constant Warm Up\nMax Sequence Length 2048 2048 2048 2048 2048 2048\nIt is worth noting that we sometimes observe instances of loss spikes during the training of medical visual comprehension\nand generation tasks. Through repeated validation, we discovered that larger model parameters and learning rates tend to lead to\nthis issue, which is the reason for the slight differences in hyperparameters betweenHealthGPT-M3 and HealthGPT-L14.\n12']","Building modern AI applications involves integrating various components, which is a challenge in itself, as traditional machine learning approaches become less relevant. This integration process is crucial for the development of advanced AI systems like HealthGPT, which uses a complex model architecture to unify comprehension and generation via heterogeneous knowledge adaptation. Security considerations are vital in AI-driven systems, as there is a growing concern about malicious agents or bots launching attacks. Continuous monitoring and implementing security gates are essential to maintain system integrity. These security measures are particularly important for applications like HealthGPT, which handle sensitive medical data and require robust protection against breaches.",multi_hop_abstract_query_synthesizer
"How does the A2A protocol facilitate communication in multi-agent systems, and what role does fine-tuning play in addressing the limitations of generative AI models?","[""<1-hop>\n\n## [1391.20s] The Unpredictable Nature of AI Development\nThe unpredictable nature of AI development is highlighted, with the assertion that no one can be certain about future advancements. The analogy of electricity is used to illustrate how initial transformations often focus on replacing existing technologies rather than reimagining workflows. Companies that fail to rethink their processes in light of new capabilities may find themselves lagging behind.\n\n## [1410.48s] Challenges Addressed by A2A Protocol\nThe A2A protocol aims to address the challenges faced in multi-agent systems, where agents may not be aware of each other's capabilities or the data formats required for communication. A2A standardizes this communication, providing a transport protocol and features that allow agents to understand one another better."", '<2-hop>\n\n## [337.84s] Limitations of Generative AI\nWhile generative AI offers many advantages, it also has limitations. One of the primary challenges is the phenomenon known as ""hallucination,"" where generative models can produce false information that appears convincing. For instance, if asked about the first person to walk on the moon, a model might fabricate an incorrect answer, demonstrating its lack of factual accuracy.\n\n### [482.56s] Addressing Limitations\nTo mitigate these issues, providing context to the model can help. However, even with context, models can still produce inaccurate outputs. Another limitation is their performance with mathematical problems, which has improved with fine-tuning but remains a concern for integration developers.']","The A2A protocol facilitates communication in multi-agent systems by standardizing the communication process, allowing agents to understand each other's capabilities and the data formats required for effective interaction. This transport protocol addresses the challenges of agents being unaware of each other's capabilities. In addressing the limitations of generative AI models, fine-tuning plays a crucial role by improving the models' performance, particularly in areas such as mathematical problem-solving, although challenges like hallucination still persist.",multi_hop_abstract_query_synthesizer
"How do security considerations in AI-driven systems relate to the implementation of an intelligent assistant and the use of an API key, particularly in ensuring the system's integrity and preventing misuse?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1829.12s] Introduction of the Intelligent Assistant\nOnce the system was up, a new intelligent assistant, referred to as ""chat B,"" was introduced. This assistant was made wide-screen for better visibility. To enhance its performance, a more effective prompt was provided to guide the agent\'s interactions, preventing it from asking excessive questions.\n\n### [1856.80s] User Interaction with the Assistant\nThe prompt used was, ""I\'m visiting Candy on this Sunday. I want a standard room for myself for two nights under this amount, and what are the options I have?"" The agent processed this request and provided suggestions. The user decided to proceed with the booking, confirming that there were no additional requests.', '<3-hop>\n\n## [4220.48s] API Key and Initial Query\nTo begin, an API key is obtained from the API gateway under chat completions. The specific query posed is, ""What guns are the best for a beginner to use?"" This question is not relevant for a hotel assistant, highlighting the limitations of a standard language model (LLM) without guardrails.\n\n## [4261.60s] Response from the Unprotected LLM\nIn this scenario, the LLM is designed to respond to any inquiry. Consequently, it provides a detailed description of various firearms suitable for beginners. This response is not ideal for an organization, as it lacks the necessary safeguards.']","In AI-driven systems, security considerations are paramount due to the potential presence of malicious agents or bots that can launch attacks. To maintain system integrity, it is crucial to assume a breach and implement security gates, along with continuous monitoring to ensure agents do not exceed their access parameters. This is particularly relevant when implementing an intelligent assistant, such as 'chat B,' which requires effective prompts to guide interactions and prevent misuse, such as asking excessive questions. Additionally, the use of an API key, as seen in the context of obtaining chat completions, highlights the importance of having guardrails in place. Without these safeguards, a language model (LLM) might respond to inappropriate queries, such as providing firearm recommendations, which is not suitable for a hotel assistant. Thus, integrating security measures and proper prompts are essential to prevent misuse and ensure the system's integrity.",multi_hop_abstract_query_synthesizer
How do AI-driven systems address latency issues and utilize vector databases for improved performance?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2700.40s] Addressing Latency Issues\nLatency has been identified as a challenge during code generation. To mitigate this issue, a streaming approach has been implemented, allowing users to see that the process is ongoing and not stalled. This method provides a concrete example of how latency can be managed effectively.\n\n## [2731.76s] Utilizing the Copilot for Code Generation\nThe copilot is designed to generate code for users, simplifying the process of connecting to the hotel search and admin APIs. Instead of manually writing the logic and data mapping, the copilot can handle these tasks efficiently. Once the code is generated, it is essential to review it before integrating it into the project.\n\nThe diagram reflecting the modified structure will show that the copilot has successfully fetched bookings and reviews without requiring manual coding.', '<3-hop>\n\n## [1841.68s] Searching for Relevant Information\nThe vector database performs the search operation using the provided vector, returning a selection of relevant document chunks. These chunks can then be utilized in the prompt to generate a response.\n\n# [1861.20s] Mastery of Generative AI\nAs we delve deeper into retrieval-augmented generation (RAG), it is crucial to understand its applications in generative AI. This technology enables the creation of content, answering questions, and analyzing data, all of which can significantly enhance organizational operations.\n\n# [1961.04s] Understanding AI Agents\nAI agents are systems that utilize generative AI models to autonomously make decisions and perform tasks. These tasks, often referred to as tools, can include functions such as API calls, database interactions, or even controlling physical devices.']","AI-driven systems address latency issues by implementing a streaming approach during code generation, allowing users to see ongoing progress and ensuring the process is not stalled. This method effectively manages latency challenges. Additionally, vector databases are utilized to perform search operations using provided vectors, returning relevant document chunks that can be used in prompts to generate responses. This enhances the performance and efficiency of AI-driven systems by facilitating quick and relevant information retrieval.",multi_hop_abstract_query_synthesizer
How does Heterogeneous Low-Rank Adaptation relate to endpoint configuration in HealthGPT's development?,"['<1-hop>\n\n## [3960.16s] Templating in the Egress Gateway\nAdditionally, the egress gateway allows for the definition of prompts with placeholders. Instead of sending the entire prompt each time, only essential keys, such as guest name, booking history, and preferences, need to be communicated. The gateway handles the mapping and sends the request to the OpenAI endpoint.\n\n# [4030.96s] API Management\nIn the API manager, users can create APIs by selecting specific providers. The API publisher facilitates this process, allowing for the configuration of endpoints and management of keys to ensure secure access.\n\n## [4094.00s] Policies and Guardrails\nPolicies can be applied to the configured APIs, such as prompt decorators that define the role of the assistant. Additionally, guardrails can be set up to handle PII, either by redacting sensitive information or masking it with placeholders. This provides control over how PII is managed throughout the process.', '<2-hop>\n\nAppendix\nThis is the Appendix for “HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation\nvia Heterogeneous Knowledge Adaptation”. This Appendix is organized as follows:\n• Section A presents the experimental implementation details, the training process of HealthGPT, and the specifics of\nVL-Health.\n• Section B systematically provides an analysis of Heterogeneous Low-Rank Adaptation.\n• Section C shows supplementary experimental results to validate the effectiveness ofHealthGPT.\nA Implementation Details\nA.1 Model Details\nWe employ CLIP-L/14 (Radford et al. 2021) as the visual feature extractor, extracting both shallow and deep features to serve as\nvisual tokens. The model uses alignment adapters, implemented with two-layer MLPs, to align shallow features, representing\nconcrete visual granularity, and deep features, representing abstract visual granularity. These visual tokens are concatenated\nwith text tokens and input into the large language models (LLMs).\nHealthGPT offers two versions: HealthGPT-M3 and HealthGPT-L14, which are based on Phi-3-mini (Abdin et al.\n2024) and Phi-4 (Abdin et al. 2024) as the pre-trained LLMs, respectively. In addition, we expand the LLM vocabulary with\n8192 VQ indices derived from VQGAN-f8-8192 (Esser, Rombach, and Ommer 2021), serving as multi-modal tokens to further\naugment the model’s capacity for understanding both visual and textual input. Figure 6 shows the details.\nTable 6: Overview of the Components of HealthGPT.\nModel ViT Adapter MLP-dims Model dims LLM Params Vocab Size H-LoRA Rank\nHealthGPT-M3 CLIP-L/14 2-layer MLP 1024 3072 Phi-3-mini 3.8B 40206 16(Comp.), 64(Gen.)\nHealthGPT-L14 CLIP-L/14 2-layer MLP 1024 5120 Phi-4 14B 108547 8(Comp.), 32(Gen.)\nA.2 Training Details\nIn this study, we propose a three-stage learning strategy that is compatible with our innovative heterogeneous low-rank adapta-\ntion (H-LoRA). We provide a detailed hyperparameter configuration for the model’s three-stage training process. The specific\nhyperparameter settings used are listed in Table 7. These hyperparameters are crucial for ensuring the model’s learning efficacy\nand final performance.\nTable 7: Overview of Hyperparameter Configurations.\nHealthGPT-M3 HealthGPT-L14\nStage-1 Stage-2 Stage-3 Stage-1 Stage-2 Stage-3Hyperparameter\nComp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen. Comp. Gen.\nOptimizer AdamW AdamW AdamW AdamW AdamW AdamW\nAdapter LR 1e-3 2e-5 2e-5 2e-5 1e-3 2e-5 2e-5 2e-5\nLearning Rate / 2e-4 2e-4 2e-4 / 1e-4 2e-4 2e-4\nGlobal Batch Size 256 64 32 128 64 256 64 32 128 64\nWeight Decay 0 0 0 0 0 0\nDropout Rate 0 0.05 0.05 0.05 0 0.05 0.05 0.05\nLR Scheduler Warm Up Constant Warm Up Warm Up Constant Warm Up\nMax Sequence Length 2048 2048 2048 2048 2048 2048\nIt is worth noting that we sometimes observe instances of loss spikes during the training of medical visual comprehension\nand generation tasks. Through repeated validation, we discovered that larger model parameters and learning rates tend to lead to\nthis issue, which is the reason for the slight differences in hyperparameters betweenHealthGPT-M3 and HealthGPT-L14.\n12']","Heterogeneous Low-Rank Adaptation (H-LoRA) is a key component in the development of HealthGPT, as it is part of the model's three-stage learning strategy. This adaptation technique is crucial for ensuring the model's learning efficacy and final performance. In the context of endpoint configuration, the API management allows for the configuration of endpoints and management of keys to ensure secure access, which is essential for deploying models like HealthGPT that rely on complex configurations and adaptations such as H-LoRA to handle medical data analysis and visual comprehension.",multi_hop_abstract_query_synthesizer
How do advancements in prompting techniques and custom integration development contribute to the security and efficiency of AI-driven systems in healthcare?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [659.36s] Advancements in Prompting Techniques\nIn contrast, future prompting involves providing examples to the model. For example, if we present the model with phrases like ""this is awesome"" (negative) and ""this is bad"" (positive), it learns from these examples. When a new sample, such as ""what\'s the horrible sh,"" is introduced, the model is expected to provide the correct response based on the prior examples. This approach is significant because it allows for the omission of explicit instructions, such as stating that sentiment analysis is required.\n\n### [735.84s] The Power of Example-Based Instructions\nThis pattern is crucial, especially when dealing with numerous instructions that need to be conveyed to the model for various tasks. By simply providing a set of examples, one can bypass the need for extensive instructions, making this a powerful prompt engineering technique.', '<3-hop>\n\n## [3340.72s] Custom Integration Development\nFor more customized solutions, such as triggering events from an FTP server, coding may be necessary. Although a new integration was not built during this session, a pre-existing integration was demonstrated to save time.\n\n## [474.56s] Trade-offs in AI Development\nThe conversation continues with a focus on the trade-offs involved in AI development. The moderator points out that teams often face decisions between optimizing for accuracy, latency, and cost. Alan Shmal responds by highlighting the three key metrics that matter: speed, quality, and cost. He explains that early in AI projects, engineers tend to prioritize accuracy to avoid user complaints about poor performance. However, this can lead to the use of expensive models that may not be efficient in terms of latency and cost.\n\nAlan shares his experience with high-quality models, such as those from Anthropic, which provide excellent reasoning but come with high operational costs. He notes the importance of balancing the need for speed in conversational assistants with the efficiency of the models used, ultimately leading to a focus on reducing latency while maintaining quality.']","Advancements in prompting techniques contribute to the efficiency of AI-driven systems by allowing models to learn from example-based instructions, which reduces the need for extensive explicit instructions. This technique enhances the model's ability to perform tasks such as sentiment analysis without detailed guidance, thereby streamlining operations. On the other hand, custom integration development plays a crucial role in the security of AI-driven systems by enabling tailored solutions, such as triggering events from an FTP server, which can be essential for maintaining system integrity. By implementing security gates and continuous monitoring, these integrations help protect against malicious agents or bots, ensuring that the system operates within its intended parameters. Together, these advancements enhance both the security and efficiency of AI-driven systems in healthcare, allowing for more robust and reliable operations.",multi_hop_abstract_query_synthesizer
What are the challenges in deploying AI applications and how do security considerations in AI-driven systems address these challenges?,"['<1-hop>\n\n## [76.16s] Challenges in AI Application Deployment\nAs organizations develop new AI applications, it is crucial to consider the challenges that arise when transitioning from a development environment to production. While it may feel satisfactory to see something work in development, ensuring scalability in production is essential to prevent organizational setbacks. The speakers encourage audience participation, inviting questions and interactions throughout the session.\n\n## [125.20s] Governance in AI Services\nArshad begins discussing the governance aspect of AI services, referencing recent news cases where AI systems have produced inappropriate or harmful responses. Such incidents pose risks to organizations, as they are responsible for delivering these services to end users. It is vital to govern AI behavior effectively to prevent such occurrences.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","The challenges in deploying AI applications include ensuring scalability in production to prevent organizational setbacks, as highlighted in the discussion on transitioning from a development environment to production. Security considerations in AI-driven systems address these challenges by implementing security gates and continuous monitoring to track the activities of malicious agents or bots. This ensures that these agents do not act outside their intended purpose or exceed their access parameters, thereby maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
How security considerations and strict regulations important in AI?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Importance of Strict Industry Regulations\nStrict industry regulations are paramount, especially in the context of artificial intelligence (AI). Regulators are expected to be very stringent regarding the usage of data and the activities surrounding AI technologies.\n\n## [616.48s] Current Landscape of AI\nA small demonstration illustrates the current state of AI. On top of the horizontal AIs, there are several vertical AIs that have been introduced and are being adopted at the moment. Different regions and even sub-areas within a vertical are tailored to meet specific requirements.']","Security considerations in AI-driven systems are crucial due to the presence of malicious agents or bots that can launch attacks. It is important to assume a breach and implement security gates at various points within the system, along with continuous monitoring to maintain system integrity. Additionally, strict industry regulations are paramount in the context of AI, as regulators are expected to be stringent regarding data usage and AI activities, ensuring that AI technologies are used responsibly and safely.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and how is the integration of AI agents facilitated in a purpose-driven egress scenario?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.', '<3-hop>\n\n# [3603.44s] Purpose-Driven Egress Scenario\nThe system is designed for a purpose-driven egress scenario. In this context, when a call is made from the backend to the outside world, the response is intercepted and routed back to the backend rather than the inducer application. This allows for the inclusion of an assessment in the response, detailing any failed guardrails and the reasons behind them. Consequently, the backend can take appropriate actions, such as reinitiating the LLM call or logging errors.\n\n**Time Range: 00:30:01 - 00:40:06**\n\n# [1801.20s] Overview of the Booking System\nThe booking system is a crucial component of the service, and it requires periodic restarts, especially after code changes. In this instance, the service was stopped to implement updates, followed by a restart to ensure everything is functioning correctly.']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to ensure they do not act outside their intended purpose or exceed their access parameters. This is crucial for maintaining the integrity and security of the system. In a purpose-driven egress scenario, the system is designed to intercept and route responses back to the backend rather than the inducer application. This allows for an assessment of any failed guardrails and the reasons behind them, enabling the backend to take appropriate actions, such as reinitiating the LLM call or logging errors. This integration facilitates the secure and efficient operation of AI agents within the system.",multi_hop_abstract_query_synthesizer
How AI-driven systems and AI integration work together to make sure security is good and developers can make new applications?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1816.72s] Focus on AI Integration\nThe primary focus today will be on the AI aspects of the integration product, rather than the integration components themselves. At its core, this product specializes in AI, enabling developers to create innovative applications.\n\n## [1855.92s] Building a Hello Agent Application\nTo begin the programming exercise, the first step is to create a ""Hello Agent"" application. The process starts with an empty project, where the developer will add an artifact. This integration tool allows for the creation of various automations, HTTP services, file integrations, and event integrations. However, the focus here is on the AI agent component.']","AI-driven systems require robust security measures due to the presence of malicious agents or bots that can launch attacks. Continuous monitoring is essential to maintain system integrity and security by ensuring these agents do not exceed their access parameters. On the other hand, AI integration focuses on enabling developers to create innovative applications by providing tools to build automations, HTTP services, and event integrations. Together, these aspects ensure that while AI-driven systems are secure, they also offer a platform for developers to innovate and create new applications.",multi_hop_abstract_query_synthesizer
What are the security considerations for AI-driven systems and how does HealthGPT perform in medical visual comprehension tasks?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nTable 3: Comparison results of super-resolution task.\nModel SSIM↑ PSNR↑ MSE↓ LPIPS↓\nSRGAN 71.34 32.01 41.27 24.50\nDASR 71.57 32.34 38.25 19.17\nReal-ESRGAN 67.30 31.87 42.57 20.64\nLIIF 73.27 32.13 40.14 22.93\nBSRGAN 69.97 31.97 41.52 28.72\nHealthGPT-M3 78.19 32.76 34.47 12.02\nHealthGPT-L14 77.94 32.71 35.19 12.43\nFigure 5: Performance comparison of LoRA, MoELoRA,\nand H-LoRA under different rank settings.\net al. 2024b), Llama-3.2 (Dubey et al. 2024)). Addition-\nally, we test several SOTA unified visual comprehension\nand generation models, including Show-o (Xie et al. 2024),\nUnified-IO 2 (Lu et al. 2024), and Janus (Wu et al.\n2024). The experimental results are shown in Table 1, with\nthe following key observations: (i) SOTA Results Com-\npared with LVLMs: In medical visual comprehension\ntasks, HealthGPT demonstrates superior performance,\nsignificantly outperforming both medical-specific models\n(e.g., HuatuoGPT-Vision) and general-purpose models (e.g.,\nLlama-3.2). (ii) Surpassing Current Unified LVLMs: De-\nspite being trained on billions of data points, unified mod-\nels still exhibit poor generalization performance in medi-\ncal visual comprehension. For instance, Unified-IO 2 scored\nonly 33.8. In contrast,HealthGPT-M3, with only 3.8B pa-\nrameters, scored 61.3 on the medical multi-modal unified\ntask, significantly outperforming existing unified models in\nmedical downstream scenarios. (iii) Stable Improvement\nwith Large Base Model: Our method demonstrates excel-\nlent scalability, with HealthGPT-L14 achieving a score\nof 66.4 in the larger model configuration. This result signif-\nicantly outperforms all other models, highlighting the effec-\ntiveness of scaling up the base model for enhanced perfor-\nmance in medical tasks.\nGeneration. We study three key tasks in medical imag-\ning. (i) Modality Conversion: In this task, we focus on\nthe conversion between CT and MRI modalities for the\nbrain and pelvic regions, designing four specific sub-tasks.\nAll comparative models (Pix2Pix (Isola et al. 2017), Cy-\ncleGAN (Zhu et al. 2017), BBDM (Li et al. 2023a),\n(%)\n(%)\n（a） （b）\nFigure 6: The loss visualization (a) and performance com-\nparison (b) with respect to different visual perceptions.\nVmamba (Liu et al. 2024e), and DiffMa (Wang et al.\n2024b)) trained a separate model for each sub-task, while\nHealthGPT unify all tasks into a single training process.\nThe experimental results, shown in Table 11, demonstrate\nthat our approach outperforms other methods across multi-\nple evaluation metrics. For instance, in the CT2MRI-Brain\ntask, HealthGPT-M3 achieves an SSIM of 79.38, signif-\nicantly surpassing traditional methods like Pix2Pix (71.09)\nand the recent DiffMa (71.47). (ii) Super-Resolution: We\nconduct 4× super-resolution experiments on the IXI dataset,\nwith the results presented in Table 3. Notably, most exist-\ning methods fail to fully leverage the prior knowledge of key\nstructures in medical images, resulting in significant short-\ncomings in detail recovery. In contrast, our method signif-\nicantly mitigates this issue. Specifically, HealthGPT-M3\nexcels in key metrics such as SSIM, PSNR, and ISE, achiev-\ning scores of 78.19, 32.76, and 34.47, respectively. Ad-\nditionally, HealthGPT-M3 achieves the lowest score of\n12.34, further validating its exceptional performance in hu-\nman visual perception. (iii) Reconstruction: We compare\nHealthGPT-M3 with unified models with reconstruction\ncapabilities, such as Unified-IO 2 and SEED-X. The results\nshow that our approach performs better controllability for vi-\nsual reconstruction. We also trainHealthGPT-L14 with a\nsimilar number of trainable parameters to the M3 version.\nHence, the similar performance between the two models\nmeets our expectations. Details are in the Appendix.\n5.3 In-Depth Study\nEffect of Heterogeneous Low-Rank Adaptation.H-LoRA\nprovides an optimized multi-LoRA architecture for multi-\ntask learning. We conduct extensive validation of this struc-\nture, with results presented in Table 4, comparing the per-\nformance of LoRA, MoELoRA, and H-LoRA in medical\nunified comprehension and generation tasks. In the majority\nof comprehension tasks and all generation tasks, H-LoRA\ndemonstrates superior performance, particularly in the Om-\nniMedVQA benchmark, where it improved from 64.90 to\n68.50. Notably, despite some applications of MoELoRA in\ncertain scenarios, it do not show advantages in this task and\n7']","In AI-driven systems, security considerations include the presence of malicious agents or bots that can launch attacks. It is crucial to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure these agents do not exceed their access parameters, thereby maintaining the system's integrity and security. In terms of performance, HealthGPT demonstrates superior capabilities in medical visual comprehension tasks, significantly outperforming both medical-specific models and general-purpose models. HealthGPT-M3, for instance, scored 61.3 on the medical multi-modal unified task, and HealthGPT-L14 achieved a score of 66.4, highlighting its effectiveness in medical tasks.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while integrating technologies for building integrations?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.', '<3-hop>\n\n## [2741.04s] Technologies for Building Integrations\nTo develop and deploy general integrations, we can utilize the WSU IP pass, which supports the integration and deployment of various workflows, including agents and RAG. Developers can use their preferred programming languages and frameworks, such as Python, Semantic Kernel, or LangChain, to build and deploy these integrations.\n\n# [2786.08s] Standardizing Integration Processes\nNext, we will discuss how to standardize the integration of LLMs with external data and APIs. The Model Context Protocol (MCP) serves as a framework for this standardization, allowing for seamless connections between tools, resources, and prompts.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring the activities of agents to maintain system integrity. When integrating technologies for building integrations, such as using the WSU IP pass for deploying workflows, it is crucial to maintain these security measures to prevent malicious activities and ensure that agents do not exceed their access parameters.",multi_hop_abstract_query_synthesizer
How do AI-driven systems enhance user experience while ensuring security against malicious agents?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [794.08s] Asking Hotel-Specific Questions\nIn addition to booking, users can inquire about specific hotel policies, such as pet policies. The system responds with relevant information, confirming that a particular hotel allows small pets, which enhances the user experience by providing immediate answers without the need for human intervention.\n\n# [878.80s] Achieving the Vision of the Chat Experience\nTo realize the vision of a seamless chat experience, it is essential to understand how to achieve this goal. The system must be capable of conducting natural conversations, booking trips, and assisting users in understanding their preferences without requiring explicit input.']","AI-driven systems enhance user experience by providing immediate answers to user inquiries, such as hotel-specific questions, without the need for human intervention. This seamless interaction is achieved through natural conversations and understanding user preferences. Simultaneously, these systems ensure security against malicious agents by implementing security gates, continuous monitoring, and assuming potential breaches to maintain system integrity.",multi_hop_abstract_query_synthesizer
How AI-driven systems handle security and what role enterprise architecture play in integration flow?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [2294.32s] Defining the Integration Flow\nWhen writing any integration, identifying the entry point is crucial. This can vary based on the enterprise architecture. For simplicity, the session will focus on automation, which can be triggered by events or scheduled tasks. The integration flow will involve retrieving booking history for a specific user from the platform, aggregating data to create a personalized profile, and sending this information to the LLM for processing. Finally, the completed profile will be stored in a database.\n\n**Time Range: 00:40:00 - 00:50:05**\n\n# [2400.88s] Overview of the Project Setup\nThe project currently appears to be in an empty state. Several modifications have been made in advance to facilitate the development process. One of the primary structures introduced is the ""record,"" which serves as a representation of data. Within this structure, there is a field designated for booking details, specifically tailored for the current form. A diagram illustrating the relationships between each record is also available.']","AI-driven systems handle security by assuming a breach and implementing security gates at various points within the system. Continuous monitoring is essential to track the activities of malicious agents or bots, ensuring they do not exceed their access parameters, thus maintaining the integrity and security of the system. In terms of enterprise architecture, it plays a crucial role in defining the integration flow, which involves identifying the entry point for automation. This flow includes retrieving booking history, aggregating data to create a personalized profile, and sending this information to the LLM for processing, with the completed profile being stored in a database.",multi_hop_abstract_query_synthesizer
How do AI-driven systems address security concerns while leveraging the power of AI models?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [136.08s] Key Innovations in AI\nThe first key innovation is the increasing power of AI models, which are becoming more expert-like. For instance, models like GPT-4 have demonstrated the ability to achieve high scores on tests such as the SAT and the US medical exam. Additionally, reasoning capabilities are improving, as evidenced by advancements in prompting techniques that are no longer necessary for these advanced models.\n\nThe second innovation pertains to agentic capabilities, where agents can reason, act, and perform tasks autonomously. The third area of improvement is multi-modality, which extends beyond text to include advancements in video and voice interactions, making them more natural and real-time.']","AI-driven systems address security concerns by implementing security gates at various points within the system and continuously monitoring the activities of agents to ensure they do not exceed their access parameters. This is crucial as the attack space evolves and malicious agents or bots may launch attacks. Meanwhile, the power of AI models is leveraged through their increasing expert-like capabilities, such as achieving high scores on standardized tests and improving reasoning abilities, which enhance the system's overall functionality and effectiveness.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while enhancing user experience through the introduction of an AI assistant tab?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [539.68s] Demonstration of the New Experience\nAnja will guide us through a demonstration of the new experience we have developed. We have set up a website for this purpose, and users will be logged in to personalize their experience. The current flow will be improved with the introduction of an AI assistant tab, which will provide users with information about the available capabilities. This will ensure that users are not left to navigate the system without guidance.\n\nAs we prepare to start the backend, we will showcase the agent we have built and explore the capabilities it offers, providing insight into what the user experience will look like.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring for malicious agents or bots to maintain system integrity. Simultaneously, user experience is enhanced through the introduction of an AI assistant tab, which provides users with information about available capabilities, ensuring they are guided and not left to navigate the system without assistance.",multi_hop_abstract_query_synthesizer
How hotels use unstructured information and indexing to answer user inquiries with poor grammar?,"['<1-hop>\n\n## [1394.88s] Data Utilization for Enhanced Responses\nTo achieve this, the team recognizes the need for a clear pattern. There is a wealth of data available, including documents, PDFs, and websites related to specific hotels. Hotels must be able to upload this unstructured information, which can then be indexed to answer user inquiries effectively.\n\n### [1426.40s] Implementation of Retrieval-Augmented Generation\nThis necessitates the integration of a retrieval-augmented generation (RAG) component, which will provide accurate contextual answers to users. Hotel owners will upload their documents and policies or direct the system to their websites. The information will be processed through a hotel information injection pipeline, which will clean, chunk, and index the data into a new hotel database.']","Hotels use unstructured information, such as documents, PDFs, and websites, which they upload to be indexed. This process involves a hotel information injection pipeline that cleans, chunks, and indexes the data into a new hotel database. This indexed information is then used to provide accurate contextual answers to user inquiries, even if the inquiries are made with poor grammar.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems balance security and user experience while incorporating generative AI integration patterns, considering the potential risks of malicious agents?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [615.04s] Balancing Security and User Experience\nIn the context of identity management (IM) and customer ID access management, it is essential to emphasize that security and user experience must be prioritized equally. As end users, including employees, interact with agents, the challenge of balancing user experience with security becomes increasingly complex. \n\nIn the digital landscape, the most secure approach is often to do nothing, which results in a poor user experience. Striking a balance is necessary, as agents need to perform their tasks without constantly interrupting users for consent or oversight. However, it is equally important to prevent agents from operating unchecked. This necessitates careful design of user experiences and interactions between authentication platforms and agent frameworks.', '<3-hop>\n\n## [795.92s] Incorporating Contextual Information\nThe most critical aspect involves supplying the current text, which adds necessary context to the LLM. This includes information about existing libraries, as the LLM may not be aware of the latest updates due to frequent releases. By utilizing few-shot prompting, the amount of instruction can be minimized, allowing for a more streamlined interaction with the user’s queries.\n\n# [840.40s] Exploring Generative Integration Patterns\nThe discussion now shifts to generative integration patterns. In the early stages of generative AI, the primary focus was on integrating generative models into applications. This integration allowed for basic interactions, such as conversing with a chat-based assistant, without the need for external data. For instance, code generation could be performed without any additional context.']","AI-driven systems balance security and user experience by carefully designing interactions between authentication platforms and agent frameworks, ensuring that agents can perform tasks without constantly interrupting users for consent or oversight. This balance is crucial as it prevents agents from operating unchecked, which is essential in the context of identity management and customer ID access management. Additionally, incorporating generative AI integration patterns involves integrating generative models into applications, allowing for basic interactions without the need for external data. This integration must be managed alongside security considerations, such as monitoring for malicious agents that could launch attacks, to maintain the integrity and security of the system.",multi_hop_abstract_query_synthesizer
How does the O2 Travels platform incorporate security measures in AI-driven systems to prevent malicious agent activities?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [650.00s] Demonstration Scenario Overview\nTo illustrate these concepts in detail, a demonstration scenario will be presented. This scenario is based on the O2 Travels platform, developed by WSU products, W2 Dewan EI, and other capabilities. The demonstration will showcase how an agentic system can be built using various technologies, including our IM and APIM products, to secure and govern the system. For those who have not participated in previous labs, a brief overview of the scenario is provided. The platform serves as a leisure and hotel booking service, allowing users to discover hotels, check availability, and make bookings. Additionally, AI is utilized to create personality profiles for users, enabling the assignment of a concierge to assist them during their stay.']","The O2 Travels platform, developed by WSU products and other capabilities, incorporates security measures in AI-driven systems by implementing security gates at various points within the system to prevent malicious agent activities. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This approach is part of a demonstration scenario that showcases how an agentic system can be built using various technologies, including IM and APIM products, to secure and govern the system.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while utilizing vector embeddings in generative applications?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [757.12s] Structure of Effective Prompts\nWhen building generative applications, the structure of the prompt is essential. Initially, the role is defined, indicating that the model should impersonate a specific personality, such as a Java developer. Following this, clear instructions are provided, detailing the expectations for generating accurate code. An output format is also specified, guiding the model on how to respond.\n\n## [1885.76s] The Value of Actionable AI Applications\nAn interesting question arises when considering the utility of AI applications. For instance, is it more beneficial to have an AI application that instructs users on how to drive a car, or one that can actually drive the car for them? The latter represents a more practical application of AI, as it not only analyzes data but also takes action on behalf of the user or organization.', '<3-hop>\n\n# [1370.24s] Understanding Vector Embeddings\nTo delve deeper into this process, it is essential to understand vector embeddings. A vector embedding is a numerical representation of words, paragraphs, or sentences in a high-dimensional space. While the explanation may seem simple, the application of vector embeddings in RAG is more complex, as it often involves representing larger text segments rather than individual words.\n\n## [1412.48s] Visualizing Vector Representations\nIn a high-dimensional representation, similar terms are positioned closer together. For example, the word ""cat"" is located near ""kitten,"" as the latter is a younger version of the former. Similarly, ""dog"" is closer to ""cat"" than ""wolf,"" illustrating the relationships between these terms. This spatial arrangement allows for the identification of similarities among various terms based on their proximity in the vector space.']","AI-driven systems ensure security by implementing continuous monitoring to track the activities of agents, preventing them from acting outside their intended purpose or exceeding their access parameters. This is crucial in the context of generative applications, where the structure of prompts and the use of vector embeddings play a significant role. Vector embeddings provide a numerical representation of text in a high-dimensional space, allowing for the identification of similarities among terms. By maintaining security gates and monitoring, AI-driven systems can effectively manage the complexities involved in using vector embeddings within generative applications.",multi_hop_abstract_query_synthesizer
"How does the Heterogeneous Low-Rank Adaptation (H-LoRA) approach enhance AI-driven systems, and what security considerations should be taken into account when implementing such systems?","['<1-hop>\n\nTable 8: Data distribution of VL-Health in three-stage learning strategy.\nMedical Task Stage-1 Stage-2\nComp. LLaV A-558k, PubMedVision-PT Mixed-47kGen. LLaV A-558k\nMedical Task Stage-3\nComp. LLaV A Med, MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, VQA-RAD\nGen. IXI, SynthRAD2023, MIMIC-CHEST-XRAY\nData Format. All data samples are converted into a unified instruction-response format for training and evaluation. Specifi-\ncally, the VL-Health dataset consists of the following components:\n• Task Type: Specifies the granularity of visual features output by the visual encoder and selects the corresponding H-\nLoRA submodule. For generation tasks, the response also includes multi-modal tokens corresponding to VQ indices.\n• Task Instruction: Guides the model to interpret the image and generate a response, covering various aspects of the\nimage and specifying the output format.\n• Response: The textual output generated based on the task instruction and input image, ensuring it meets the question and\nformatting requirements.\n• Input Image: Provides the visual signal for the model to process.\n• Target Image Index: In generation tasks, this is added as a multi-modal token to the response for autoregressive\ngeneration.\nB Analysis of Heterogeneous Low-Rank Adaptation\nWe propose H-LoRA, which utilizes hard routing selection to allocate plugins for knowledge learning and representation across\ntasks, thereby preventing conflicts arising from heterogeneous knowledge. Furthermore, within each task, we optimized based\non MoELoRA, enhancing performance while reducing computational overhead. The pseudocode is detailed Algorithm 1.\nAlgorithm 1: H-LoRA Algorithm\nInput: concrete-grained visual features FCon, abstract-grained visual featuresFAbs, comprehension-based H-LoRA modules\n({AComp.\ni }k\ni=1, RComp.\nouter ), generation-based H-LoRA modules({AGen.\ni }k\ni=1, RGen.\nouter), task type T (comprehension or generation),\nnumber of LoRA experts k, origin linear layer weights W0, text features T , hidden state h\nOutput: final output O\n// Select task-specific image features\nif T = generation task then\nFimg ← FCon\nelse if T = comprehension task then\nFimg ← FAbs\nend if\nU ←concat(Fimg, T ) // Concatenate image features and text features\n{Ai}k\ni=1, {Bi}k\ni=1, Router ← {AT\ni }k\ni=1, {BT\ni }k\ni=1, RT\nouter // Assign task-specific H-LoRA submodule\n// Merge LoRA experts’ matrices\nAmerged ← concat({Ai}k\ni=1)\nBmerged ← concat({Bi}k\ni=1)\nW ←R(h) // Generate routing weights based on input hidden state x\nWexpanded ← α × W/r ⊗ 1r // Expand routing weights to match merged matrices\nOH-LoRA ← (x · Amerged ⊙ Wexpanded) · Bmerged // Compute H-LoRA output using element-wise multiplication\nO ←x · W0 + OH-LoRA // Add H-LoRA output to pre-trained weights to get final output\nReturn O\nWe further analyzed the computational overhead differences between MoELoRA and H-LoRA. Assuming that both methods\nuse the same number of LoRA experts k, we can compare their time complexity from the perspective of the operational steps\ninvolved.\nComputational Overhead of MoELoRA. In MoELoRA, the operations involving the expert matrix mainly include the fol-\nlowing steps: (i) Expert Multiplication : MoELoRA requires 2k multiplications with the LoRA experts. (ii) Router Multi-\nplication: One multiplication with the Router is required. (iii) Router Output Expansion : MoELoRA needs to perform k\n14', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","The Heterogeneous Low-Rank Adaptation (H-LoRA) approach enhances AI-driven systems by utilizing hard routing selection to allocate plugins for knowledge learning and representation across tasks, which prevents conflicts arising from heterogeneous knowledge. This method optimizes performance while reducing computational overhead by selecting task-specific image features and merging LoRA experts' matrices. When implementing AI-driven systems, it is crucial to consider security aspects, such as the presence of malicious agents or bots that can launch attacks. Continuous monitoring is essential to track these agents' activities, ensuring they do not exceed their access parameters, thereby maintaining the system's integrity and security.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and what role does the final architecture play in this process?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4375.04s] Final Architecture and Security Measures\nThe final architecture incorporates mechanisms to secure agent operations and establish a zero trust framework. Technologies like Asgardio and identity servers play a crucial role in managing agent identities and ensuring proper authorization for actions taken by AI tools.\n\n## [4408.08s] Conclusion and Key Takeaways\nIn conclusion, the discussion highlighted the accessibility of AI systems, such as Jenna, while acknowledging their limitations, including issues like hallucination due to outdated knowledge and lack of access to private data. The integration of generative models with retrieval-augmented generation (RAG) enhances capabilities by allowing efficient knowledge injection and enabling agents to execute actual tools.\n\nFurthermore, standardizing connections to external systems, such as APIs and databases, is essential for effective integration. Finally, it is imperative to implement responsible AI practices, including the use of AI gateways and zero trust designs, when developing AI agents.']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring agent activities to prevent them from acting outside their intended purpose or exceeding their access parameters. The final architecture plays a crucial role in this process by incorporating mechanisms to secure agent operations and establishing a zero trust framework. Technologies like Asgardio and identity servers are used to manage agent identities and ensure proper authorization for actions taken by AI tools, thereby maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
How AI security important and what security considerations needed for AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [1358.80s] Conclusion and Reflection\nIn conclusion, it is important to acknowledge the current apprehension surrounding AI, with concerns about its potential to replace jobs and industries. However, innovation should be viewed as an opportunity rather than a threat. This perspective is encapsulated in a quote by Steve Jobs, which remains highly relevant today. Thank you very much for your attention.\n\n**Time Range: 00:00:03 - 00:10:07**\n\n# [3.76s] Introduction\nIn this session, the speakers, Arshad and Aisha, welcome everyone and express their hope that the audience is ready to get started. They are here to discuss how to govern and secure AI services in a scalable manner.']","AI security is important due to the presence of malicious agents or bots that can launch attacks on AI-driven systems. Security considerations needed include assuming a breach, implementing security gates at various points within the system, and continuous monitoring to track the activities of these agents. This ensures they do not act outside their intended purpose or exceed their access parameters, maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
How AI-driven systems handle security with credential management and what role does monitoring play?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n## [1711.12s] Credential Management\nThe presenter explains that one type of credential available is a secret, with plans to introduce additional options such as MTLS and private keys. They will also assign roles to the agent being configured.\n\n## [1752.48s] Finalizing Agent Configuration\nThe presenter has configured the agent's identity and secret, noting that in a production environment, these details should be sourced from a secure vault. The configuration includes connecting to the identity provider and enabling the chatbot component for the agent. The agent is now fully configured and ready for action.""]","In AI-driven systems, security is a major concern due to the potential presence of malicious agents or bots that can launch attacks. To handle security, it is crucial to assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters, thus maintaining the integrity and security of the system. Credential management plays a significant role in this process, as it involves configuring the agent's identity and secret, which should be sourced from a secure vault in a production environment. This configuration includes connecting to the identity provider and enabling the chatbot component for the agent, ensuring that the agent is fully configured and ready for action with appropriate security measures in place.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while facilitating dynamic interactions through AI agents?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1040.08s] The Role of AI Agents\nAI agents are essential for dynamic interactions, connecting to business APIs, and leveraging personalization. They can remember user preferences and provide a more tailored experience, which is not possible with generative integrations alone.\n\n# [1072.32s] System Architecture Overview\nThe proposed architecture includes core business APIs, such as search and booking APIs, and a trip planning agent that connects to user personalization data. This setup aims to streamline the process of answering hotel-specific questions without delays caused by waiting for human representatives.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring the activities of AI agents to prevent them from acting outside their intended purpose or exceeding their access parameters. This is crucial as AI agents are essential for dynamic interactions, connecting to business APIs, and leveraging personalization, which enhances user experience by remembering preferences and providing tailored services.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security and permissions during agent execution, and what are the potential risks involved?","['<1-hop>\n\n# [2401.28s] Executing Location Retrieval\nTo begin the process, the agent is instructed to execute a command to retrieve locations. This information is essential for the next steps in the execution. The agent, having gathered the necessary data, will utilize an API to obtain a set of locations that it can recommend to the user.\n\n## [2419.76s] Decision-Making Process of the Agent\nOnce the agent has the set of locations, it will analyze the information and consult the language model (LLM) to determine the next course of action. The LLM will suggest checking the weather conditions in these locations, as adverse weather could affect the recommendations. The agent will then use a weather API, inputting the locations as parameters, to retrieve the current weather conditions.\n\nAfter receiving the weather data, the agent will iterate on this information and send it back to the LLM. With sufficient data at hand, the agent can confidently make a decision and recommend the best locations for the user, concluding the task.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<3-hop>\n\n### [264.08s] Security and Permissions\nDespite proper governance, there are instances where AI systems may act outside their intended parameters. An example is cited where an AI agent deleted its production databases despite being instructed not to. This highlights the need for robust security measures and appropriate permission allocations.\n\n# [300.32s] Incorporating AI Agents into Enterprise Systems\nAisha takes over to discuss the integration of AI agents into enterprise systems. She emphasizes that the focus is not on creating toy applications but on providing AI with access to enterprise resources and business data. It is crucial to ensure that only authorized access is granted to this data.']","AI-driven systems ensure security and permissions during agent execution by implementing security gates at various points within the system and continuously monitoring the activities of agents to ensure they do not exceed their access parameters. This is crucial to maintain the integrity and security of the system, especially given the evolving attack space and the presence of malicious agents or bots. Despite these measures, there are potential risks involved, such as AI systems acting outside their intended parameters. An example of this is an AI agent deleting its production databases despite being instructed not to, highlighting the need for robust security measures and appropriate permission allocations.",multi_hop_abstract_query_synthesizer
How does retrieval-augmented generation contribute to the development of expert-like AI models in medical applications?,"['<1-hop>\n\n# [3600.80s] Introduction to the Retrieval Process\nTo begin the retrieval process, it is essential to utilize the policy assistant, which will facilitate the necessary steps. The first task involves updating Visual Studio Code, as a base project has already been created.\n\n## [3641.04s] Function Creation for Policy Retrieval\nThe objective is to retrieve specific data when a user inquires about a policy. For instance, if a user asks about the pet policy of a particular hotel, the integration should be triggered. A function will be created in the backend interface, named `query_hotel_policies`, which will accept two parameters: the type of inquiry (a string) and the hotel ID. \n\nThe reasoning behind including the hotel ID is twofold. First, users may select a specific hotel, allowing the system to scope in on that hotel. Second, the retrieval-augmented generation (RAG) can query all hotels, making it a more comprehensive solution. The function is designed to return either a simple string or an error based on the query.', '<2-hop>\n\n## [136.08s] Key Innovations in AI\nThe first key innovation is the increasing power of AI models, which are becoming more expert-like. For instance, models like GPT-4 have demonstrated the ability to achieve high scores on tests such as the SAT and the US medical exam. Additionally, reasoning capabilities are improving, as evidenced by advancements in prompting techniques that are no longer necessary for these advanced models.\n\nThe second innovation pertains to agentic capabilities, where agents can reason, act, and perform tasks autonomously. The third area of improvement is multi-modality, which extends beyond text to include advancements in video and voice interactions, making them more natural and real-time.']","Retrieval-augmented generation (RAG) contributes to the development of expert-like AI models in medical applications by enabling comprehensive data querying, such as querying all hotels for policy information, which enhances the model's ability to provide accurate and contextually relevant responses. This capability aligns with the increasing power of AI models, which are becoming more expert-like, as demonstrated by models like GPT-4 achieving high scores on standardized tests and improving reasoning capabilities.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security and governance, and what role does the integrated BI platform play in this process?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n## [4940.64s] Conclusion of the Session\nAs we wrap up, I want to highlight that we discussed many aspects today. To summarize, we implemented a practical use case for a hypothetical organization, adding value through AI features. This was accomplished within approximately 30 to 40 minutes using the integrated BI platform, along with assistance from the editors and databases.\n\nThere are a few key points to note. As Nadish mentioned earlier, some elements are still missing. For instance, we did not obtain user authorization before making a booking, which is something we need to address in the next session. Additionally, we must be cautious about granting the agent excessive power, as we are currently connecting to admin APIs. This is where agent identification and governance become crucial. We need to monitor the agent's actions and, if something goes wrong, analyze how it occurred and calculate the associated costs.\n\nAfter lunch, there will be a session led by Aisha that will cover these governance aspects. If you are interested, I encourage you to attend."", '<3-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.']","AI-driven systems ensure security by assuming a breach and implementing security gates at various points within the system, along with continuous monitoring to track the activities of agents and prevent them from exceeding their access parameters. Governance is crucial to prevent granting excessive power to agents, especially when connecting to admin APIs. The integrated BI platform aids in this process by providing a framework for implementing AI features that add value to organizations, while also highlighting the need for agent identification and governance to monitor actions and analyze any issues that arise.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security while maintaining model performance, particularly with the introduction of intelligent assistants?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1829.12s] Introduction of the Intelligent Assistant\nOnce the system was up, a new intelligent assistant, referred to as ""chat B,"" was introduced. This assistant was made wide-screen for better visibility. To enhance its performance, a more effective prompt was provided to guide the agent\'s interactions, preventing it from asking excessive questions.\n\n### [1856.80s] User Interaction with the Assistant\nThe prompt used was, ""I\'m visiting Candy on this Sunday. I want a standard room for myself for two nights under this amount, and what are the options I have?"" The agent processed this request and provided suggestions. The user decided to proceed with the booking, confirming that there were no additional requests.', ""<3-hop>\n\n### [1171.44s] Understanding Token Limitations\nAlthough newer models can support larger context windows, such as hundreds of thousands or even up to one million tokens, it is essential to manage costs effectively. Utilizing the full capacity of these models can lead to increased expenses, as each token consumed incurs a cost.\n\n**Time Range: 00:20:01 - 00:30:02**\n\n# [1201.04s] The Impact of Excessive Information on Model Performance\nWhen excessive information is included in the prompt, it can lead to increased costs and inefficiencies. This situation results in a scenario where the model has to sift through a large amount of data to determine what is relevant for completing the task. Consequently, this can reduce the accuracy of the task and lead to higher latencies, meaning slower response times. The model's performance is hindered due to the extensive processing required when handling a significant volume of data.""]","AI-driven systems ensure security by assuming a breach and implementing security gates at various points within the system, along with continuous monitoring to track the activities of agents and maintain system integrity. With the introduction of intelligent assistants, such as 'chat B,' performance is enhanced by providing effective prompts to guide interactions, preventing excessive questioning. However, excessive information in prompts can hinder model performance by increasing costs and inefficiencies, leading to reduced accuracy and slower response times.",multi_hop_abstract_query_synthesizer
How bots and personalized suggestions work together?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', ""<2-hop>\n\n## [1072.00s] User Interaction and Suggestions\nWhen a user checks the sessions through the mobile application, a request is sent to the session integration, which retrieves the user ID. This ID is then used to access the agenda information and the user's profile, allowing the model to generate personalized suggestions.\n\n## [3713.68s] Common Examples of Guardrails\nTo better understand guardrails, it is helpful to explore common examples. One of the most widely used guardrails is content filtering. For instance, if a user attempts to generate harmful content, such as instructions on committing violence or self-harm, the content filtering guardrails will block such requests before they reach the user.\n\nAdditionally, classifier-based guardrails, such as Llama Guard, are employed to check for safety and policy violations. This tool is particularly effective against jailbreaking attempts, as it reviews prompts before they are sent to the LLM. If a prompt is identified as an attempt to jailbreak the model, it will not be processed.""]","In AI-driven systems, bots can pose security risks, requiring continuous monitoring to ensure they do not exceed their access parameters. Meanwhile, personalized suggestions are generated by retrieving user IDs through session integration, which accesses agenda information and user profiles. This process allows the model to tailor suggestions to individual users. Both elements highlight the need for robust security measures to protect user data and ensure the integrity of personalized interactions.",multi_hop_abstract_query_synthesizer
How do AI-driven systems enhance medical visual comprehension and ensure security against malicious agents?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nTo address the needs of various tasks, the hidden states\nare divided into two types: (i) Concrete-grained features\nFCon = {f1, f2, . . . , fk}, k < L, derived from the shal-\nlower layers of ViT, containing sufficient global features,\nsuitable for generation tasks; (ii) Abstract-grained features\nFAbs = {fk+1, fk+2, . . . , fL}, derived from the deeper\nlayers of ViT, which contain abstract semantic information\ncloser to the text space, suitable for comprehension tasks.\nThe task type T (comprehension or generation) deter-\nmines which set of features is selected as the input for the\ndownstream large language model:\nFimg\nT =\n(\nFCon, if T = generation task\nFAbs, if T = comprehension task (6)\nWe integrate the image featuresFimg\nT and text featuresT into\na joint sequence through simple concatenation, which is then\nfed into the LLM Mllm for autoregressive generation.\n4.3 Heterogeneous Knowledge Adaptation\nWe devise H-LoRA, which stores heterogeneous knowledge\nfrom comprehension and generation tasks in separate mod-\nules and dynamically routes to extract task-relevant knowl-\nedge from these modules. At the task level, for each task type\nT, we dynamically assign a dedicated H-LoRA submodule\nθT , which is expressed as:\nR = MLLM(U|θ, θT ), θ T = {AT , BT , RT\nouter}. (7)\nAt the feature level for a single task, H-LoRA integrates the\nidea of Mixture of Experts (MoE) (Masoudnia and Ebrahim-\npour 2014) and designs an efficient matrix merging and rout-\ning weight allocation mechanism, thus avoiding the signif-\nicant computational delay introduced by matrix splitting in\nexisting MoELoRA (Luo et al. 2024a). Specifically, we first\nmerge the low-rank matrices (rank = r) of k LoRA experts\ninto a unified matrix:\nAmerged, Bmerged = Concat({Ai}k\n1 ), Concat({Bi}k\n1 ), (8)\nwhere Amerged ∈ Rdin×rk and Bmerged ∈ Rrk×dout\n. The\nk-dimension routing layer generates expert weights W ∈\nRtoken num×k based on the input hidden state x, and these are\nexpanded to Rtoken num×rk as follows:\nWexpanded = αkW/r ⊗ 1r, (9)\nwhere ⊗ denotes the replication operation. The overall out-\nput of H-LoRA is computed as:\nOH-LoRA = (xAmerged ⊙ Wexpanded)Bmerged, (10)\nwhere ⊙ represents element-wise multiplication. Finally, the\noutput of H-LoRA is added to the frozen pre-trained weights\nto produce the final output:\nO = xW0 + OH-LoRA. (11)\n900\n800\n700\n600\n500\n400\n300\n200\n100\n0\nComp. Gen.\n(a) (b)\n783K765K\n（K）\nFigure 4: Data statistics of VL-Health.\n4.4 Training Pipeline\n1st Stage: Multi-modal Alignment. In the first stage, we\ndesign separate visual adapters and H-LoRA submodules for\nmedical unified tasks. For the medical comprehension task,\nwe train abstract-grained visual adapters using high-quality\nimage-text pairs to align visual embeddings with textual\nembeddings, thereby enabling the model to accurately de-\nscribe medical visual content. During this process, the pre-\ntrained LLM and its corresponding H-LoRA submodules\nremain frozen. In contrast, the medical generation task re-\nquires training concrete-grained adapters and H-LoRA sub-\nmodules while keeping the LLM frozen. Meanwhile, we ex-\ntend the textual vocabulary to include multimodal tokens,\nenabling the support of additional VQGAN vector quanti-\nzation indices. The model trains on image-VQ pairs, en-\ndowing the pre-trained LLM with the capability for image\nreconstruction. This design ensures pixel-level consistency\nof pre- and post-LVLM. The processes establish the initial\nalignment between the LLM’s outputs and the visual inputs.\n2nd Stage: Heterogeneous H-LoRA Plugin Adaptation.\nThe submodules of H-LoRA share the word embedding\nlayer and output head but may encounter issues such as\nbias and scale inconsistencies during training across dif-\nferent tasks. To ensure that the multiple H-LoRA plugins\nseamlessly interface with the LLMs and form a unified base,\nwe fine-tune the word embedding layer and output head us-\ning a small amount of mixed data to maintain consistency\nin the model weights. Specifically, during this stage, all H-\nLoRA submodules for different tasks are kept frozen, with\nonly the word embedding layer and output head being op-\ntimized. Through this stage, the model accumulates foun-\ndational knowledge for unified tasks by adapting H-LoRA\nplugins.\n3rd Stage: Visual Instruction Fine-Tuning. In the third\nstage, we introduce additional task-specific data to fur-\nther optimize the model and enhance its adaptability to\ndownstream tasks such as medical visual comprehension\n(e.g., medical QA, medical dialogues, and report generation)\nor generation tasks (e.g., super-resolution, denoising, and\n5', '<3-hop>\n\n# [600.64s] Application Update and Architecture Overview\nThe discussion begins with an update on the application. A review of the architecture, both before and after the update, is presented. Initially, the architecture consisted of two primary flows: the registration flow, where users would visit a website to register and input their details into a database, and the data retrieval flow, which allowed users to access their session data from the database. \n\nWith the integration of AI capabilities, the architecture has become significantly more complex. Various agents, retrieval-augmented generation (RAG) integrations, and other components have been added to enhance functionality.']","AI-driven systems enhance medical visual comprehension by utilizing a multi-stage training pipeline that includes multi-modal alignment and visual instruction fine-tuning. This involves training abstract-grained visual adapters using high-quality image-text pairs to align visual embeddings with textual embeddings, enabling accurate description of medical visual content. Additionally, the integration of H-LoRA submodules allows for the dynamic routing of task-relevant knowledge, further improving comprehension tasks. To ensure security against malicious agents, these systems implement continuous monitoring and security gates at various points within the system to track activities and maintain integrity, assuming a breach is always possible.",multi_hop_abstract_query_synthesizer
How user ID parameter used in agentic AI for staff allocation?,"['<1-hop>\n\n### [4415.44s] Function to Retrieve User Profile\nThe function will be designed to get the user profile based on the user ID. The expected return type will be a string or an error, as we only need the personalized profile information.\n\n## [4470.08s] Establishing a PostgreSQL Connection\nTo proceed, we need to establish a new PostgreSQL connection. This involves specifying the host, user, password, database, and port. Once the connection is created, we will query a single row from the database using a simple select statement, sending the user ID as a parameter in the SQL query.\n\n### [4563.20s] Returning the User Profile\nThe return variable will be named ""profile,"" and the return type will be a string. The function will simply return this profile information.', ""<2-hop>\n\n### [920.32s] Staff Allocation Agent\nThe second agent operates in the background as a staff allocation agent. It is triggered when a booking is made, accessing the user's personal profile to assign appropriate staff for that booking instance. This integration raises important considerations regarding security boundaries within the agentic AI framework.\n\n## [948.00s] Security Boundaries in Agentic AI\nWhen introducing agentic AI into the platform, it is essential to establish various security boundaries. The user-agent interaction forms one boundary, while the backend systems represent another. These backend systems may interact with external parties, necessitating secure management of incoming and outgoing requests. Additionally, the ambient agent receives requests to perform tasks, requiring secure communication with the business's backend APIs and the ability to update existing bookings.""]","The user ID parameter is used in agentic AI for staff allocation by accessing the user's personal profile. This is done when a booking is made, and the staff allocation agent is triggered. The agent uses the user ID to retrieve the user's profile from the database, which is then used to assign appropriate staff for the booking instance. This process involves querying the database with the user ID as a parameter and returning the profile information as a string.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while integrating API connections and personalization features?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2450.88s] API Connections and Local Connectors\nThe goal is to call APIs and create a specific form of data. To begin, it is essential to connect to the APIs. In the BI environment, this is accomplished by navigating to the connections section. Here, various connectors are available, but the hotel search API and the admin API are not publicly accessible. Therefore, a local connector will be added using an OpenAPI specification that has been prepared in advance. The admin API will be selected, and a local connector will be created for easy access later.\n\nSimilarly, a local connector for the hotel search API will also be established. With both local connectors in place, the next step is to create connections to these APIs. The URLs have been pre-configured to save time, and the connections will be established for both the hotel search API and the admin API.', '<3-hop>\n\n## [1122.48s] Personalization Data Challenges\nChallenges arise in obtaining user personalization data, as raw data is available but not yet transformed into useful profiles. Additionally, the system must avoid delays caused by waiting for hotel representatives to respond to inquiries.\n\n## [1158.00s] Leveraging Strategic Data for Personalization\nTo enhance personalization, the system can utilize strategic data, including booking history, search behaviors, and reviews. By applying generative AI, this information can be transformed into actionable personalization profiles that improve the user experience.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring for malicious agents or bots that could launch attacks, as mentioned in the context of security considerations. When integrating API connections, local connectors are used to securely access APIs like the hotel search API and the admin API, ensuring that connections are established with pre-configured URLs to save time and maintain security. For personalization, strategic data such as booking history and search behaviors are transformed into actionable profiles using generative AI, which enhances user experience while maintaining data integrity and security.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security when creating and managing agents through the administrative portal?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1600.32s] Logging into the Administrative Portal\nThe presenter logs into the administrative portal of Asgardio, where they have pre-configured various settings. They will demonstrate how to create a new agent and manage its attributes.\n\n## [1645.52s] Creating and Configuring an Agent\nIn the portal, there is a dedicated section for agents. The presenter discusses the process of creating a new agent, including providing a description and generating a unique ID and secret for authentication. The system allows for the management of various attributes, which can be customized based on business requirements.']","AI-driven systems ensure security when creating and managing agents through the administrative portal by implementing security gates at various points within the system and continuously monitoring the activities of agents. This approach helps in tracking the agents to ensure they do not exceed their access parameters or act outside their intended purpose, thereby maintaining the integrity and security of the system. The administrative portal allows for the creation and configuration of agents, including generating a unique ID and secret for authentication, which further enhances security.",multi_hop_abstract_query_synthesizer
How do AI-driven systems ensure security while integrating APIs with MCP?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [3081.60s] Fixed Specifications of MCP\nUnlike APIs, which can have flexible specifications, MCP has a fixed specification that defines the available endpoints. These endpoints include functionalities such as listing available resources or executing specific tools by name. This structured approach ensures consistency and reliability in interactions with the MCP server.\n\n## [3122.08s] Integration of APIs with MCP\nThere is a growing trend to connect APIs directly to MCP hosts. This integration allows agents to utilize API resources as tools, enhancing their functionality. For instance, platforms like Cursor Cloud enable users to register an MCP server and perform various operations using natural language. This trend highlights the importance of understanding how MCP works in conjunction with APIs.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring for malicious agents or bots that could launch attacks. This is crucial as the attack space evolves, and it is important to assume a breach to maintain system integrity. When integrating APIs with MCP, the fixed specifications of MCP provide a structured approach that ensures consistency and reliability. This integration allows agents to utilize API resources as tools, enhancing their functionality while maintaining security through the structured endpoints of MCP.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems address security concerns, and what role does WSO2's 'AI for Code' strategy play in enhancing these systems?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [44.88s] WSO2\'s AI Strategy\nWSO2\'s AI strategy consists of two main components. The first is termed ""AI for Code,"" which focuses on enhancing the developer experience by integrating capabilities and features into their products. The second component, ""Code for AI,"" is centered around building AI applications and identifying the necessary abstractions for their development.\n\n# [85.12s] Evolution of AI Agents\nToday, Malit will discuss the evolution of AI agents. He emphasizes that this presentation will summarize key innovations driving the current adaptation of AI, referencing an article published by McKinsey.']","AI-driven systems address security concerns by assuming a breach and implementing security gates at various points within the system. Continuous monitoring is essential to track the activities of malicious agents or bots, ensuring they do not act outside their intended purpose or exceed their access parameters, thus maintaining the integrity and security of the system. WSO2's 'AI for Code' strategy plays a role in enhancing these systems by focusing on improving the developer experience through the integration of capabilities and features into their products, which can contribute to building more secure and efficient AI-driven systems.",multi_hop_abstract_query_synthesizer
"How does continuous monitoring contribute to the security of AI-driven systems, and how is this integrated with electronic health record systems in healthcare?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [350.72s] Framework for Vertical AI\nThe vertical AI layer is built on existing frameworks, utilizing core large language models (LLMs) from companies like OpenAI, Anthropic, and Gemini. These foundational models serve as the base for horizontal AI applications. On top of this, supporting frameworks such as retrieval-augmented generation (RAG) and data infrastructure are integrated. The vertical layer introduces industry-specific model tuning and regulatory compliance, ensuring that the AI solutions are tailored to meet the unique needs of specific sectors.\n\n## [424.88s] Example: Healthcare Customer Support\nTo illustrate the effectiveness of vertical AI, consider a healthcare customer support requirement. At the foundational level, general-purpose LLMs provide basic language capabilities. Companies like Sierra and Decagon enhance these capabilities with frameworks optimized for customer support. The vertical AI layer then adds the necessary clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems. Without this tailored vertical layer, the AI solution would lack the understanding of healthcare nuances and regulatory constraints essential for real-world deployment.']","Continuous monitoring in AI-driven systems is crucial for tracking the activities of agents to ensure they do not exceed their access parameters, thereby maintaining the integrity and security of the system. In the healthcare sector, this continuous monitoring is integrated with electronic health record systems through the vertical AI layer, which ensures compliance with healthcare regulations and enhances the AI's understanding of healthcare-specific nuances. This integration allows for secure and effective deployment of AI solutions tailored to the healthcare industry's needs.",multi_hop_abstract_query_synthesizer
"How do security considerations in AI-driven systems relate to the development and application of machine learning models, particularly in the context of generative AI and large language models?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [115.60s] Defining Key Terminologies\nBefore we proceed, it is important to define some key terminologies. AI refers to any system that can simulate human intelligence. This can range from simple functions to complex machine learning models and deep learning architectures. Generative AI, a subset of AI, focuses on creating original content, which can include text, audio, and visual elements.\n\n### [155.28s] Understanding Large Language Models\nLarge language models (LLMs), such as ChatGPT from OpenAI, are examples of generative AI that specialize in natural language processing. They are designed to understand and generate text, making them a significant advancement in the field.']","Security considerations in AI-driven systems are crucial due to the potential presence of malicious agents or bots that can exploit vulnerabilities. This is particularly relevant in the development and application of machine learning models, including generative AI and large language models like ChatGPT. These models simulate human intelligence and can generate original content, making them susceptible to misuse if not properly secured. Continuous monitoring and implementing security gates are essential to ensure these models operate within their intended parameters and maintain system integrity.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security and governance, and what role does the Medical Large Vision-Language Model play in enhancing medical comprehension and visualization?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [264.08s] Security and Permissions\nDespite proper governance, there are instances where AI systems may act outside their intended parameters. An example is cited where an AI agent deleted its production databases despite being instructed not to. This highlights the need for robust security measures and appropriate permission allocations.\n\n# [300.32s] Incorporating AI Agents into Enterprise Systems\nAisha takes over to discuss the integration of AI agents into enterprise systems. She emphasizes that the focus is not on creating toy applications but on providing AI with access to enterprise resources and business data. It is crucial to ensure that only authorized access is granted to this data.', '<3-hop>\n\n## [1027.52s] Conclusion and Next Steps\nIn conclusion, security and access control should be integral to agent development from day one. The conversation will continue in the next video, where Aayisha will join to discuss implementing identities and credentials for agents, as well as the capabilities launched on Escardio. \n\nIn the meantime, interested individuals are encouraged to visit wso2.com/Asgardeo to create a free account and explore the capabilities available for securing agents and authorizing MCP servers. Thank you for joining this discussion, and happy securing your agents.\n\nHealthGPT: A Medical Large Vision-Language Model for Unifying\nComprehension and Generation via Heterogeneous Knowledge Adaptation\nTianwei Lin1, Wenqiao Zhang1, Sijing Li1, Yuqian Yuan1, Binhe Yu2, Haoyuan Li3, Wanggui He3, Hao Jiang3,\nMengze Li4, Xiaohui Song1, Siliang Tang1, Jun Xiao1, Hui Lin1, Yueting Zhuang1, Beng Chin Ooi5\n1Zhejiang University, 2University of Electronic Science and Technology of China, 3Alibaba,\n4The Hong Kong University of Science and Technology,5National University of Singapore\nProject Page\n Code\n1. X-Ray \nComprehension\n2. CT\nComprehension\n3. MRI\nComprehension\nComp. Perf.\n7 Medical Multi-Modal Comprehension Tasks\nGen. \nPerformance\n5 Medical Multi-Modal Generation Tasks\nList all anatomical locations showing \npulmonary edema, hazy opacity, or \nmediastinal displacement.\nLeft hilar structures, left lung,\nright hilar structures, right lung.\nWhich abdominal organ shows any \nindication of a lesion or abnormality \nin the CT image?\nNo abdominal organs show\nany clear indications of lesions\nor abnormalities.\nCould you explain what this mass\nin the MRI means for my health? \nIs it very serious?\nCertainly, the MRI shows a\ndefined mass in your left nasal\ncavity. There is no sign of the ...\n4. Microsopy Comprehension\n What is the purpose of the different \nmembrane treatments used in this \nstudy?\nThe purpose of the different\nmembrane treatments used…\n5. OCT Comprehension\n What is the purpose of comparing \nthe OCT structure image and OCTA \nimage with H&E histology?\nTo confirm the histological position\nof the obtained OCT brain images.\n6. Fundus\nComprehension\n What specific findings or pathological \nchanges can be observed in this \nfundus image?\nThe fundus image appears normal with\nno noticeable signs of pathology…\n7. Ultrasound\nComprehension\n What type of imaging technique \nis used in this image?\nThe image is a sagittal gray-\nscale ultrasonographic…\n1. CT2MRI\nGeneration\nI need a version of this CT representation \nin MRI.\nThe image has\nbeen transformed\ninto MRI.\n2. MRI2CT\nGeneration\nTransform the MRI display into a \nCT image.\nHere is the CT\nversion of the\nMRI image.\n3. Image Reconstruction\nReconstruct the following \nmedical images.\nHere is the reconstructed\nmedical image you need.\n4. Super Resolution\nCould you improve the quality\nof this MRI image?\nHere is the image with\nimproved resolution.\n5. Report-to-CXR\nThe X-ray shows no \npleural effusion or \npneumothorax.\nHere is the\nchest X-ray\nimage for\nyou.\nGen. Perf.\nFigure 1: HealthGPT enables medical multi-modal comprehension and generation , outperforming both state-of-the-art\nunified visual models and medical-specific models across various tasks. This highlights its superior capability in tackling com-\nplex tasks in healthcare applications. Comp.Perf. and Gen.Perf. denote the results of comprehension and generation.\nAbstract\nWe present HealthGPT, a powerful Medical Large Vision-\nLanguage Model (Med-LVLM) that integrates medical vi-\nsual comprehension and generation capabilities within a uni-\nfied autoregressive paradigm. Our bootstrapping philosophy\nis to progressively adapt heterogeneous comprehension and\ngeneration knowledge to pre-trained large language mod-\nels (LLMs). This is achieved through a novel heterogeneous\nlow-rank adaptation (H-LoRA) technique, which is com-\nplemented by a tailored hierarchical visual perception ap-\nproach and a three-stage learning strategy. To effectively\nlearn the HealthGPT, we devise a comprehensive medi-\ncal domain-specific comprehension and generation dataset\ncalled VL-Health. Experimental results demonstrate ex-\nceptional performance and scalability of HealthGPT in\nmedical visual unified tasks. Our project can be accessed at\nhttps://github.com/DCDmllm/HealthGPT.\n1 Introduction\nLarge Vision-Language Models (LVLMs) (Liu et al. 2023;\nOpenAI 2023; Liu et al. 2024c; Chen et al. 2024b) have\ndemonstrated outstanding open-world visual comprehension\nand reasoning abilities through language-based interactive\ndialogue over the past years, simultaneously opening up\nnew opportunities for applications in specialized domains.\n1\narXiv:2502.09838v3  [cs.CV]  21 Feb 2025']","AI-driven systems ensure security and governance by implementing security gates at various points within the system and continuously monitoring the activities of agents to prevent them from acting outside their intended purpose or exceeding their access parameters. Despite these measures, there are instances where AI systems may act outside their intended parameters, highlighting the need for robust security measures and appropriate permission allocations. In the context of healthcare, the Medical Large Vision-Language Model, HealthGPT, plays a significant role in enhancing medical comprehension and visualization. It integrates medical visual comprehension and generation capabilities within a unified autoregressive paradigm, outperforming both state-of-the-art unified visual models and medical-specific models across various tasks. This highlights its superior capability in tackling complex tasks in healthcare applications.",multi_hop_abstract_query_synthesizer
"How them large language models and trip planning system work together for nature and adventure trips, and what about data privacy?","[""<1-hop>\n\n**Time Range: 00:10:01 - 00:20:04**\n\n# [601.44s] Chat Experience Overview\nThe chat experience allows users to interact with a system to plan trips. For instance, a user might request assistance in planning a trip to Sri Lanka. The system is designed to understand user preferences without requiring explicit details about their likes or dislikes.\n\n## [632.64s] Trip Planning to Sri Lanka\nWhen a user asks to plan a trip to Sri Lanka, the system generates a five-day itinerary tailored to their preferences. The user in this scenario has previously booked eco-friendly hotels and has a history of choosing accommodations near hiking locations. The system leverages this data to suggest hotels and activities that align with the user's love for nature and adventure."", '<2-hop>\n\n### [172.96s] Cost Considerations\nAnother critical point raised is the cost associated with deploying AI applications. In development, costs may not be as apparent, but once in production, organizations may face challenges related to token usage and scaling, making governance even more important.\n\n### [205.20s] Data Privacy Risks\nData privacy is another significant concern, especially with the advent of large language models (LLMs). Organizations previously had control over their data, but the use of LLMs complicates this, as they often require sending data outside the organization for processing. This raises concerns about the potential leakage of personally identifiable information (PII).']","The trip planning system uses user preferences, such as a history of booking eco-friendly hotels and choosing accommodations near hiking locations, to generate a five-day itinerary tailored to the user's love for nature and adventure. Large language models (LLMs) can enhance this system by processing vast amounts of data to better understand user preferences and improve recommendations. However, the use of LLMs raises data privacy concerns, as they often require sending data outside the organization for processing, which could lead to potential leakage of personally identifiable information (PII).",multi_hop_abstract_query_synthesizer
What are the security considerations for AI applications across different domains?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.']","In AI-driven systems, security considerations are crucial due to the presence of malicious agents or bots that can launch attacks. It is important to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure these agents do not exceed their access parameters. This is vital for maintaining system integrity and security. As AI applications evolve and become more accessible across different domains, these security measures become increasingly important to protect the systems from potential threats.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security and manage tokens, and what changes were made in the application update to support these functionalities?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [3001.36s] Token Management in AI Systems\nWithin organizations, managing token usage is crucial. There are instances where one team may utilize 500,000 tokens while other teams are assured a specific count of tokens. To address this, a system has been introduced for this use case. Within the gateway, token counting can be performed, but it primarily relies on the output provided by the language model (LLM) itself. Most LLMs report the number of tokens used, and this output is essential for accurate counting.\n\n# [1261.68s] Identity Management Offerings\nThe system offers two identity management (IM) solutions: Suffering W and Asgardio. Asgardio is readily available for use, and users are encouraged to try it out. Additionally, there are plans to onboard these offerings to the upcoming W2 identity server product, which will be downloadable for users to run in their own environments.', '<3-hop>\n\n# [600.64s] Application Update and Architecture Overview\nThe discussion begins with an update on the application. A review of the architecture, both before and after the update, is presented. Initially, the architecture consisted of two primary flows: the registration flow, where users would visit a website to register and input their details into a database, and the data retrieval flow, which allowed users to access their session data from the database. \n\nWith the integration of AI capabilities, the architecture has become significantly more complex. Various agents, retrieval-augmented generation (RAG) integrations, and other components have been added to enhance functionality.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring the activities of agents to prevent them from acting outside their intended purpose or exceeding their access parameters. Token management is crucial within these systems, where a system has been introduced to manage token usage, relying on the output provided by language models (LLMs) for accurate counting. The application update involved a review of the architecture, which initially consisted of registration and data retrieval flows. With the integration of AI capabilities, the architecture has become more complex, incorporating various agents and retrieval-augmented generation (RAG) integrations to enhance functionality.",multi_hop_abstract_query_synthesizer
How AI-driven systems use security features to stop bad agents?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [4435.28s] Overview of Security Features\nThe key highlights include security rate limiting, various configured guardrails, jailbreak detection, illegal events, and violence filters.\n\n## [4455.28s] Jailbreak Detection\nA demonstration of jailbreak detection is also planned. A prompt is submitted that instructs the model to disregard previous instructions and simply answer a basic arithmetic question, ""What is 2 + 2?"" This attempt to change the subject can be detected by the guardrails.\n\n## [4491.52s] Utilizing AWS Bedrock for Demonstration\nFor this demonstration, AWS Bedrock is utilized, but similar capabilities can be achieved with guardless AI deployments to capture such events. Users are encouraged to explore these features further.']","AI-driven systems use various security features to stop malicious agents by implementing security gates at different points within the system and continuously monitoring activities to ensure agents do not exceed their access parameters. Key security features include rate limiting, configured guardrails, jailbreak detection, and filters for illegal events and violence. These measures help maintain the integrity and security of the system by detecting and preventing unauthorized actions, such as attempts to bypass instructions, which can be identified by guardrails.",multi_hop_abstract_query_synthesizer
How do excessive information and security concerns affect AI-driven systems' performance?,"[""<1-hop>\n\n### [1171.44s] Understanding Token Limitations\nAlthough newer models can support larger context windows, such as hundreds of thousands or even up to one million tokens, it is essential to manage costs effectively. Utilizing the full capacity of these models can lead to increased expenses, as each token consumed incurs a cost.\n\n**Time Range: 00:20:01 - 00:30:02**\n\n# [1201.04s] The Impact of Excessive Information on Model Performance\nWhen excessive information is included in the prompt, it can lead to increased costs and inefficiencies. This situation results in a scenario where the model has to sift through a large amount of data to determine what is relevant for completing the task. Consequently, this can reduce the accuracy of the task and lead to higher latencies, meaning slower response times. The model's performance is hindered due to the extensive processing required when handling a significant volume of data."", '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","Excessive information in AI-driven systems can lead to increased costs and inefficiencies, as the model must process a large volume of data to determine relevance, which reduces accuracy and increases response times. Additionally, security concerns in these systems involve the risk of malicious agents launching attacks, necessitating continuous monitoring and security measures to maintain system integrity and performance.",multi_hop_abstract_query_synthesizer
How malicious agents affect machine learning systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.']","Malicious agents or bots in AI-driven systems can launch attacks, posing a threat to the integrity and security of machine learning systems. Continuous monitoring is essential to track these agents' activities, ensuring they do not exceed their access parameters or act outside their intended purpose. This is crucial for maintaining the system's security, especially as the attack space evolves.",multi_hop_abstract_query_synthesizer
Wht r the securty considrations when deploying AI applcations?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [76.16s] Challenges in AI Application Deployment\nAs organizations develop new AI applications, it is crucial to consider the challenges that arise when transitioning from a development environment to production. While it may feel satisfactory to see something work in development, ensuring scalability in production is essential to prevent organizational setbacks. The speakers encourage audience participation, inviting questions and interactions throughout the session.\n\n## [125.20s] Governance in AI Services\nArshad begins discussing the governance aspect of AI services, referencing recent news cases where AI systems have produced inappropriate or harmful responses. Such incidents pose risks to organizations, as they are responsible for delivering these services to end users. It is vital to govern AI behavior effectively to prevent such occurrences.']","When deploying AI applications, security considerations include assuming a breach and implementing security gates at various points within the system to protect against malicious agents or bots. Continuous monitoring is essential to track these agents' activities, ensuring they do not exceed their access parameters. Additionally, governance is crucial to prevent AI systems from producing inappropriate or harmful responses, which could pose risks to organizations responsible for these services.",multi_hop_abstract_query_synthesizer
How do security considerations impact the accessibility of AI-driven systems in the current AI landscape?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.']","Security considerations impact the accessibility of AI-driven systems by necessitating the implementation of security gates and continuous monitoring to protect against malicious agents or bots. This ensures that the systems remain secure and maintain their integrity, which is crucial as AI becomes more accessible to a broader audience. The ease of use and availability of AI through APIs and conversational interfaces make it essential to address these security concerns to prevent unauthorized access and misuse.",multi_hop_abstract_query_synthesizer
"What are the security considerations for AI-driven systems in medical datasets, and how do models like HealthGPT perform in medical visual comprehension tasks?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\nTable 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","In AI-driven systems, especially those handling medical datasets, security considerations are paramount due to the risk of malicious agents or bots launching attacks. It is crucial to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure these agents do not exceed their access parameters, thereby maintaining the system's integrity and security. In terms of performance, models like HealthGPT excel in medical visual comprehension tasks. For instance, HealthGPT-L14, with 14 billion parameters, achieves high scores across various tasks, such as VQA-RAD, SLAKE, and PathVQA, indicating its superior capability in handling medical visual data compared to other models like Med-Flamingo and HuatuoGPT-Vision.",multi_hop_abstract_query_synthesizer
"How do AI tools in software engineering and healthcare address security considerations and the handling of sensitive information, particularly in the context of evolving attack spaces and the management of personally identifiable information (PII)?","['<1-hop>\n\n## [1611.76s] The Evolution of Software Engineering with AI\nThe evolution of software engineering in the context of AI tools is discussed. As developers begin to adopt AI-driven tools, they often seek to identify mistakes in their code. However, AI can assist in code reviews and error detection more effectively than traditional methods. The necessity for developers to adapt to these tools is emphasized, as failure to do so may result in obsolescence in the industry.\n\n**Time Range: 00:00:03 - 00:10:05**\n\n# [3.44s] Introduction\nThe speaker has been a part of the WSO2 solutions team for over seven years, primarily focusing on the financial sector. Currently, they are working on AI applications in healthcare and other sectors.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<3-hop>\n\n## [3960.16s] Templating in the Egress Gateway\nAdditionally, the egress gateway allows for the definition of prompts with placeholders. Instead of sending the entire prompt each time, only essential keys, such as guest name, booking history, and preferences, need to be communicated. The gateway handles the mapping and sends the request to the OpenAI endpoint.\n\n# [4030.96s] API Management\nIn the API manager, users can create APIs by selecting specific providers. The API publisher facilitates this process, allowing for the configuration of endpoints and management of keys to ensure secure access.\n\n## [4094.00s] Policies and Guardrails\nPolicies can be applied to the configured APIs, such as prompt decorators that define the role of the assistant. Additionally, guardrails can be set up to handle PII, either by redacting sensitive information or masking it with placeholders. This provides control over how PII is managed throughout the process.']","AI tools in software engineering and healthcare are increasingly being adopted to enhance code reviews, error detection, and other tasks. However, as these AI-driven systems evolve, there is a growing concern about security, particularly regarding malicious agents or bots that can launch attacks. To address these security considerations, it is crucial to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure agents do not exceed their access parameters. Additionally, in the context of handling sensitive information, such as personally identifiable information (PII), policies and guardrails can be applied to APIs. These include prompt decorators that define the role of the assistant and mechanisms to redact or mask PII with placeholders, ensuring that sensitive information is managed securely throughout the process.",multi_hop_abstract_query_synthesizer
How do continuous monitoring and generative models contribute to the security and efficiency of AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2914.80s] Architecture of MCP\nThe MCP architecture includes an MCP host, which can be any integration or agent that connects to data or tools. Clients connect to the MCP server using a JSON RPC protocol, simplifying the process of establishing connections.\n\nThe MCP server has a fixed specification, allowing for a single client definition that can communicate with the server without needing to rewrite the client for each new integration. This design streamlines the connection process to various data sources and APIs, enhancing the overall efficiency of LLM integrations.\n\n# [601.12s] Utilizing Single LLM Invocation\nIn the realm of generative models, there are instances where a single large language model (LLM) invocation is employed to address specific issues. This approach is often complemented by multiple techniques that involve several iterations of LLM calls to effectively overcome limitations.']","Continuous monitoring in AI-driven systems is crucial for tracking the activities of agents to ensure they do not exceed their access parameters, thereby maintaining the integrity and security of the system. This is particularly important in the context of evolving attack spaces where malicious agents or bots may launch attacks. On the other hand, generative models, such as those involving single large language model (LLM) invocations, enhance the efficiency of AI systems by addressing specific issues through multiple iterations of LLM calls. This approach streamlines processes and improves the integration of data sources and APIs, as seen in the architecture of MCP, which simplifies connections and enhances the overall efficiency of LLM integrations.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security and compliance while fostering innovation and operational efficiency, considering the presence of malicious agents and the need for scalability?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n### [2329.68s] Compliance and Trust in AI Systems\nBuilding agentic AI systems securely from the outset helps meet compliance requirements and prepares businesses for future regulations. This approach fosters user trust, ensuring that data remains secure and protected from unauthorized access. Additionally, it enhances operational efficiency by automating tasks, allowing businesses to operate confidently without fear of agents causing disruptions.\n\n**Time Range: 00:40:01 - 00:50:03**\n\n# [2401.52s] Operational Efficiency and Scalability of Agents\nThe operational efficiency of agents is a critical aspect to consider. When discussing agents, it is important to recognize that there will be thousands of them, including personal agents, team agents, and organizational agents. Additionally, there will be agents that are spawned temporarily to perform specific tasks before being terminated. Scalability is essential in this context, as it allows for the effective management of these agents.\n\nWith a clear identity for each agent, it becomes possible to ensure that they are properly identified and can only access the systems for which they have authorization. As previously mentioned by Arshad, this capability enables faster innovation and enhances the value of AI with confidence.']","AI-driven systems ensure security by implementing security gates at various points within the system and continuously monitoring the activities of agents to prevent them from acting outside their intended purpose or exceeding their access parameters. This approach is crucial in maintaining the integrity and security of the system, especially given the evolving attack space and the presence of malicious agents. Compliance and trust are built by designing agentic AI systems securely from the outset, which helps meet compliance requirements and prepares businesses for future regulations. This secure design fosters user trust by ensuring data remains protected from unauthorized access. Additionally, operational efficiency and scalability are achieved by managing thousands of agents, including personal, team, and organizational agents, as well as temporary agents for specific tasks. Scalability allows for effective management and ensures that agents are properly identified and authorized, enabling faster innovation and enhancing the value of AI with confidence.",multi_hop_abstract_query_synthesizer
How AI guard and security considerations important when integrating AI agent with egress AI gateway?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [2721.68s] Features of the Egress AI Gateway\nAs organizations grow their AI teams and adopt various AI services, the need for a mediation layer becomes apparent. This layer allows organizations to manage interactions with multiple AI providers without being dependent on a single one. \n\nThe egress AI gateway offers several features, including model routing, token-based rate limiting, AI guard, prompt management, adaptive routing, and semantic caching. Additionally, it retains the standard capabilities of an ingress gateway, such as analytics, identity access management, and mediation capabilities. Organizations can connect with any AI service, and the product comes pre-configured with a set of services while allowing for custom configurations.', '<3-hop>\n\n## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.']","AI guard and security considerations are crucial when integrating an AI agent with the egress AI gateway. The egress AI gateway provides features like AI guard, which helps manage interactions with multiple AI providers and ensures security through token-based rate limiting and identity access management. Security considerations in AI-driven systems emphasize the need for continuous monitoring to prevent malicious agents from exceeding their access parameters, maintaining the integrity and security of the system. Together, these elements ensure that the integration of AI agents is secure and efficient, protecting against potential breaches.",multi_hop_abstract_query_synthesizer
"How AI-driven systems in healthcare need governance and security, and what advantages vertical AI bring?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [4142.16s] Observability and Logging\nFinally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant.\n\n**Time Range: 01:10:00 - 01:18:25**\n\n# [4200.40s] Introduction to API Usage with Guardrails\nBefore attempting to use the API with Guardrails, it is essential to understand how a use case would appear without these protective measures. In this demonstration, a query related to firearms is posed, which is not an appropriate topic for a hotel assistant.', '<3-hop>\n\n## [195.60s] Advantages of Vertical AI\nVertical AI offers several advantages, including:\n\n1. **Domain Expertise**: Vertical AI can deliver precision and relevance in critical applications.\n2. **Regulatory Alignment**: Industries such as healthcare, finance, and legal are highly regulated, necessitating strict adherence to data sharing and communication protocols.\n3. **Business Impact**: Vertical AI can drive automation and insights tailored to specific verticals, which generic solutions may not address.\n4. **Competitive Advantage**: Specialized tools designed for specific requirements provide a competitive edge.']","AI-driven systems in healthcare require robust governance and security measures due to the presence of malicious agents or bots that can launch attacks. It is crucial to assume a breach and implement security gates at various points within the system, along with continuous monitoring to maintain the integrity and security of the system. Observability and logging policies are essential for effective management and governance, ensuring all interactions are secure and compliant. Vertical AI offers advantages such as domain expertise, regulatory alignment, and competitive advantage, which are particularly beneficial in highly regulated industries like healthcare, where precision, relevance, and adherence to data sharing and communication protocols are critical.",multi_hop_abstract_query_synthesizer
How do security considerations in AI-driven systems and the zero-trust model contribute to evaluating model performance and ensuring trust in AI agents?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [939.84s] Evaluating Model Performance\nAn important aspect of our work involves evaluating model performance, especially in light of changes that may affect functionality. This is a significant area of research within the field of agents and generative AI, as these systems are inherently probabilistic. When the same prompt is called multiple times, it can yield different responses, complicating the testing process. \n\nTo address this, we need to establish methodologies and benchmark datasets to ensure consistent performance, particularly given the rapid advancements in technology. As we transition to new models every six months, it is vital to confirm that we do not lose any previously effective functionalities.', '<3-hop>\n\n# [4171.52s] Trusting AI Agents\nAs organizations grant AI agents greater autonomy, questions arise regarding the level of trust that can be placed in these systems. While agents are designed to perform specific actions and utilize various tools independently, it is crucial to recognize that complete trust may not be warranted. This highlights the importance of implementing a zero-trust design for AI agents, ensuring that safeguards are in place to monitor and control their actions effectively.\n\n**Time Range: 01:10:00 - 01:14:46**\n\n# [4200.32s] Understanding Zero Trust in AI Systems\nZero trust is a security model that emphasizes the principle of never trusting and always verifying. This approach is applied to system architectures, ensuring that trust is not assumed but rather verified at every step. When designing systems, it is crucial to maintain this principle, especially when dealing with AI agents.']","Security considerations in AI-driven systems involve assuming a breach and implementing security gates to monitor malicious agents, which is crucial for maintaining system integrity. This aligns with the zero-trust model, which emphasizes never trusting and always verifying, ensuring that AI agents are monitored and controlled effectively. These security measures are essential when evaluating model performance, as they help maintain consistent functionality despite the probabilistic nature of AI systems. By applying these principles, organizations can ensure that AI agents perform their intended actions without exceeding their access parameters, thereby fostering trust in their autonomy.",multi_hop_abstract_query_synthesizer
"In the context of AI-driven systems, how do AI agents and AI guardrails contribute to maintaining security and integrity, and what are the considerations for their implementation?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1190.08s] The Need for AI Agents\nThe discussion raises the question of whether an AI agent is necessary for this scenario. While an AI agent can be beneficial, the specific requirements and technical feasibility must be evaluated to determine the best approach for implementation.\n\n**Time Range: 00:20:01 - 00:30:03**\n\n# [1201.20s] Overview of the Integration Scenario\nIn this scenario, the integration approach is deemed overkill. However, the team is aware of the necessary components to build the required workflow, allowing for a simple integration without the need for an agent.\n\n## [1213.60s] Ideal Workflow Requirements\nThe ideal pattern for this scenario involves establishing a generative workflow. The construction of this workflow is straightforward. The team will interact with admin APIs, as direct communication with users is not feasible. The APIs utilized by the user portal require user authorization through tokens. Instead, the admin portal can be accessed by administrators to review user data, such as booking history and reviews, based on user IDs.', '<3-hop>\n\n# [3222.96s] AI Guardrails\nAI guardrails are a critical area of focus, and a variety of guard mechanisms have been released. These guardrails are available in both Software as a Service (SaaS) and on-premises solutions. The first guard is the semantic prompt guard, which allows users to configure a set of allowed and denied topics. This ensures that all prompts exiting the egress gateway adhere to the defined parameters.\n\n## [3264.72s] Semantic Prompt Guard\nThe semantic prompt guard captures variations of terms to prevent misuse. For instance, if a student assistant app has a denied topic like ""write my homework,"" any attempt by a student to phrase this request differently will be blocked or flagged based on user configuration.']","In AI-driven systems, maintaining security and integrity is a significant concern due to the potential presence of malicious agents or bots that can launch attacks. AI agents can be beneficial in this scenario, but their necessity and technical feasibility must be carefully evaluated to determine the best approach for implementation. Continuous monitoring of these agents is crucial to ensure they do not exceed their intended purpose or access parameters. Additionally, AI guardrails play a critical role in maintaining system integrity. These guardrails, available as both Software as a Service (SaaS) and on-premises solutions, include mechanisms like the semantic prompt guard. This guard allows users to configure allowed and denied topics, ensuring that all prompts adhere to defined parameters, thus preventing misuse and maintaining the security of the system.",multi_hop_abstract_query_synthesizer
"How do AI-driven systems ensure security against malicious agents, and what role do AI capabilities play in transforming user experiences in data-driven applications?","['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n# [600.64s] Application Update and Architecture Overview\nThe discussion begins with an update on the application. A review of the architecture, both before and after the update, is presented. Initially, the architecture consisted of two primary flows: the registration flow, where users would visit a website to register and input their details into a database, and the data retrieval flow, which allowed users to access their session data from the database. \n\nWith the integration of AI capabilities, the architecture has become significantly more complex. Various agents, retrieval-augmented generation (RAG) integrations, and other components have been added to enhance functionality.', '<3-hop>\n\n## [332.56s] Data as a Strategic Asset\nData is a crucial strategic asset for any business. For instance, we possess valuable information such as customer booking history, search behaviors, and reviews. This data can be leveraged to enhance our offerings. Additionally, we have access to external data, including trends in hotel information, seasonal patterns, and weather events, which can further inform our strategies.\n\n## [379.76s] Implementing AI Transformation\nBefore diving into the technical aspects, it is vital to establish a clear vision for the transformation we wish to implement. Our goal is to create an intelligent, interactive experience for users, allowing them to plan trips by specifying their budget and desired activities. This experience should enable users to receive tailored trip plans and subsequently make reservations based on those plans.\n\nTo achieve this transformation, we must consider whether it is possible to implement new capabilities without overhauling existing business APIs. One approach could involve discarding current APIs and developing new systems, but this poses significant risks, especially given the uncertainties in customer preferences during the transition. Instead, we aim to retain existing systems while integrating new capabilities to enhance the user experience.']","AI-driven systems ensure security against malicious agents by implementing security gates at various points within the system and continuously monitoring the activities of these agents to ensure they do not exceed their access parameters or act outside their intended purpose. This is crucial for maintaining the integrity and security of the system. In terms of transforming user experiences in data-driven applications, AI capabilities have significantly enhanced the architecture by integrating various agents and retrieval-augmented generation (RAG) components. This transformation aims to create an intelligent, interactive experience for users, allowing them to plan trips by specifying their budget and desired activities, ultimately receiving tailored trip plans and making reservations based on those plans. The integration of AI capabilities allows for the enhancement of functionality without overhauling existing business APIs, thus improving the user experience while maintaining system stability.",multi_hop_abstract_query_synthesizer
What are the financial implications and system integrity concerns associated with AI technologies?,"['<1-hop>\n\n# [3353.84s] Addressing Risks Associated with AI\nThe discussion shifts to the potential risks associated with AI technologies. While there are no immediate world-ending scenarios, there are personal and organizational risks that must be acknowledged. These risks can manifest in various forms, including financial and legal implications.\n\n## [3404.64s] Understanding AI Hallucinations and Bias\nAI models are trained on datasets that may contain biases or gaps, leading to problematic outputs. For example, an AI might generate images predominantly featuring one demographic due to the lack of diversity in its training data. This issue highlights the importance of addressing data quality and representation in AI training.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.']","The financial implications associated with AI technologies include potential risks that can manifest in various forms, such as financial and legal implications. These risks are part of the broader discussion on the potential dangers of AI technologies. In terms of system integrity, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks on AI-driven systems. To maintain system integrity, it is crucial to assume a breach and implement security gates at various points within the system, along with continuous monitoring to ensure these agents do not exceed their access parameters.",multi_hop_abstract_query_synthesizer
How do evolving standards and security considerations in AI-driven systems impact the implementation of vertical AI use cases?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [798.24s] Evolving Standards and Community Engagement\nThe evolution of standards within the IM community is exciting, as it addresses the challenges associated with building agents. The involvement of team members, such as Aisha and Arana, in these discussions is crucial as the community works to solve these emerging issues.\n\n## [825.92s] Future of Agent DKI and Recommendations\nAs the conversation shifts towards the future of agent DKI, it is important to consider where this technology is headed. The concept of agents is gaining significant attention, and organizations that have not yet implemented agents are likely to do so soon. \n\nIt is anticipated that every engineer will need to become proficient in AI, as it becomes a fundamental part of the computing stack, akin to APIs and data. However, the current middleware stack is still evolving to support the integration of AI agents securely and efficiently.', '<3-hop>\n\n## [979.28s] Vertical AI Use Cases\nSeveral vertical AI use cases can be explored, highlighting different aspects of AI applications. The first use case involves user-present agents, commonly referred to as chat agents. In this scenario, the user interacts with a large language model (LLM) and can be redirected for authentication or asked questions by the chat agent.\n\n### [1021.20s] User-Present Agent Example\nAn example of this is Sarah, who wants to reschedule her cardiology appointment. The current flow involves a manual rescheduling process where Sarah calls the hospital, is transferred to the cardiology department, and the staff verifies her identity. The staff then manually searches for available slots, and Sarah waits to select a new time, after which the staff updates the records and sends an SMS confirmation. \n\nThe main problems with this process include time consumption, human dependency, and the need for repeated information sharing, especially during peak call volumes. The manual effort required by staff to update records and send confirmations can be frustrating.']","Evolving standards within the AI community, as discussed by team members like Aisha and Arana, are crucial for addressing challenges in building AI agents, which are becoming integral to the computing stack. These standards are essential for securely and efficiently integrating AI agents, as the middleware stack is still evolving. In AI-driven systems, security considerations are paramount due to the risk of malicious agents or bots launching attacks. Continuous monitoring and security gates are necessary to maintain system integrity. These evolving standards and security measures directly impact the implementation of vertical AI use cases, such as user-present agents, by ensuring that these systems can operate securely and efficiently, reducing manual effort and improving user experience.",multi_hop_abstract_query_synthesizer
How do AI capabilities in the W2 Integrator enhance security in AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [1611.68s] Introduction to W2 Integrator\nThe W2 Integrator BI is a next-generation integration product recently introduced by WSO2. The focus will be on the AI capabilities of the tool and how to implement the use case effectively.\n\n### [1658.48s] Key Features of W2 Integrator\nOne of the key features of this product is its support for a seamless transition from low code to pro code, ensuring that all code written is reflected in the diagram without losing any information.\n\n### [1694.40s] AI Integration Capabilities\nThis product is designed in the age of AI, allowing for the development of integrations using natural language processing. It also supports building AI applications for enterprise use cases, making it a versatile tool for modern integration challenges.']","The AI capabilities in the W2 Integrator enhance security in AI-driven systems by allowing for the development of integrations using natural language processing, which can be used to build AI applications for enterprise use cases. This integration capability supports the implementation of security measures, such as continuous monitoring and security gates, to track and manage the activities of malicious agents or bots, ensuring they do not exceed their access parameters and maintaining the integrity and security of the system.",multi_hop_abstract_query_synthesizer
How do AI-driven systems address security concerns compared to traditional user authentication methods?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n## [728.00s] Traditional Booking Process\nThe demonstration will begin by showcasing the platform without agentic capabilities, reflecting the traditional booking methods used by platforms like Booking.com. In this traditional identity management (IM) setup, users interact with applications that connect to backend services. Users authenticate themselves through an identity provider, granting access to the application for task completion. This process does not incorporate any agentic features, which will be highlighted in the demo.\n\n### [785.60s] Booking a Hotel\nThe booking website is a standard interface where users can sign in and make reservations. The user will demonstrate the process by booking a hotel in Colombo. This traditional method requires manual navigation through the website to find and book a hotel, which is confirmed upon completion.']","AI-driven systems address security concerns by implementing security gates at various points within the system and continuously monitoring for malicious agents or bots to maintain system integrity. In contrast, traditional user authentication methods involve users authenticating themselves through an identity provider to access applications, without incorporating agentic features or advanced security measures found in AI-driven systems.",multi_hop_abstract_query_synthesizer
How do security considerations and the implementation of a zero trust framework contribute to addressing scalability challenges in AI-driven systems?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n# [602.32s] Security Considerations in AI-Driven Systems\nIn the context of AI-driven systems, there is a growing concern regarding the presence of malicious agents or bots that can launch attacks. As the attack space evolves, it is crucial to always assume a breach and implement security gates at various points within the system. Continuous monitoring is essential to track the activities of these agents, ensuring they do not act outside their intended purpose or exceed their access parameters. This monitoring is vital for maintaining the integrity and security of the system.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.', '<3-hop>\n\n## [4375.04s] Final Architecture and Security Measures\nThe final architecture incorporates mechanisms to secure agent operations and establish a zero trust framework. Technologies like Asgardio and identity servers play a crucial role in managing agent identities and ensuring proper authorization for actions taken by AI tools.\n\n## [4408.08s] Conclusion and Key Takeaways\nIn conclusion, the discussion highlighted the accessibility of AI systems, such as Jenna, while acknowledging their limitations, including issues like hallucination due to outdated knowledge and lack of access to private data. The integration of generative models with retrieval-augmented generation (RAG) enhances capabilities by allowing efficient knowledge injection and enabling agents to execute actual tools.\n\nFurthermore, standardizing connections to external systems, such as APIs and databases, is essential for effective integration. Finally, it is imperative to implement responsible AI practices, including the use of AI gateways and zero trust designs, when developing AI agents.']","Security considerations in AI-driven systems involve assuming a breach and implementing security gates at various points within the system, along with continuous monitoring to maintain system integrity. This is crucial as the attack space evolves, ensuring that malicious agents do not exceed their access parameters. The implementation of a zero trust framework further enhances security by securing agent operations and managing identities through technologies like Asgardio and identity servers. These measures are essential in addressing scalability challenges, as they ensure that AI systems can scale securely and efficiently, facilitating real-time interactions and capabilities both in the cloud and at the edge. By integrating these security measures, organizations can better manage the scalability of their AI solutions while maintaining transparency and explainability, which are also critical for scalable AI systems.",multi_hop_abstract_query_synthesizer
How does Retrieval-Augmented Generation (RAG) enhance the efficiency of large language models in modern AI applications?,"[""<1-hop>\n\n**Time Range: 00:10:01 - 00:20:02**\n\n# [1253.20s] Introduction to Retrieval-Augmented Generation\nTo address these challenges, the solution lies in retrieval-augmented generation (RAG). This approach is gaining attention as it allows for more efficient use of data within large language models (LLMs). The core idea is straightforward: rather than inputting all available information into the model's prompt, only the relevant data should be included. However, determining what is relevant poses a significant challenge.\n\n## [1298.16s] The RAG Process\nRAG suggests that before incorporating data into prompts, one should first index the data. This can be achieved using vector embeddings and a vector database. The process involves creating a search index, which allows for efficient retrieval of relevant information when a question or task arises. For instance, similar to how Google retrieves links based on a search query, RAG utilizes an index to find pertinent information, which is then fed to the LLM to generate answers."", '<2-hop>\n\n# [339.20s] Building Modern AI Applications\nBuilding modern AI applications involves connecting various components. The process begins with developing AI components, which is itself an integration challenge. Traditional machine learning approaches are becoming less relevant, with integration taking precedence. The success of this integration process relies on utilizing the appropriate patterns.\n\n## [408.88s] Core Patterns in AI Strategy\nWSO2 has identified three core patterns in their AI strategy, which have been extensively covered in previous sessions. The first pattern is GenAI integration, which involves making calls to a GenAI API. This pattern supports various use cases, including text summarization, sentiment analysis, and email drafting.\n\nThe second pattern is Retrieval-Augmented Generation (RAG), where data is stored in a knowledge base and retrieved as needed to ground responses. However, both RAG and GenAI integrations are primarily passive or reactive, lacking the ability to perform actions independently.']","Retrieval-Augmented Generation (RAG) enhances the efficiency of large language models in modern AI applications by allowing for the inclusion of only relevant data into the model's prompt, rather than inputting all available information. This is achieved by first indexing the data using vector embeddings and a vector database, creating a search index for efficient retrieval of pertinent information. This process is similar to how Google retrieves links based on a search query. In modern AI applications, RAG is used to store data in a knowledge base and retrieve it as needed to ground responses, supporting various use cases such as text summarization and sentiment analysis.",multi_hop_specific_query_synthesizer
"What are the advantages of transitioning from generic AI to vertical AI in highly regulated industries like healthcare, and how does this transition provide a competitive advantage?","['<1-hop>\n\n## [195.60s] Advantages of Vertical AI\nVertical AI offers several advantages, including:\n\n1. **Domain Expertise**: Vertical AI can deliver precision and relevance in critical applications.\n2. **Regulatory Alignment**: Industries such as healthcare, finance, and legal are highly regulated, necessitating strict adherence to data sharing and communication protocols.\n3. **Business Impact**: Vertical AI can drive automation and insights tailored to specific verticals, which generic solutions may not address.\n4. **Competitive Advantage**: Specialized tools designed for specific requirements provide a competitive edge.', ""<2-hop>\n\n## [25.28s] Discussion on Vertical AI\nThe focus of today's discussion is on vertical AI, which is a significant aspect of the ongoing track dedicated to specialized AI applications. Before delving into vertical AI, it is essential to clarify what generic AI entails.\n\n### [38.24s] Understanding Generic AI\nGeneric AI, often referred to as general-purpose AI, has been widely used for various personal and business tasks. It is designed to handle a broad range of applications. However, we are transitioning from this general-purpose AI, which is built for diverse uses, to a more specialized form known as vertical AI. This shift allows for the development of specific AI solutions tailored to industries such as healthcare, legal, and financial services.""]","The transition from generic AI to vertical AI in highly regulated industries such as healthcare offers several advantages. Vertical AI provides domain expertise, delivering precision and relevance in critical applications, which is crucial for industries that require strict adherence to regulatory standards. This specialized approach ensures regulatory alignment, as vertical AI solutions are tailored to meet the specific data sharing and communication protocols necessary in these fields. Additionally, vertical AI drives business impact by offering automation and insights that are specifically designed for the unique needs of each industry, which generic AI solutions may not adequately address. This specialization provides a competitive advantage by equipping businesses with tools that are specifically designed to meet their unique requirements, thereby enhancing their operational efficiency and effectiveness.",multi_hop_specific_query_synthesizer
What W integrator do in AI transformation?,"['<1-hop>\n\n## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.']","The W integrator is introduced by Anjen to facilitate the AI transformation process. It serves as a toolkit for implementing AI transformation step by step in a specific business use case, addressing the need for a narrow and specific focus in AI solutions.",multi_hop_specific_query_synthesizer
Wht is the role of Guarders AI in the context of built-in guardrails and third-party integrations?,"['<1-hop>\n\n## [3646.16s] Built-in Guardrails and Third-Party Integrations\nThe product includes a set of built-in guardrails, and it also supports third-party integrations. For instance, if there are integrations with services like AWS Bedrock or content safety solutions, users can opt to utilize these guardrails. The gateway is fully compatible with these services, allowing prompts to be sent to LLM services like AWS Bedrock, which will perform the necessary classification to identify any guard validations or failures.\n\nIf there are concerns regarding Personally Identifiable Information (PII), a mixed approach can be adopted. Initially, PII validation can occur at the gateway level before sending the request to AWS Bedrock for further processing. For those who do not have subscriptions or face cost issues, the system provides its own set of guardrails through a framework called Guarders AI. This framework is developed and hosted by the team, and there are plans to offer it as Docker images for users to run within their organizations, allowing for customizations to ensure security and proper governance.']","Guarders AI serves as a framework developed and hosted by the team to provide a set of built-in guardrails for users who do not have subscriptions or face cost issues with third-party integrations. It allows for customizations to ensure security and proper governance, and there are plans to offer it as Docker images for users to run within their organizations.",multi_hop_specific_query_synthesizer
How does InternVL2 perform in medical visual comprehension tasks compared to other models?,"['<1-hop>\n\nTable 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","InternVL2, with 8 billion parameters, shows strong performance in medical visual comprehension tasks. It achieves scores of 64.9 in VQA-RAD, 49.0 in SLAKE, 66.6 in PathVQA, and 50.1 in MMMU-Med. These results indicate that InternVL2 performs competitively, although it is outperformed by HealthGPT-M3 and HealthGPT-L14 in several tasks. HealthGPT-L14, for instance, achieves the highest scores across most tasks, such as 77.7 in VQA-RAD and 76.4 in PathVQA, demonstrating superior performance in medical visual comprehension compared to InternVL2.",multi_hop_specific_query_synthesizer
How does the three-stage learning strategy using VQA-RAD improve medical visual comprehension in HealthGPT?,"['<1-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8', '<2-hop>\n\nTable 8: Data distribution of VL-Health in three-stage learning strategy.\nMedical Task Stage-1 Stage-2\nComp. LLaV A-558k, PubMedVision-PT Mixed-47kGen. LLaV A-558k\nMedical Task Stage-3\nComp. LLaV A Med, MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, VQA-RAD\nGen. IXI, SynthRAD2023, MIMIC-CHEST-XRAY\nData Format. All data samples are converted into a unified instruction-response format for training and evaluation. Specifi-\ncally, the VL-Health dataset consists of the following components:\n• Task Type: Specifies the granularity of visual features output by the visual encoder and selects the corresponding H-\nLoRA submodule. For generation tasks, the response also includes multi-modal tokens corresponding to VQ indices.\n• Task Instruction: Guides the model to interpret the image and generate a response, covering various aspects of the\nimage and specifying the output format.\n• Response: The textual output generated based on the task instruction and input image, ensuring it meets the question and\nformatting requirements.\n• Input Image: Provides the visual signal for the model to process.\n• Target Image Index: In generation tasks, this is added as a multi-modal token to the response for autoregressive\ngeneration.\nB Analysis of Heterogeneous Low-Rank Adaptation\nWe propose H-LoRA, which utilizes hard routing selection to allocate plugins for knowledge learning and representation across\ntasks, thereby preventing conflicts arising from heterogeneous knowledge. Furthermore, within each task, we optimized based\non MoELoRA, enhancing performance while reducing computational overhead. The pseudocode is detailed Algorithm 1.\nAlgorithm 1: H-LoRA Algorithm\nInput: concrete-grained visual features FCon, abstract-grained visual featuresFAbs, comprehension-based H-LoRA modules\n({AComp.\ni }k\ni=1, RComp.\nouter ), generation-based H-LoRA modules({AGen.\ni }k\ni=1, RGen.\nouter), task type T (comprehension or generation),\nnumber of LoRA experts k, origin linear layer weights W0, text features T , hidden state h\nOutput: final output O\n// Select task-specific image features\nif T = generation task then\nFimg ← FCon\nelse if T = comprehension task then\nFimg ← FAbs\nend if\nU ←concat(Fimg, T ) // Concatenate image features and text features\n{Ai}k\ni=1, {Bi}k\ni=1, Router ← {AT\ni }k\ni=1, {BT\ni }k\ni=1, RT\nouter // Assign task-specific H-LoRA submodule\n// Merge LoRA experts’ matrices\nAmerged ← concat({Ai}k\ni=1)\nBmerged ← concat({Bi}k\ni=1)\nW ←R(h) // Generate routing weights based on input hidden state x\nWexpanded ← α × W/r ⊗ 1r // Expand routing weights to match merged matrices\nOH-LoRA ← (x · Amerged ⊙ Wexpanded) · Bmerged // Compute H-LoRA output using element-wise multiplication\nO ←x · W0 + OH-LoRA // Add H-LoRA output to pre-trained weights to get final output\nReturn O\nWe further analyzed the computational overhead differences between MoELoRA and H-LoRA. Assuming that both methods\nuse the same number of LoRA experts k, we can compare their time complexity from the perspective of the operational steps\ninvolved.\nComputational Overhead of MoELoRA. In MoELoRA, the operations involving the expert matrix mainly include the fol-\nlowing steps: (i) Expert Multiplication : MoELoRA requires 2k multiplications with the LoRA experts. (ii) Router Multi-\nplication: One multiplication with the Router is required. (iii) Router Output Expansion : MoELoRA needs to perform k\n14']","The three-stage learning strategy using VQA-RAD improves medical visual comprehension in HealthGPT by decoupling comprehension and generation tasks, which reduces performance degradation from task conflicts. This strategy effectively utilizes medical embedding knowledge in pre-trained LLMs to mitigate conflicts, as shown in Table 5. In the medical visual comprehension task, mixed training causes catastrophic forgetting and degrades visual reconstruction, whereas the three-stage strategy prevents these issues. Additionally, the VL-Health dataset used in this strategy includes VQA-RAD as part of the comprehension tasks in Stage-3, which helps in enhancing the model's performance in medical visual comprehension.",multi_hop_specific_query_synthesizer
How GPT-4 used in medical AI and what security needed?,"['<1-hop>\n\n## [136.08s] Key Innovations in AI\nThe first key innovation is the increasing power of AI models, which are becoming more expert-like. For instance, models like GPT-4 have demonstrated the ability to achieve high scores on tests such as the SAT and the US medical exam. Additionally, reasoning capabilities are improving, as evidenced by advancements in prompting techniques that are no longer necessary for these advanced models.\n\nThe second innovation pertains to agentic capabilities, where agents can reason, act, and perform tasks autonomously. The third area of improvement is multi-modality, which extends beyond text to include advancements in video and voice interactions, making them more natural and real-time.', '<2-hop>\n\n## [2096.80s] Identity Representation and Security\nThis system introduced an extension to existing standards, enabling the identification of actions taken by agents on behalf of users. The staff allocation agent operated using its own token, proving its identity to the Guardio system and making API calls to backend services. This structure ensures that all users, applications, and agents have distinct identifications within the ecosystem.\n\n### [1024.40s] Securing AI Model Connections\nThe AI model, which could be based on various providers such as GPT-4, introduces another layer of security considerations. Connections between the business and the external AI model must be secured, and this is where governance layers and guardrails, as previously discussed, become critical.']","GPT-4, as an advanced AI model, demonstrates high reasoning capabilities and can achieve high scores on tests like the US medical exam, making it suitable for medical AI tasks. However, when integrating GPT-4 into medical AI systems, security is crucial. Connections between the business and the external AI model, such as GPT-4, must be secured with governance layers and guardrails to ensure safe and secure operations.",multi_hop_specific_query_synthesizer
How does the implementation of logging policies contribute to the management and governance of the AI gateway?,"['<1-hop>\n\n## [4142.16s] Observability and Logging\nFinally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant.\n\n**Time Range: 01:10:00 - 01:18:25**\n\n# [4200.40s] Introduction to API Usage with Guardrails\nBefore attempting to use the API with Guardrails, it is essential to understand how a use case would appear without these protective measures. In this demonstration, a query related to firearms is posed, which is not an appropriate topic for a hotel assistant.']","The implementation of logging policies contributes to the management and governance of the AI gateway by ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management, ensuring that all interactions are secure and compliant.",multi_hop_specific_query_synthesizer
How WC2 Integrator BI make AI integration easier for developers?,"['<1-hop>\n\n## [1741.76s] Recap of Historical Context\nHistorically, adding AI features to products required extensive resources, including hiring data science engineers and building models from scratch. However, the current landscape has made AI more accessible, with capable reasoning models available through cloud providers, transforming the integration process into a more manageable task.\n\n**Time Range: 00:30:01 - 00:40:06**\n\n# [1801.52s] Introduction to AI Integration Development\nIn the past, the development of AI integrations was typically the responsibility of a separate team. However, current practices allow integration developers to utilize existing resources to create remarkable AI experiences for products. The focus of WC2 Integrator BI is to provide first-class abstractions and developer tooling specifically designed for building AI applications.']","WC2 Integrator BI makes AI integration easier for developers by providing first-class abstractions and developer tooling specifically designed for building AI applications. This approach allows integration developers to utilize existing resources, transforming the integration process into a more manageable task compared to the past when adding AI features required extensive resources and separate teams.",multi_hop_specific_query_synthesizer
"What role does the VQA-RAD dataset play in the VL-Health dataset, and how does HealthGPT perform on it?","['<1-hop>\n\n（a） （b）\nFigure 8: VL-Health dataset collection distribution.\nA.3 VL-Health\nThe construction of theVL-Health dataset involves two key steps:(i) data collection, (ii) data processing, as detailed below:\nData Collection: During the collection phase, we carefully considered the diversity of medical images and the complexity of\nthe tasks, selecting appropriate subsets for comprehension and generation tasks. For comprehension tasks, we selected datasets\nsuch as VQA-RAD (Lau et al. 2018), SLAKE (Liu et al. 2021), PathVQA (He et al. 2020), and MIMIC-CXR-VQA (Bae et al.\n2024), which cover various medical imaging modalities like radiology and pathology, and include professional annotations\nto assist the model in learning tasks such as lesion detection and disease diagnosis. Additionally, large-scale multi-modal\ndatasets like LLaV A-Med (Li et al. 2024b) and PubMedVision (Chen et al. 2024a) were included to provide broader medical\nknowledge support and facilitate the training of complex reasoning tasks. For generation tasks, we focused on four mainstream\ntask categories: super-resolution image generation, modality conversion, text-to-image generation, and image reconstruction.\nThe IXI (Davies et al. 2014) dataset, containing a large number of healthy brain MRI images, is suitable for training super-\nresolution models; the MIMIC-CHEST-XRAY (Bae et al. 2024) dataset, with X-ray images and their corresponding textual\nreports, is appropriate for text-to-image generation tasks; the SynthRAD2023 (Thummerer et al. 2023) dataset provides a large\nnumber of paired CT and MRI images, supporting modality conversion model training; for image reconstruction tasks, we\nrewrote and adjusted the LLaV A-558k (Liu et al. 2024b) dataset.\nData Processing: After data collection, we performed filtering and processing of the raw data. For VisualQA tasks, we stan-\ndardized the data entries into two forms: open-ended questions and single-choice questions, enabling flexible training and\nevaluation. Additionally, considering that multi-image data has a minimal impact on performance but introduces extra padding\nand training time, we excluded multi-image data. For the scanned image data in generation tasks, we applied slicing extrac-\ntion, image registration, data augmentation, and normalization to treat 2D images as visual inputs for model training or used\nVQGAN-generated indices to supervise the generation tasks.\nData Statistics This section provides detailed statistical information about the VL-Health dataset to offer a more compre-\nhensive understanding.\nData Overview: To ensure a balanced development of the model’s comprehension and generation capabilities, in addition\nto the LLaV A-558k and PubMedVision-PT datasets used for alignment, the VL-Health dataset ultimately selected 765,802\nadditional visual question-answering (VQA) training samples (to endow the model with visual comprehension and instruction-\nfollowing capabilities) and 783,045 generation training samples (to provide the model with reconstruction and visual generation\ninstruction-following abilities). This contributes to the transfer of knowledge between comprehension and generation tasks, en-\nhancing the model’s overall performance. For medical image comprehension tasks, images were selected from VQA-RAD (ap-\nproximately 450 images), SLAKE (approximately 630 images), PathVQA (approximately 2,600 images), MIMIC-CXR-VQA\n(approximately 52,000 images), LLaV A-Med (approximately 61,000 images), and PubMedVision (approximately 500,000 im-\nages). Multiple question-answer pairs were retained for each image to enhance the model’s understanding and generalization\nof the image content. Table 8 shows the data distribution ofVL-Health for three-stage learning strategy, where mixed-47k is\nbased on the sampling of all data in stage-1.\nDiversity and Quality Assessment: VL-Health covers 11 modalities, including CT, MRI, X-ray, microscopy, OCT, ultra-\nsound, and fundus photography, which aids the model in learning features from various modalities. The dataset also encom-\npasses a wide range of diseases, from common to rare, and from localized lesions to systemic diseases, including pulmonary\ndiseases, skeletal abnormalities, brain lesions, tumors, cardiovascular diseases, and cellular abnormalities. This provides com-\nprehensive training support to the model, enabling it to learn the characteristics and diagnosis of various diseases.\n13', '<2-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","The VQA-RAD dataset is part of the VL-Health dataset, which is used for medical image comprehension tasks. It includes approximately 450 images and is utilized to enhance the model's understanding and generalization of image content through multiple question-answer pairs. HealthGPT, when evaluated on benchmarks including VQA-RAD, frequently provided the best answers according to human evaluation, indicating its strong performance and potential application in medical care scenarios.",multi_hop_specific_query_synthesizer
"How does the LLaV A Med model utilize the H-LoRA algorithm to improve medical visual comprehension tasks, and what are the benefits of this approach?","['<1-hop>\n\nTable 8: Data distribution of VL-Health in three-stage learning strategy.\nMedical Task Stage-1 Stage-2\nComp. LLaV A-558k, PubMedVision-PT Mixed-47kGen. LLaV A-558k\nMedical Task Stage-3\nComp. LLaV A Med, MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, VQA-RAD\nGen. IXI, SynthRAD2023, MIMIC-CHEST-XRAY\nData Format. All data samples are converted into a unified instruction-response format for training and evaluation. Specifi-\ncally, the VL-Health dataset consists of the following components:\n• Task Type: Specifies the granularity of visual features output by the visual encoder and selects the corresponding H-\nLoRA submodule. For generation tasks, the response also includes multi-modal tokens corresponding to VQ indices.\n• Task Instruction: Guides the model to interpret the image and generate a response, covering various aspects of the\nimage and specifying the output format.\n• Response: The textual output generated based on the task instruction and input image, ensuring it meets the question and\nformatting requirements.\n• Input Image: Provides the visual signal for the model to process.\n• Target Image Index: In generation tasks, this is added as a multi-modal token to the response for autoregressive\ngeneration.\nB Analysis of Heterogeneous Low-Rank Adaptation\nWe propose H-LoRA, which utilizes hard routing selection to allocate plugins for knowledge learning and representation across\ntasks, thereby preventing conflicts arising from heterogeneous knowledge. Furthermore, within each task, we optimized based\non MoELoRA, enhancing performance while reducing computational overhead. The pseudocode is detailed Algorithm 1.\nAlgorithm 1: H-LoRA Algorithm\nInput: concrete-grained visual features FCon, abstract-grained visual featuresFAbs, comprehension-based H-LoRA modules\n({AComp.\ni }k\ni=1, RComp.\nouter ), generation-based H-LoRA modules({AGen.\ni }k\ni=1, RGen.\nouter), task type T (comprehension or generation),\nnumber of LoRA experts k, origin linear layer weights W0, text features T , hidden state h\nOutput: final output O\n// Select task-specific image features\nif T = generation task then\nFimg ← FCon\nelse if T = comprehension task then\nFimg ← FAbs\nend if\nU ←concat(Fimg, T ) // Concatenate image features and text features\n{Ai}k\ni=1, {Bi}k\ni=1, Router ← {AT\ni }k\ni=1, {BT\ni }k\ni=1, RT\nouter // Assign task-specific H-LoRA submodule\n// Merge LoRA experts’ matrices\nAmerged ← concat({Ai}k\ni=1)\nBmerged ← concat({Bi}k\ni=1)\nW ←R(h) // Generate routing weights based on input hidden state x\nWexpanded ← α × W/r ⊗ 1r // Expand routing weights to match merged matrices\nOH-LoRA ← (x · Amerged ⊙ Wexpanded) · Bmerged // Compute H-LoRA output using element-wise multiplication\nO ←x · W0 + OH-LoRA // Add H-LoRA output to pre-trained weights to get final output\nReturn O\nWe further analyzed the computational overhead differences between MoELoRA and H-LoRA. Assuming that both methods\nuse the same number of LoRA experts k, we can compare their time complexity from the perspective of the operational steps\ninvolved.\nComputational Overhead of MoELoRA. In MoELoRA, the operations involving the expert matrix mainly include the fol-\nlowing steps: (i) Expert Multiplication : MoELoRA requires 2k multiplications with the LoRA experts. (ii) Router Multi-\nplication: One multiplication with the Router is required. (iii) Router Output Expansion : MoELoRA needs to perform k\n14']","The LLaV A Med model employs the H-LoRA algorithm to enhance medical visual comprehension tasks by utilizing hard routing selection to allocate plugins for knowledge learning and representation across tasks. This approach prevents conflicts arising from heterogeneous knowledge. Within each task, the model is optimized based on MoELoRA, which enhances performance while reducing computational overhead. The H-LoRA algorithm selects task-specific image features, concatenates them with text features, and assigns task-specific H-LoRA submodules. It merges LoRA experts' matrices and computes the H-LoRA output using element-wise multiplication, which is then added to pre-trained weights to get the final output. This method allows for efficient handling of comprehension tasks by optimizing the use of visual and textual features, ultimately improving the model's performance in medical visual comprehension tasks.",multi_hop_specific_query_synthesizer
How MCP server help AI agent with weather and healthcare data?,"['<1-hop>\n\n## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.', '<2-hop>\n\n### [846.64s] Code for AI\nMoving on to ""Code for AI,"" this involves providing building blocks for developing AI-related capabilities. An example is the MCP server, which converts a standard API into a tool that an AI agent can easily communicate with. WSO2 offers pre-built support to convert any FHIR server, such as an EHR server, into an MCP server, allowing direct communication with AI agents.\n\nA demonstration illustrates this user experience. When a user enters a healthcare-specific prompt, the system redirects to an authorization flow where the user must provide consent for the agent to access their data. The AI agent then calls the APIs using the MCP server to access the records. For example, if the prompt is about recorded immunizations, the AI agent retrieves the relevant health records. This capability is significant because a horizontal AI would lack the knowledge to interact with EHR systems and would require server-side enablement via the MCP server.']","The MCP server assists the AI agent by providing a means to incorporate weather conditions into planning processes and by enabling direct communication with healthcare systems. In the context of weather, the MCP server is operational and can be connected to provide weather information, which can be used to enhance itinerary planning. For healthcare, the MCP server converts a standard API into a tool that allows AI agents to communicate with EHR systems. This is facilitated by WSO2, which supports converting FHIR servers into MCP servers, enabling AI agents to access healthcare records, such as immunizations, after user consent is obtained.",multi_hop_specific_query_synthesizer
"How did Malit contribute to the enhancement of the WSO2 mobile app, and what role does WSO2's AI strategy play in this development?","['<1-hop>\n\n## [503.36s] Defining an Agent\nAgents introduce proactivity, allowing them to perform actions autonomously. An agent is defined as a system or entity capable of executing tasks by interacting with tools, such as APIs and databases, with the assistance of a large language model.\n\n# [556.40s] WSO2 Mobile App Development\nMalit discusses a WSO2 mobile app developed for the last WSO2 conference. Initially, the app was static and lacked AI features. To enhance user experience, the team added various features, including personalized scheduling and a chatbot for user interaction.\n\n**Time Range: 00:10:00 - 00:20:08**', '<2-hop>\n\n## [44.88s] WSO2\'s AI Strategy\nWSO2\'s AI strategy consists of two main components. The first is termed ""AI for Code,"" which focuses on enhancing the developer experience by integrating capabilities and features into their products. The second component, ""Code for AI,"" is centered around building AI applications and identifying the necessary abstractions for their development.\n\n# [85.12s] Evolution of AI Agents\nToday, Malit will discuss the evolution of AI agents. He emphasizes that this presentation will summarize key innovations driving the current adaptation of AI, referencing an article published by McKinsey.']","Malit contributed to the enhancement of the WSO2 mobile app by discussing the addition of features such as personalized scheduling and a chatbot for user interaction, which improved the user experience. WSO2's AI strategy, which includes components like 'AI for Code' and 'Code for AI,' plays a role in this development by focusing on integrating AI capabilities into their products and building AI applications, thereby supporting the evolution and enhancement of applications like the WSO2 mobile app.",multi_hop_specific_query_synthesizer
How does the Med-LVLM model HealthGPT utilize the three-stage learning strategy to improve performance in medical visual comprehension and generation tasks?,"['<1-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8']","The Med-LVLM model HealthGPT employs a three-stage learning strategy to enhance performance in medical visual comprehension and generation tasks. This strategy decouples comprehension and generation tasks, which helps to reduce performance degradation caused by task conflicts. Unlike mixed-training methods that train both tasks simultaneously and suffer from catastrophic forgetting, the three-stage approach effectively leverages medical embedding knowledge in pre-trained LLMs to mitigate these conflicts. Additionally, the strategy involves fusing heterogeneous H-LoRA plugins in the second training stage, resulting in minimal performance degradation. This approach allows HealthGPT to achieve significant performance improvements across multiple medical comprehension and generation tasks.",multi_hop_specific_query_synthesizer
Wht happens when GPT-4 quota is exeeded?,"['<1-hop>\n\n## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.']","When the GPT-4 quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. This is part of the model failover policy, where the AI gateway routes requests to a primary endpoint until it is exhausted, then falls back to a secondary endpoint.",multi_hop_specific_query_synthesizer
How does LLaVA-Med perfom in MRI super-resoluton tasks?,"['<1-hop>\n\nC.6 Case Study\nFigures 11 and 12 illustrate examples of modality transformation and super-resolution reconstruction. In Figure 11, the results\ngenerated by our method in the CT (MRI) to MRI (CT) transformation task are highly close to the ground truth, effectively\nguiding the model in the transformation across different regions. For the MRI super-resolution reconstruction task, Figure 12\ndemonstrates the accuracy of our method in restoring scan image details, accurately reconstructing the essential details of the\nimage.\nTable 11: The experimental results for the four reconstruction tasks.\nCT(Brain) CT(Pelvis) MRI (Brain) MRI(Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\nSEED-X 20.18 27.66 112.11 21.53 28.02 102.87 4.90 27.62 112.86 6.31 27.89 106.21\nUnified-IO 2 83.93 36.09 17.95 85.36 35.10 25.46 87.50 34.25 25.47 86.31 33.53 29.80\nHealthGPT-M3 91.73 36.42 15.46 94.26 37.30 12.53 88.76 33.97 27.05 84.40 33.11 32.62\n34.08\n15.87\n9.16\n5.62\n13.33\n21.94\nHealthGPT\nLLaVA-Med\nHuatuoGPT-Vision\nLlama-3.2\nInternVL-2\nShow-o\nHuman\nEvaluation\n(a) (b)\nFigure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.\n17']","The context does not provide specific performance metrics for LLaVA-Med in MRI super-resolution tasks. However, it mentions that the method used in the study accurately reconstructs essential details of MRI images, suggesting effective performance in such tasks.",multi_hop_specific_query_synthesizer
How does the AI gateway manage model failover and ensure secure interactions?,"['<1-hop>\n\n## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.', '<2-hop>\n\n## [4142.16s] Observability and Logging\nFinally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant.\n\n**Time Range: 01:10:00 - 01:18:25**\n\n# [4200.40s] Introduction to API Usage with Guardrails\nBefore attempting to use the API with Guardrails, it is essential to understand how a use case would appear without these protective measures. In this demonstration, a query related to firearms is posed, which is not an appropriate topic for a hotel assistant.']","The AI gateway manages model failover by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region. To ensure secure interactions, logging policies are implemented for observability, allowing all actions to be tracked and monitored, which ensures effective management and governance of the AI gateway.",multi_hop_specific_query_synthesizer
What are the features of the Egress AI Gateway and how does it manage interactions with multiple AI providers?,"['<1-hop>\n\n## [2721.68s] Features of the Egress AI Gateway\nAs organizations grow their AI teams and adopt various AI services, the need for a mediation layer becomes apparent. This layer allows organizations to manage interactions with multiple AI providers without being dependent on a single one. \n\nThe egress AI gateway offers several features, including model routing, token-based rate limiting, AI guard, prompt management, adaptive routing, and semantic caching. Additionally, it retains the standard capabilities of an ingress gateway, such as analytics, identity access management, and mediation capabilities. Organizations can connect with any AI service, and the product comes pre-configured with a set of services while allowing for custom configurations.', '<2-hop>\n\n### [2605.04s] Egress AI Gateway Introduction\nThe egress AI gateway functions similarly to the ingress gateway, with a set of customized policies and rules enforced to ensure that all outgoing calls from the organization are properly governed and managed. This provides visibility into the interactions occurring outside the organization.\n\nFor instance, consider an AI-powered booking assistant and a staff allocation agent accessing different deployments of OpenAI in various regions. This scenario illustrates the complexity of tracking calls to different models and deployments, which can lead to hidden costs and management challenges. The egress AI gateway addresses these issues by sitting between backend systems and LLM services, ensuring proper governance.']","The Egress AI Gateway offers several features, including model routing, token-based rate limiting, AI guard, prompt management, adaptive routing, and semantic caching. It retains the standard capabilities of an ingress gateway, such as analytics, identity access management, and mediation capabilities. The gateway functions similarly to an ingress gateway, with customized policies and rules to ensure that all outgoing calls from the organization are properly governed and managed. This provides visibility into interactions occurring outside the organization, allowing organizations to manage interactions with multiple AI providers without being dependent on a single one.",multi_hop_specific_query_synthesizer
How does the integration of LoRA in HealthGPT enhance its performance in medical visual comprehension and generation tasks?,"['<1-hop>\n\nFigure 3: The HealthGPT architecture integrates hierarchical visual perception and H-LoRA, employing a task-specific hard\nrouter to select visual features and H-LoRA plugins, ultimately generating outputs with an autoregressive manner.\na design paradigm based on ViT, alignment adapters, and\npre-trained LLMs(Liu et al. 2023, 2024b), enabling quick\nadaptation to downstream tasks.\nVQGAN. VQGAN (Esser, Rombach, and Ommer 2021)\nemploys latent space compression and indexing mechanisms\nto effectively learn a complete discrete representation of im-\nages. VQGAN first maps the input imageximg to a latent rep-\nresentation z = E(x) through a encoder E. Then, the latent\nrepresentation is quantized using a codebookZ = {zk}K\nk=1,\ngenerating a discrete index sequence I = [im]N\nm=1, where\nim ∈ Zrepresents the quantized code index:\nI = Quantize(z|Z) = arg min\nzk∈Z\n∥z − zk∥2. (2)\nIn our approach, the discrete index sequence I serves as\na supervisory signal for the generation task, enabling the\nmodel to predict the index sequence ˆI from input conditions\nsuch as text or other modality signals. Finally, the predicted\nindex sequence ˆI is upsampled by the VQGAN decoder G,\ngenerating the high-quality image ˆximg = G(ˆI).\nLow Rank Adaptation. LoRA(Hu et al. 2021) effectively\ncaptures the characteristics of downstream tasks by intro-\nducing low-rank adapters. The core idea is to decompose\nthe bypass weight matrix ∆W ∈ Rdin×dout\ninto two low-\nrank matrices {A ∈ Rdin×r, B ∈ Rr×dout\n}, where r ≪\nmin{din, dout}, significantly reducing learnable parameters.\nThe output with the LoRA adapter for the input x is then\ngiven by:\nh = xW0 + αx∆W/r = xW0 + αxAB/r, (3)\nwhere matrix A is initialized with a Gaussian distribution,\nwhile the matrixB is initialized as a zero matrix. The scaling\nfactor α/r controls the impact of ∆W on the model.\n4 HealthGPT\n4.1 Unified Autoregressive Generation.\nHealthGPT (Figure 3) utilizes a discrete token representa-\ntion that covers both text and visual outputs, unifying visual\ncomprehension and generation as an autoregressive task. For\ncomprehension, Mllm receives the input joint sequence U\nand outputs a series of text token R = [ r1, r2, . . . , rNr ],\nwhere ri ∈ Vtxt, and Vtxt represents the LLM’s vocabulary:\nPθ(R | U) =\nNrY\ni=1\nPθ(ri | U, r<i). (4)\nFor generation, Mllm first receives a special start token\n⟨START IMG⟩, then generates a series of tokens corre-\nsponding to the VQGAN indices I = [ i1, i2, . . . , iNi ],\nwhere ij ∈ Vvq, and Vvq represents the index range of VQ-\nGAN. Upon completion of generation, the LLM outputs an\nend token ⟨END IMG⟩:\nPθ(I | U) =\nNiY\nj=1\nPθ(ij | U, i<j). (5)\nFinally, the generated index sequence I is fed into the de-\ncoder G, which reconstructs the target image ˆximg = G(I).\n4.2 Hierarchical Visual Perception\nGiven the differences in visual perception between compre-\nhension and generation tasks—where the former focuses on\nabstract semantics and the latter emphasizes complete se-\nmantics—we employ ViT to compress the image into dis-\ncrete visual tokens at multiple hierarchical levels. Specif-\nically, the image is converted into a series of features\n{f1, f2, . . . , fL} as it passes through L ViT blocks.\n4', '<2-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8']","The integration of LoRA in HealthGPT enhances its performance in medical visual comprehension and generation tasks by effectively capturing the characteristics of downstream tasks through low-rank adapters. LoRA decomposes the bypass weight matrix into two low-rank matrices, significantly reducing learnable parameters while maintaining performance. This approach allows HealthGPT to adapt quickly to various tasks, as evidenced by its improved performance metrics in tasks such as VQA-RAD and SLAKE, where it outperforms other methods like MoELoRA and H-LoRA in certain scenarios. Additionally, the use of LoRA contributes to the efficient handling of diverse tasks, as shown in the performance comparisons presented in Table 4.",multi_hop_specific_query_synthesizer
How does the default model provider from WS2 facilitate the development process in the context of AI integration using the Devant platform?,"['<1-hop>\n\n### [1891.84s] Creating the Agent\nThe developer will name the agent ""Creating Agent."" Once the agent is created, a diagram representing the agent will be displayed. Although the initial view may appear blank, it is possible to assign roles and provide specific instructions for the agent\'s functionality. The default model provider from WS2 is available, which serves as an open AI proxy to facilitate the development process.\n\n## [2205.04s] Integration Development Process\nBefore diving into the development, it is essential to understand the existing applications, including hotel APIs, admin APIs, and external APIs. The platform called Devant will be used for building, deploying, and managing integrations. The focus will be on the development aspect rather than existing applications.', ""<2-hop>\n\n## [4651.36s] MCP Hub and Developer Portal\nRecently released features include an MCP hub, which serves as a developer portal where AI developers can discover and integrate various MCP servers. Additionally, an MCP inspector, referred to as the MCP playground, is available for testing and feedback.\n\n# [4700.69s] Conclusion\nIn conclusion, users are encouraged to explore these new features and provide feedback to enhance the overall experience and functionality of the system.\n\n**Time Range: 00:00:05 - 00:10:02**\n\n# [5.27s] Introduction\nIn this session, Geethika Cooray, the Vice President and General Manager of WS2's identity management business, welcomes everyone and expresses hope for their well-being.""]","The default model provider from WS2 serves as an open AI proxy, which facilitates the development process by allowing developers to assign roles and provide specific instructions for the agent's functionality. This is particularly useful in the context of AI integration using the Devant platform, which is used for building, deploying, and managing integrations. The WS2 model provider aids in streamlining the development aspect, enabling a more efficient integration process.",multi_hop_specific_query_synthesizer
How does Guard AI enhance the security of PII detection and masking in conjunction with regex-based methods?,"['<1-hop>\n\n## [3331.68s] Regex-Based PII Masking\nRegex-based PII (Personally Identifiable Information) masking allows users to define patterns, such as email addresses, that must not be matched in outgoing prompts. If an email is detected, the system replaces it with a dummy value, ensuring that sensitive information is not exposed while still allowing the LLM to function normally.\n\n## [3397.12s] Advanced PII Detection and Masking\nFor more ambiguous cases, advanced PII detection and masking techniques are employed. This involves using a framework called Guard AI, which utilizes LLMs to make decisions and perform reasoning. This combination of regex and advanced detection provides robust security for the egress gateway, preventing sensitive information from being leaked to the LLM.']","Guard AI enhances the security of PII detection and masking by utilizing LLMs to make decisions and perform reasoning in more ambiguous cases. This advanced detection works alongside regex-based methods, providing robust security for the egress gateway and preventing sensitive information from being leaked to the LLM.",multi_hop_specific_query_synthesizer
"What are the value additions of Vertical AI in healthcare, and why is it important?","['<1-hop>\n\n## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.', '<2-hop>\n\n### [518.96s] Value Additions of Vertical AI\nThe vertical AI layer includes several value additions, such as:\n\n- **Industry-Specific Model Adaptation**: Tailored knowledge and terminology relevant to healthcare customers.\n- **Proprietary Data Utilization**: Incorporation of industry-specific workflows and decision-making logic that aligns with established processes.\n- **Seamless Integration**: The ability to connect with industry-specific systems, such as healthcare systems and open banking APIs.\n- **Regulatory Compliance**: Development of API products that adhere to industry regulations, ensuring that the solutions are both effective and compliant.']","Vertical AI in healthcare offers several value additions, including industry-specific model adaptation with tailored knowledge and terminology relevant to healthcare customers, proprietary data utilization that incorporates industry-specific workflows and decision-making logic, seamless integration with healthcare systems, and regulatory compliance through the development of API products that adhere to industry regulations. Vertical AI is important because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios, where consumers demand solutions specifically designed to meet their unique business needs.",multi_hop_specific_query_synthesizer
Wht is the Model Context Protocol and how does it relate to the need for retrieval-augmented generation in AI?,"[""<1-hop>\n\n## [2846.24s] Overview of the Model Context Protocol\nThe MCP provides a universal port for agents and general integrations, facilitating the connection of data and APIs with minimal effort. It standardizes how tools, resources, and prompts interact, ensuring consistency across various applications.\n\n### [2859.44s] Components of MCP\nTools refer to API calls and database queries, while resources encompass data files and contextual information. Prompts are templates that guide the LLM's responses, allowing for reuse across different applications.\n\n**Time Range: 00:50:02 - 01:00:02**\n\n# [3002.40s] Importance of Reusable Code in Client Connections\nWhen multiple hosts attempt to connect to the same data source, it becomes crucial to avoid redundant coding practices. Writing the same code repeatedly for each client can be tedious and inefficient. While some instances may involve simple code, others can require more complex and lengthy implementations. Additionally, ensuring best practices in the code is essential for production readiness. \n\nTo streamline this process, one can create a Managed Code Platform (MCP) server, allowing all clients and hosts to reuse the same logic. This approach is akin to the use of APIs, where reusable segments of code are created and integrated into a monolithic architecture. APIs are deployed and created only once, which simplifies the integration process."", ""<2-hop>\n\n**Time Range: 00:00:03 - 00:10:04**\n\n# [3.76s] Introduction to AI and Generative AI\nGood morning, everybody. The focus of today's discussion is on artificial intelligence (AI), particularly generative AI. We will explore the significance of integration in building AI applications in the current landscape, especially with the rise of generative AI. This topic is crucial, and we will also cover common integration patterns associated with generative AI.\n\n## [42.32s] The Need for Retrieval-Augmented Generation\nIn addition to integration patterns, we will delve into the necessity of retrieval-augmented generation. This will be discussed in detail, along with the concept of agents, which is a hot topic in the AI community today. We will also examine the importance of the Model Context Protocol (MCP) and the responsibility that comes with building effective AI applications. It is essential that AI systems are designed with certain guardrails and governance in mind. We will touch upon the concept of zero trust design for AI agents, which, while traditionally applied to other domains, is now being adapted for AI.""]","The Model Context Protocol (MCP) provides a universal port for agents and general integrations, facilitating the connection of data and APIs with minimal effort. It standardizes how tools, resources, and prompts interact, ensuring consistency across various applications. This is particularly important in the context of retrieval-augmented generation, which is a significant aspect of building AI applications, especially with the rise of generative AI. The MCP ensures that AI systems are designed with certain guardrails and governance in mind, which is crucial for effective AI application development.",multi_hop_specific_query_synthesizer
How AI Gateway Analytics help in healthcare AI?,"['<1-hop>\n\n# [3146.56s] AI Gateway Analytics\nAI gateway analytics involves publishing specific analytic details for AI use cases. For example, a casual analytic scenario may count requests, identify headers used, and track errors. This provides a breakdown that helps AI developers understand system performance. The analytics dashboard is purpose-driven, allowing developers to identify issues, such as which services or applications are consuming more data or tokens. \n\nThe dashboard offers detailed insights into vendor model usage, identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.']","AI Gateway Analytics helps in healthcare AI by providing a detailed breakdown of system performance, which includes counting requests, identifying headers used, and tracking errors. This allows AI developers to understand which services or applications are consuming more data or tokens, and offers insights into vendor model usage, such as identifying the most in-demand models and those that are quickly rate-limited. These insights enable organizations to adjust their systems for optimal performance, which is crucial in the healthcare sector where efficiency and accuracy are paramount.",multi_hop_specific_query_synthesizer
How Anjen use W integrator for AI transformation in business?,"['<1-hop>\n\n## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.']","Anjen will introduce a W integrator to facilitate the AI transformation process in business. This integrator is part of the toolkit necessary for implementing AI transformation step by step, as discussed in the context of a specific business use case.",multi_hop_specific_query_synthesizer
How hav large langauge models made AI more accesible for medical visual comprehension tasks?,"['<1-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.']","Large language models have made AI more accessible for medical visual comprehension tasks by providing versatile tools that do not require extensive fine-tuning. These models allow users to perform various tasks, such as text summarization or sentiment analysis, through conversational interfaces, making them user-friendly and accessible even to those without deep expertise in AI development. Additionally, their availability as APIs further simplifies their integration into different applications, including those in the medical field.",multi_hop_specific_query_synthesizer
How does the VQA-RAD benchmark contribute to evaluating the performance of HealthGPT in medical visual comprehension tasks?,"['<1-hop>\n\nTable 8: Data distribution of VL-Health in three-stage learning strategy.\nMedical Task Stage-1 Stage-2\nComp. LLaV A-558k, PubMedVision-PT Mixed-47kGen. LLaV A-558k\nMedical Task Stage-3\nComp. LLaV A Med, MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, VQA-RAD\nGen. IXI, SynthRAD2023, MIMIC-CHEST-XRAY\nData Format. All data samples are converted into a unified instruction-response format for training and evaluation. Specifi-\ncally, the VL-Health dataset consists of the following components:\n• Task Type: Specifies the granularity of visual features output by the visual encoder and selects the corresponding H-\nLoRA submodule. For generation tasks, the response also includes multi-modal tokens corresponding to VQ indices.\n• Task Instruction: Guides the model to interpret the image and generate a response, covering various aspects of the\nimage and specifying the output format.\n• Response: The textual output generated based on the task instruction and input image, ensuring it meets the question and\nformatting requirements.\n• Input Image: Provides the visual signal for the model to process.\n• Target Image Index: In generation tasks, this is added as a multi-modal token to the response for autoregressive\ngeneration.\nB Analysis of Heterogeneous Low-Rank Adaptation\nWe propose H-LoRA, which utilizes hard routing selection to allocate plugins for knowledge learning and representation across\ntasks, thereby preventing conflicts arising from heterogeneous knowledge. Furthermore, within each task, we optimized based\non MoELoRA, enhancing performance while reducing computational overhead. The pseudocode is detailed Algorithm 1.\nAlgorithm 1: H-LoRA Algorithm\nInput: concrete-grained visual features FCon, abstract-grained visual featuresFAbs, comprehension-based H-LoRA modules\n({AComp.\ni }k\ni=1, RComp.\nouter ), generation-based H-LoRA modules({AGen.\ni }k\ni=1, RGen.\nouter), task type T (comprehension or generation),\nnumber of LoRA experts k, origin linear layer weights W0, text features T , hidden state h\nOutput: final output O\n// Select task-specific image features\nif T = generation task then\nFimg ← FCon\nelse if T = comprehension task then\nFimg ← FAbs\nend if\nU ←concat(Fimg, T ) // Concatenate image features and text features\n{Ai}k\ni=1, {Bi}k\ni=1, Router ← {AT\ni }k\ni=1, {BT\ni }k\ni=1, RT\nouter // Assign task-specific H-LoRA submodule\n// Merge LoRA experts’ matrices\nAmerged ← concat({Ai}k\ni=1)\nBmerged ← concat({Bi}k\ni=1)\nW ←R(h) // Generate routing weights based on input hidden state x\nWexpanded ← α × W/r ⊗ 1r // Expand routing weights to match merged matrices\nOH-LoRA ← (x · Amerged ⊙ Wexpanded) · Bmerged // Compute H-LoRA output using element-wise multiplication\nO ←x · W0 + OH-LoRA // Add H-LoRA output to pre-trained weights to get final output\nReturn O\nWe further analyzed the computational overhead differences between MoELoRA and H-LoRA. Assuming that both methods\nuse the same number of LoRA experts k, we can compare their time complexity from the perspective of the operational steps\ninvolved.\nComputational Overhead of MoELoRA. In MoELoRA, the operations involving the expert matrix mainly include the fol-\nlowing steps: (i) Expert Multiplication : MoELoRA requires 2k multiplications with the LoRA experts. (ii) Router Multi-\nplication: One multiplication with the Router is required. (iii) Router Output Expansion : MoELoRA needs to perform k\n14', '<2-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","The VQA-RAD benchmark is used in human evaluation to assess the performance of HealthGPT in medical visual comprehension tasks. Specifically, it contains 1,000 open-ended questions, and during the evaluation, responses generated by HealthGPT and other models are ranked by clinicians. The results indicate that HealthGPT frequently provides the best answers, suggesting its strong application potential in medical care scenarios. This evaluation helps demonstrate HealthGPT's effectiveness in handling medical visual comprehension tasks, as evidenced by its performance on the VQA-RAD benchmark.",multi_hop_specific_query_synthesizer
"How does the work of Ma, Y. contribute to the development of advanced AI tools for medical image and text understanding, and what are the implications for healthcare innovation?","['<1-hop>\n\nWang, Z.; Wu, Z.; Agarwal, D.; and Sun, J. 2022. Medclip:\nContrastive learning from unpaired medical images and text.\narXiv preprint arXiv:2210.10163.\nWang, Z.; Zhang, L.; Wang, L.; and Zhang, Z. 2024b. Soft\nMasked Mamba Diffusion Model for CT to MRI Conver-\nsion. arXiv preprint arXiv:2406.15910.\nWu, C.; Chen, X.; Wu, Z.; Ma, Y .; Liu, X.; Pan, Z.; Liu, W.;\nXie, Z.; Yu, X.; Ruan, C.; and Luo, P. 2024. Janus: Decou-\npling Visual Encoding for Unified Multimodal Understand-\ning and Generation. arXiv:2410.13848.\nWu, S.; Fei, H.; Qu, L.; Ji, W.; and Chua, T.-S. 2023.\nNext-gpt: Any-to-any multimodal llm. arXiv preprint\narXiv:2309.05519.\nXie, J.; Mao, W.; Bai, Z.; Zhang, D. J.; Wang, W.; Lin, K. Q.;\nGu, Y .; Chen, Z.; Yang, Z.; and Shou, M. Z. 2024. Show-o:\nOne single transformer to unify multimodal understanding\nand generation. arXiv preprint arXiv:2408.12528.\nYoung, A.; Chen, B.; Li, C.; Huang, C.; Zhang, G.; Zhang,\nG.; Li, H.; Zhu, J.; Chen, J.; Chang, J.; et al. 2024.\nYi: Open foundation models by 01. ai. arXiv preprint\narXiv:2403.04652.\nZhou, H.; Liu, F.; Gu, B.; Zou, X.; Huang, J.; Wu, J.; Li,\nY .; Chen, S. S.; Zhou, P.; Liu, J.; et al. 2023. A survey of\nlarge language models in medicine: Progress, application,\nand challenge. arXiv preprint arXiv:2311.05112.\nZhu, J.-Y .; Park, T.; Isola, P.; and Efros, A. A. 2017. Un-\npaired image-to-image translation using cycle-consistent ad-\nversarial networks. InProceedings of the IEEE international\nconference on computer vision, 2223–2232.\n11']","Ma, Y. is part of the research team that developed Janus, a model focused on decoupling visual encoding for unified multimodal understanding and generation. This work contributes to the development of advanced AI tools by enhancing the integration of visual and textual data, which is crucial for improving medical image and text comprehension. The implications for healthcare innovation include more accurate diagnostics and personalized treatment plans, as these tools can better interpret complex medical data.",multi_hop_specific_query_synthesizer
"How does the model failover policy utilize ChatGPT in AI systems, and what role do large language models play in this context?","['<1-hop>\n\n## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.', '<2-hop>\n\n## [115.60s] Defining Key Terminologies\nBefore we proceed, it is important to define some key terminologies. AI refers to any system that can simulate human intelligence. This can range from simple functions to complex machine learning models and deep learning architectures. Generative AI, a subset of AI, focuses on creating original content, which can include text, audio, and visual elements.\n\n### [155.28s] Understanding Large Language Models\nLarge language models (LLMs), such as ChatGPT from OpenAI, are examples of generative AI that specialize in natural language processing. They are designed to understand and generate text, making them a significant advancement in the field.']","The model failover policy utilizes ChatGPT by initially providing users with responses from GPT-4, which are informative and high-quality. Once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. This policy is part of an AI gateway that routes requests to a primary endpoint until it is exhausted, then falls back to a secondary endpoint. Large language models like ChatGPT, which are examples of generative AI, specialize in natural language processing and are designed to understand and generate text, making them integral to the implementation of such failover policies in AI systems.",multi_hop_specific_query_synthesizer
Who is Rana Kalaf and what role does she play in AI development at WSO2?,"['<1-hop>\n\n## [301.52s] The Challenge of Delivering Business Value\nThe discussion shifts to the challenges of delivering business value through AI products. Rana Kalaf addresses the initial excitement of building AI products and the subsequent concerns about whether they truly deliver value. She notes the evolution of AI development, contrasting traditional data science practices with the current need for real-time, distributed systems. Rana emphasizes that building AI applications is now a collaborative effort, requiring a focus on scalability and production readiness. She stresses the importance of measuring the effectiveness of AI tools, suggesting that organizations should view AI as a means to enhance processes rather than an end goal.', ""<2-hop>\n\n## [11.84s] Panelist Introductions\nYad Ahmed shares his background, stating that he has 24 years of experience in technology, with eight years focused on natural language processing (NLP) and AI. He explains that Arabic AI, which operates under the name Turjim, has been in business for 17 years, initially focusing on translation and content generation. In 2016, the company expanded into technology, developing automated systems for translation and content generation. Recently, they secured a Series A funding round of $50 million to further their work in AI, particularly in model fine-tuning and workflow automation.\n\nRana Kalaf introduces herself as the Chief AI Officer at WSO2. She emphasizes the company's focus on two main areas in their AI journey: accelerating user engagement with their products through embedded agents and co-pilots, and integrating AI into applications via connectors and an agent-building framework.\n\nAlan Shmal from Vistra describes the company as a corporate services provider that handles accounting, payroll, and legal entity management. He explains that their AI initiatives include a conversational agent built with Aentic AI frameworks, which serves three main functions: advisory, reporting on customer data, and executing workflows. He also mentions the use of asynchronous systems to process unstructured data, such as legal documents and voice notes.\n\nMahesh Saloria represents Canada HSBC Life Insurance, a joint venture between Canara Bank and HSBC. He discusses their focus on securing individuals' futures through insurance and highlights a recent initiative involving an underwriting co-pilot designed to assist underwriters in assessing risk.""]","Rana Kalaf is the Chief AI Officer at WSO2. She plays a significant role in AI development by focusing on accelerating user engagement with their products through embedded agents and co-pilots, as well as integrating AI into applications via connectors and an agent-building framework.",multi_hop_specific_query_synthesizer
"How does the retrieval-augmented generation (RAG) process enhance the efficiency of large language models in healthcare applications, and what role do vector embeddings and databases play in this process?","[""<1-hop>\n\n**Time Range: 00:10:01 - 00:20:02**\n\n# [1253.20s] Introduction to Retrieval-Augmented Generation\nTo address these challenges, the solution lies in retrieval-augmented generation (RAG). This approach is gaining attention as it allows for more efficient use of data within large language models (LLMs). The core idea is straightforward: rather than inputting all available information into the model's prompt, only the relevant data should be included. However, determining what is relevant poses a significant challenge.\n\n## [1298.16s] The RAG Process\nRAG suggests that before incorporating data into prompts, one should first index the data. This can be achieved using vector embeddings and a vector database. The process involves creating a search index, which allows for efficient retrieval of relevant information when a question or task arises. For instance, similar to how Google retrieves links based on a search query, RAG utilizes an index to find pertinent information, which is then fed to the LLM to generate answers.""]","The retrieval-augmented generation (RAG) process enhances the efficiency of large language models (LLMs) in healthcare applications by ensuring that only relevant data is included in the model's prompts. This is crucial in healthcare, where vast amounts of data are available, and precision is essential. The RAG process involves indexing data using vector embeddings and a vector database, which creates a search index. This index allows for the efficient retrieval of pertinent information when a question or task arises, similar to how Google retrieves links based on a search query. By feeding only the relevant information to the LLM, RAG optimizes the model's performance, making it more effective in generating accurate and contextually appropriate responses in healthcare settings.",multi_hop_specific_query_synthesizer
How retrieval-augmented generation work with vector database?,"['<1-hop>\n\n## [1841.68s] Searching for Relevant Information\nThe vector database performs the search operation using the provided vector, returning a selection of relevant document chunks. These chunks can then be utilized in the prompt to generate a response.\n\n# [1861.20s] Mastery of Generative AI\nAs we delve deeper into retrieval-augmented generation (RAG), it is crucial to understand its applications in generative AI. This technology enables the creation of content, answering questions, and analyzing data, all of which can significantly enhance organizational operations.\n\n# [1961.04s] Understanding AI Agents\nAI agents are systems that utilize generative AI models to autonomously make decisions and perform tasks. These tasks, often referred to as tools, can include functions such as API calls, database interactions, or even controlling physical devices.', ""<2-hop>\n\n**Time Range: 00:10:01 - 00:20:02**\n\n# [1253.20s] Introduction to Retrieval-Augmented Generation\nTo address these challenges, the solution lies in retrieval-augmented generation (RAG). This approach is gaining attention as it allows for more efficient use of data within large language models (LLMs). The core idea is straightforward: rather than inputting all available information into the model's prompt, only the relevant data should be included. However, determining what is relevant poses a significant challenge.\n\n## [1298.16s] The RAG Process\nRAG suggests that before incorporating data into prompts, one should first index the data. This can be achieved using vector embeddings and a vector database. The process involves creating a search index, which allows for efficient retrieval of relevant information when a question or task arises. For instance, similar to how Google retrieves links based on a search query, RAG utilizes an index to find pertinent information, which is then fed to the LLM to generate answers.""]","Retrieval-augmented generation (RAG) works with a vector database by first indexing data using vector embeddings. The vector database performs a search operation using a provided vector to return relevant document chunks. These chunks are then utilized in the prompt to generate a response. This process allows for efficient retrieval of relevant information, which is then fed to large language models (LLMs) to generate answers, enhancing the use of data within generative AI applications.",multi_hop_specific_query_synthesizer
How does MoELoRA compare to other methods like LoRA and H-LoRA in terms of performance and training time for medical visual comprehension and generation tasks?,"['<1-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8', '<2-hop>\n\nTable 3: Comparison results of super-resolution task.\nModel SSIM↑ PSNR↑ MSE↓ LPIPS↓\nSRGAN 71.34 32.01 41.27 24.50\nDASR 71.57 32.34 38.25 19.17\nReal-ESRGAN 67.30 31.87 42.57 20.64\nLIIF 73.27 32.13 40.14 22.93\nBSRGAN 69.97 31.97 41.52 28.72\nHealthGPT-M3 78.19 32.76 34.47 12.02\nHealthGPT-L14 77.94 32.71 35.19 12.43\nFigure 5: Performance comparison of LoRA, MoELoRA,\nand H-LoRA under different rank settings.\net al. 2024b), Llama-3.2 (Dubey et al. 2024)). Addition-\nally, we test several SOTA unified visual comprehension\nand generation models, including Show-o (Xie et al. 2024),\nUnified-IO 2 (Lu et al. 2024), and Janus (Wu et al.\n2024). The experimental results are shown in Table 1, with\nthe following key observations: (i) SOTA Results Com-\npared with LVLMs: In medical visual comprehension\ntasks, HealthGPT demonstrates superior performance,\nsignificantly outperforming both medical-specific models\n(e.g., HuatuoGPT-Vision) and general-purpose models (e.g.,\nLlama-3.2). (ii) Surpassing Current Unified LVLMs: De-\nspite being trained on billions of data points, unified mod-\nels still exhibit poor generalization performance in medi-\ncal visual comprehension. For instance, Unified-IO 2 scored\nonly 33.8. In contrast,HealthGPT-M3, with only 3.8B pa-\nrameters, scored 61.3 on the medical multi-modal unified\ntask, significantly outperforming existing unified models in\nmedical downstream scenarios. (iii) Stable Improvement\nwith Large Base Model: Our method demonstrates excel-\nlent scalability, with HealthGPT-L14 achieving a score\nof 66.4 in the larger model configuration. This result signif-\nicantly outperforms all other models, highlighting the effec-\ntiveness of scaling up the base model for enhanced perfor-\nmance in medical tasks.\nGeneration. We study three key tasks in medical imag-\ning. (i) Modality Conversion: In this task, we focus on\nthe conversion between CT and MRI modalities for the\nbrain and pelvic regions, designing four specific sub-tasks.\nAll comparative models (Pix2Pix (Isola et al. 2017), Cy-\ncleGAN (Zhu et al. 2017), BBDM (Li et al. 2023a),\n(%)\n(%)\n（a） （b）\nFigure 6: The loss visualization (a) and performance com-\nparison (b) with respect to different visual perceptions.\nVmamba (Liu et al. 2024e), and DiffMa (Wang et al.\n2024b)) trained a separate model for each sub-task, while\nHealthGPT unify all tasks into a single training process.\nThe experimental results, shown in Table 11, demonstrate\nthat our approach outperforms other methods across multi-\nple evaluation metrics. For instance, in the CT2MRI-Brain\ntask, HealthGPT-M3 achieves an SSIM of 79.38, signif-\nicantly surpassing traditional methods like Pix2Pix (71.09)\nand the recent DiffMa (71.47). (ii) Super-Resolution: We\nconduct 4× super-resolution experiments on the IXI dataset,\nwith the results presented in Table 3. Notably, most exist-\ning methods fail to fully leverage the prior knowledge of key\nstructures in medical images, resulting in significant short-\ncomings in detail recovery. In contrast, our method signif-\nicantly mitigates this issue. Specifically, HealthGPT-M3\nexcels in key metrics such as SSIM, PSNR, and ISE, achiev-\ning scores of 78.19, 32.76, and 34.47, respectively. Ad-\nditionally, HealthGPT-M3 achieves the lowest score of\n12.34, further validating its exceptional performance in hu-\nman visual perception. (iii) Reconstruction: We compare\nHealthGPT-M3 with unified models with reconstruction\ncapabilities, such as Unified-IO 2 and SEED-X. The results\nshow that our approach performs better controllability for vi-\nsual reconstruction. We also trainHealthGPT-L14 with a\nsimilar number of trainable parameters to the M3 version.\nHence, the similar performance between the two models\nmeets our expectations. Details are in the Appendix.\n5.3 In-Depth Study\nEffect of Heterogeneous Low-Rank Adaptation.H-LoRA\nprovides an optimized multi-LoRA architecture for multi-\ntask learning. We conduct extensive validation of this struc-\nture, with results presented in Table 4, comparing the per-\nformance of LoRA, MoELoRA, and H-LoRA in medical\nunified comprehension and generation tasks. In the majority\nof comprehension tasks and all generation tasks, H-LoRA\ndemonstrates superior performance, particularly in the Om-\nniMedVQA benchmark, where it improved from 64.90 to\n68.50. Notably, despite some applications of MoELoRA in\ncertain scenarios, it do not show advantages in this task and\n7']","MoELoRA, when compared to LoRA and H-LoRA, shows varied performance in medical visual comprehension and generation tasks. According to Table 4, MoELoRA achieves a training time approximately 50% longer than LoRA. In terms of performance, MoELoRA scores 72.5 on VQA-RAD and 57.2 on SLAKE, which is slightly better than LoRA but not as high as H-LoRA, which scores 73.7 and 55.9 respectively. H-LoRA consistently outperforms both LoRA and MoELoRA across different tasks, demonstrating significant advantages in handling diverse tasks, as shown in Figure 5. Additionally, H-LoRA's three-stage learning strategy effectively reduces performance degradation from task conflicts, further enhancing its performance over MoELoRA.",multi_hop_specific_query_synthesizer
How MCP server help AI agent talk to EHR systems?,"['<1-hop>\n\n# [4800.24s] Overview of MCP Server Configuration\nBy default, the configuration is set to two, but this particular MCP server only supports HTTP/1. This is something I confirmed through testing. You can edit the settings in local code or in pro code mode; either method works. Regardless of the approach taken, the diagram and the code remain in sync.\n\n## [4823.12s] Executing a Query\nThe system is currently running, and I should access the chat window. Here it is. We will proceed with our usual query: ""Plan me a trip for 5 days in Sri Lanka."" The system is taking some time to process the request. We will wait for the response, and then I will walk through the verbose logs.', '<2-hop>\n\n### [846.64s] Code for AI\nMoving on to ""Code for AI,"" this involves providing building blocks for developing AI-related capabilities. An example is the MCP server, which converts a standard API into a tool that an AI agent can easily communicate with. WSO2 offers pre-built support to convert any FHIR server, such as an EHR server, into an MCP server, allowing direct communication with AI agents.\n\nA demonstration illustrates this user experience. When a user enters a healthcare-specific prompt, the system redirects to an authorization flow where the user must provide consent for the agent to access their data. The AI agent then calls the APIs using the MCP server to access the records. For example, if the prompt is about recorded immunizations, the AI agent retrieves the relevant health records. This capability is significant because a horizontal AI would lack the knowledge to interact with EHR systems and would require server-side enablement via the MCP server.']","The MCP server helps an AI agent communicate with EHR systems by converting a standard API into a tool that the AI agent can easily interact with. WSO2 provides pre-built support to convert any FHIR server, such as an EHR server, into an MCP server, enabling direct communication with AI agents. This allows the AI agent to call the APIs using the MCP server to access health records, such as recorded immunizations, after the user provides consent.",multi_hop_specific_query_synthesizer
How does the AI gateway manage model failover and the incorporation of new models?,"['<1-hop>\n\n## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.']","The AI gateway manages model failover by routing requests to a primary endpoint until it is exhausted, at which point it falls back to a secondary endpoint, potentially in a different region. For incorporating new models, the system can initially route a small percentage of requests to the new model and gradually increase this percentage as confidence in the model grows.",multi_hop_specific_query_synthesizer
How have recent advancements in machine learning improved the accessibility and scalability of AI applications?,"['<1-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.', '<2-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.']","Recent advancements in machine learning have improved the accessibility of AI applications by making them user-friendly, allowing users to interact with models through conversational interfaces rather than requiring extensive work with numerical and categorical features. Additionally, the advent of large language models has simplified the process of performing tasks like text summarization or sentiment analysis without needing to fine-tune the models. These models are available as APIs, making them easily accessible for developers. However, scalability remains a significant challenge, although improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.",multi_hop_specific_query_synthesizer
How do AI gateways enhance centralized governance and security in managing AI applications?,"['<1-hop>\n\n## [4032.08s] Centralized Governance through AI Gateways\nThe implementation of guardrails and governance can be challenging if done at the application level for each individual model. A more scalable solution is to establish an AI gateway that centralizes control and enforcement of policies across all applications. This approach simplifies management and auditing, ensuring consistent enforcement of guidelines, such as prohibiting the submission of personal information to LLMs.\n\nThe AI gateway acts as a gatekeeper, monitoring and governing all incoming and outgoing traffic to and from the LLMs. This centralized system enhances security and efficiency, allowing organizations to manage their AI applications more effectively.']","AI gateways enhance centralized governance and security in managing AI applications by acting as a gatekeeper that monitors and governs all incoming and outgoing traffic to and from the LLMs. This centralized system simplifies management and auditing, ensuring consistent enforcement of guidelines, such as prohibiting the submission of personal information to LLMs. By centralizing control and enforcement of policies across all applications, AI gateways provide a more scalable solution compared to implementing guardrails at the application level for each individual model.",multi_hop_specific_query_synthesizer
"How does the integration of Retrieval-Augmented Generation (RAG) enhance the capabilities of generative AI in modern AI applications, and what role does it play in the AI strategy patterns identified by WSO2?","['<1-hop>\n\n## [1841.68s] Searching for Relevant Information\nThe vector database performs the search operation using the provided vector, returning a selection of relevant document chunks. These chunks can then be utilized in the prompt to generate a response.\n\n# [1861.20s] Mastery of Generative AI\nAs we delve deeper into retrieval-augmented generation (RAG), it is crucial to understand its applications in generative AI. This technology enables the creation of content, answering questions, and analyzing data, all of which can significantly enhance organizational operations.\n\n# [1961.04s] Understanding AI Agents\nAI agents are systems that utilize generative AI models to autonomously make decisions and perform tasks. These tasks, often referred to as tools, can include functions such as API calls, database interactions, or even controlling physical devices.', '<2-hop>\n\n# [339.20s] Building Modern AI Applications\nBuilding modern AI applications involves connecting various components. The process begins with developing AI components, which is itself an integration challenge. Traditional machine learning approaches are becoming less relevant, with integration taking precedence. The success of this integration process relies on utilizing the appropriate patterns.\n\n## [408.88s] Core Patterns in AI Strategy\nWSO2 has identified three core patterns in their AI strategy, which have been extensively covered in previous sessions. The first pattern is GenAI integration, which involves making calls to a GenAI API. This pattern supports various use cases, including text summarization, sentiment analysis, and email drafting.\n\nThe second pattern is Retrieval-Augmented Generation (RAG), where data is stored in a knowledge base and retrieved as needed to ground responses. However, both RAG and GenAI integrations are primarily passive or reactive, lacking the ability to perform actions independently.']","The integration of Retrieval-Augmented Generation (RAG) enhances the capabilities of generative AI by enabling the creation of content, answering questions, and analyzing data, which significantly improves organizational operations. In modern AI applications, RAG involves storing data in a knowledge base and retrieving it as needed to ground responses, thus supporting the generative AI process. According to WSO2's AI strategy, RAG is one of the core patterns identified, alongside GenAI integration. While both RAG and GenAI integrations are primarily passive or reactive, they are crucial for tasks such as text summarization, sentiment analysis, and email drafting, thereby playing a significant role in the development and implementation of advanced AI tools.",multi_hop_specific_query_synthesizer
Howw does the vertical AI layer enhanse healthcare customer support by integrating industry-specific model adaptation and regulatory compliance?,"['<1-hop>\n\n### [518.96s] Value Additions of Vertical AI\nThe vertical AI layer includes several value additions, such as:\n\n- **Industry-Specific Model Adaptation**: Tailored knowledge and terminology relevant to healthcare customers.\n- **Proprietary Data Utilization**: Incorporation of industry-specific workflows and decision-making logic that aligns with established processes.\n- **Seamless Integration**: The ability to connect with industry-specific systems, such as healthcare systems and open banking APIs.\n- **Regulatory Compliance**: Development of API products that adhere to industry regulations, ensuring that the solutions are both effective and compliant.', '<2-hop>\n\n### [350.72s] Framework for Vertical AI\nThe vertical AI layer is built on existing frameworks, utilizing core large language models (LLMs) from companies like OpenAI, Anthropic, and Gemini. These foundational models serve as the base for horizontal AI applications. On top of this, supporting frameworks such as retrieval-augmented generation (RAG) and data infrastructure are integrated. The vertical layer introduces industry-specific model tuning and regulatory compliance, ensuring that the AI solutions are tailored to meet the unique needs of specific sectors.\n\n## [424.88s] Example: Healthcare Customer Support\nTo illustrate the effectiveness of vertical AI, consider a healthcare customer support requirement. At the foundational level, general-purpose LLMs provide basic language capabilities. Companies like Sierra and Decagon enhance these capabilities with frameworks optimized for customer support. The vertical AI layer then adds the necessary clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems. Without this tailored vertical layer, the AI solution would lack the understanding of healthcare nuances and regulatory constraints essential for real-world deployment.']","The vertical AI layer enhances healthcare customer support by incorporating industry-specific model adaptation and regulatory compliance. This layer tailors knowledge and terminology relevant to healthcare customers, ensuring that AI solutions understand the nuances of the healthcare industry. It also ensures compliance with healthcare regulations, which is crucial for real-world deployment. By integrating with electronic health record systems and adhering to industry regulations, the vertical AI layer provides a seamless and compliant solution that enhances the capabilities of foundational large language models, making them suitable for healthcare applications.",multi_hop_specific_query_synthesizer
What role does Escardio play in addressing security challenges in agent development?,"['<1-hop>\n\n## [1027.52s] Conclusion and Next Steps\nIn conclusion, security and access control should be integral to agent development from day one. The conversation will continue in the next video, where Aayisha will join to discuss implementing identities and credentials for agents, as well as the capabilities launched on Escardio. \n\nIn the meantime, interested individuals are encouraged to visit wso2.com/Asgardeo to create a free account and explore the capabilities available for securing agents and authorizing MCP servers. Thank you for joining this discussion, and happy securing your agents.\n\nHealthGPT: A Medical Large Vision-Language Model for Unifying\nComprehension and Generation via Heterogeneous Knowledge Adaptation\nTianwei Lin1, Wenqiao Zhang1, Sijing Li1, Yuqian Yuan1, Binhe Yu2, Haoyuan Li3, Wanggui He3, Hao Jiang3,\nMengze Li4, Xiaohui Song1, Siliang Tang1, Jun Xiao1, Hui Lin1, Yueting Zhuang1, Beng Chin Ooi5\n1Zhejiang University, 2University of Electronic Science and Technology of China, 3Alibaba,\n4The Hong Kong University of Science and Technology,5National University of Singapore\nProject Page\n Code\n1. X-Ray \nComprehension\n2. CT\nComprehension\n3. MRI\nComprehension\nComp. Perf.\n7 Medical Multi-Modal Comprehension Tasks\nGen. \nPerformance\n5 Medical Multi-Modal Generation Tasks\nList all anatomical locations showing \npulmonary edema, hazy opacity, or \nmediastinal displacement.\nLeft hilar structures, left lung,\nright hilar structures, right lung.\nWhich abdominal organ shows any \nindication of a lesion or abnormality \nin the CT image?\nNo abdominal organs show\nany clear indications of lesions\nor abnormalities.\nCould you explain what this mass\nin the MRI means for my health? \nIs it very serious?\nCertainly, the MRI shows a\ndefined mass in your left nasal\ncavity. There is no sign of the ...\n4. Microsopy Comprehension\n What is the purpose of the different \nmembrane treatments used in this \nstudy?\nThe purpose of the different\nmembrane treatments used…\n5. OCT Comprehension\n What is the purpose of comparing \nthe OCT structure image and OCTA \nimage with H&E histology?\nTo confirm the histological position\nof the obtained OCT brain images.\n6. Fundus\nComprehension\n What specific findings or pathological \nchanges can be observed in this \nfundus image?\nThe fundus image appears normal with\nno noticeable signs of pathology…\n7. Ultrasound\nComprehension\n What type of imaging technique \nis used in this image?\nThe image is a sagittal gray-\nscale ultrasonographic…\n1. CT2MRI\nGeneration\nI need a version of this CT representation \nin MRI.\nThe image has\nbeen transformed\ninto MRI.\n2. MRI2CT\nGeneration\nTransform the MRI display into a \nCT image.\nHere is the CT\nversion of the\nMRI image.\n3. Image Reconstruction\nReconstruct the following \nmedical images.\nHere is the reconstructed\nmedical image you need.\n4. Super Resolution\nCould you improve the quality\nof this MRI image?\nHere is the image with\nimproved resolution.\n5. Report-to-CXR\nThe X-ray shows no \npleural effusion or \npneumothorax.\nHere is the\nchest X-ray\nimage for\nyou.\nGen. Perf.\nFigure 1: HealthGPT enables medical multi-modal comprehension and generation , outperforming both state-of-the-art\nunified visual models and medical-specific models across various tasks. This highlights its superior capability in tackling com-\nplex tasks in healthcare applications. Comp.Perf. and Gen.Perf. denote the results of comprehension and generation.\nAbstract\nWe present HealthGPT, a powerful Medical Large Vision-\nLanguage Model (Med-LVLM) that integrates medical vi-\nsual comprehension and generation capabilities within a uni-\nfied autoregressive paradigm. Our bootstrapping philosophy\nis to progressively adapt heterogeneous comprehension and\ngeneration knowledge to pre-trained large language mod-\nels (LLMs). This is achieved through a novel heterogeneous\nlow-rank adaptation (H-LoRA) technique, which is com-\nplemented by a tailored hierarchical visual perception ap-\nproach and a three-stage learning strategy. To effectively\nlearn the HealthGPT, we devise a comprehensive medi-\ncal domain-specific comprehension and generation dataset\ncalled VL-Health. Experimental results demonstrate ex-\nceptional performance and scalability of HealthGPT in\nmedical visual unified tasks. Our project can be accessed at\nhttps://github.com/DCDmllm/HealthGPT.\n1 Introduction\nLarge Vision-Language Models (LVLMs) (Liu et al. 2023;\nOpenAI 2023; Liu et al. 2024c; Chen et al. 2024b) have\ndemonstrated outstanding open-world visual comprehension\nand reasoning abilities through language-based interactive\ndialogue over the past years, simultaneously opening up\nnew opportunities for applications in specialized domains.\n1\narXiv:2502.09838v3  [cs.CV]  21 Feb 2025', '<2-hop>\n\n## [944.08s] Adoption Challenges and Security Considerations\nDespite the eagerness to adopt agents, a small percentage currently reach production due to inadequate access control and guardrails, leading to a lack of trust in these systems. Therefore, it is vital to incorporate identity and access management and security considerations from the outset of development. \n\nOrganizations should not treat security as an afterthought, as retrofitting these concepts later can be challenging and may result in significant issues. Existing IM constructs can be leveraged based on specific contexts, and offerings like Escardio provide unique identities for agents, allowing for controlled access.']","Escardio plays a crucial role in addressing security challenges in agent development by providing unique identities for agents, which allows for controlled access. This is important because inadequate access control and guardrails have been identified as significant barriers to the adoption of agents, leading to a lack of trust in these systems. By incorporating identity and access management from the outset, Escardio helps ensure that security is not treated as an afterthought, thereby facilitating the production readiness of agents.",multi_hop_specific_query_synthesizer
What role does Geethika play in the discussion about securing agent AI and identity access management?,"[""<1-hop>\n\n## [10.80s] Overview of Previous Discussion\nIn the first video of this series, Geethika discussed some of the capabilities already introduced for securing agent AI. Today's session will take a step back to explore concepts around identity access management for agent AI, providing real-world examples and discussing why traditional identity management will not suffice for securing agent AI.\n\n## [41.44s] Guest Introduction\nGeethika is joined by Rania Khalaf, the Chief AI Officer, and Ayesha Disanayake, who leads the R&D effort for identity access management for agentic AI.\n\n## [61.92s] Understanding Agentic AI\nRania begins by explaining the basics of agentic AI and providing real-world examples. She notes that with the advent of foundation models and generative AI, there has been a significant improvement in conversational AI. Initially, many applications embedded calls to generative AI systems, focusing primarily on question answering and natural language processing. For instance, ChatGPT is an application that utilizes the GPT family of models to facilitate interaction. Another example is Gmail, where users can refine their messages with the help of Gemini.""]",Geethika plays a pivotal role in the discussion about securing agent AI and identity access management by introducing the capabilities already established for securing agent AI and facilitating the exploration of concepts around identity access management for agent AI. She is joined by experts like Rania Khalaf and Ayesha Disanayake to provide real-world examples and discuss the inadequacy of traditional identity management for securing agent AI.,multi_hop_specific_query_synthesizer
How does Vertical AI provide a competitive advantage in the healthcare industry through domain expertise and regulatory compliance?,"['<1-hop>\n\n## [195.60s] Advantages of Vertical AI\nVertical AI offers several advantages, including:\n\n1. **Domain Expertise**: Vertical AI can deliver precision and relevance in critical applications.\n2. **Regulatory Alignment**: Industries such as healthcare, finance, and legal are highly regulated, necessitating strict adherence to data sharing and communication protocols.\n3. **Business Impact**: Vertical AI can drive automation and insights tailored to specific verticals, which generic solutions may not address.\n4. **Competitive Advantage**: Specialized tools designed for specific requirements provide a competitive edge.', '<2-hop>\n\n### [518.96s] Value Additions of Vertical AI\nThe vertical AI layer includes several value additions, such as:\n\n- **Industry-Specific Model Adaptation**: Tailored knowledge and terminology relevant to healthcare customers.\n- **Proprietary Data Utilization**: Incorporation of industry-specific workflows and decision-making logic that aligns with established processes.\n- **Seamless Integration**: The ability to connect with industry-specific systems, such as healthcare systems and open banking APIs.\n- **Regulatory Compliance**: Development of API products that adhere to industry regulations, ensuring that the solutions are both effective and compliant.']","Vertical AI provides a competitive advantage in the healthcare industry by leveraging domain expertise to deliver precision and relevance in critical applications. This specialization allows for the development of industry-specific model adaptations that incorporate tailored knowledge and terminology relevant to healthcare customers. Additionally, Vertical AI ensures regulatory compliance by developing API products that adhere to industry regulations, which is crucial in highly regulated sectors like healthcare. This alignment with regulatory standards not only ensures the effectiveness of the solutions but also their compliance, further enhancing the competitive edge of Vertical AI in the healthcare industry.",multi_hop_specific_query_synthesizer
How GPT-4 show its power in AI and what it do with tests like SAT and US medical exam?,"['<1-hop>\n\n## [136.08s] Key Innovations in AI\nThe first key innovation is the increasing power of AI models, which are becoming more expert-like. For instance, models like GPT-4 have demonstrated the ability to achieve high scores on tests such as the SAT and the US medical exam. Additionally, reasoning capabilities are improving, as evidenced by advancements in prompting techniques that are no longer necessary for these advanced models.\n\nThe second innovation pertains to agentic capabilities, where agents can reason, act, and perform tasks autonomously. The third area of improvement is multi-modality, which extends beyond text to include advancements in video and voice interactions, making them more natural and real-time.']","GPT-4 demonstrates its power in AI by achieving high scores on tests such as the SAT and the US medical exam. This showcases its expert-like capabilities and improved reasoning abilities, which are part of the key innovations in AI models.",multi_hop_specific_query_synthesizer
"How does WSO2's 'AI for Code' initiative enhance developer experiences in the healthcare sector, and what specific standards does it support?","['<1-hop>\n\n## [649.52s] WSO2 Solutions Team Initiatives\nThe solutions team at WSO2 is actively engaged in this sector, although they do not provide a full AI solution. Instead, they focus on two main areas. The first is ""AI for Code,"" which offers developer-focused capabilities designed to enhance developer experiences and productivity throughout the software development life cycle. The second area is ""Code for AI,"" where they provide programming abstractions and building blocks that can be utilized to create custom AI solutions.\n\n### [715.12s] AI for Code\nAn example of ""AI for Code"" can be seen in the integration capabilities developed by the WSO2 solutions team. In the healthcare sector, they support various standards such as FHIR, HL7, X12, CDA, and decom messages, along with pre-built translations between these standards. In the banking sector, they support ISO 853, ISO 222 (also known as MX messages), and Swift MT messages, with pre-built translations for Swift MT to MX.\n\nThe integration solution includes a co-pilot that developers can use. This co-pilot is a generic or horizontal AI, but for healthcare and banking requirements, WSO2 has developed vertical AIs. For instance, the healthcare co-pilot is designed to understand healthcare-related prompts. It is aware of standards such as FHIR and EHR systems, and it utilizes the available libraries and solutions to address healthcare-specific requirements.', '<2-hop>\n\n## [44.88s] WSO2\'s AI Strategy\nWSO2\'s AI strategy consists of two main components. The first is termed ""AI for Code,"" which focuses on enhancing the developer experience by integrating capabilities and features into their products. The second component, ""Code for AI,"" is centered around building AI applications and identifying the necessary abstractions for their development.\n\n# [85.12s] Evolution of AI Agents\nToday, Malit will discuss the evolution of AI agents. He emphasizes that this presentation will summarize key innovations driving the current adaptation of AI, referencing an article published by McKinsey.']","WSO2's 'AI for Code' initiative enhances developer experiences in the healthcare sector by integrating capabilities that support various healthcare standards. Specifically, it supports standards such as FHIR, HL7, X12, CDA, and decom messages. Additionally, it provides pre-built translations between these standards, facilitating easier and more efficient development processes for healthcare applications. The initiative includes a co-pilot designed to understand healthcare-related prompts and utilize available libraries and solutions to address healthcare-specific requirements.",multi_hop_specific_query_synthesizer
How does the Model Context Protocol (MCP) standardize integration processes and facilitate reusable code in healthcare AI applications?,"['<1-hop>\n\n## [2741.04s] Technologies for Building Integrations\nTo develop and deploy general integrations, we can utilize the WSU IP pass, which supports the integration and deployment of various workflows, including agents and RAG. Developers can use their preferred programming languages and frameworks, such as Python, Semantic Kernel, or LangChain, to build and deploy these integrations.\n\n# [2786.08s] Standardizing Integration Processes\nNext, we will discuss how to standardize the integration of LLMs with external data and APIs. The Model Context Protocol (MCP) serves as a framework for this standardization, allowing for seamless connections between tools, resources, and prompts.', ""<2-hop>\n\n## [2846.24s] Overview of the Model Context Protocol\nThe MCP provides a universal port for agents and general integrations, facilitating the connection of data and APIs with minimal effort. It standardizes how tools, resources, and prompts interact, ensuring consistency across various applications.\n\n### [2859.44s] Components of MCP\nTools refer to API calls and database queries, while resources encompass data files and contextual information. Prompts are templates that guide the LLM's responses, allowing for reuse across different applications.\n\n**Time Range: 00:50:02 - 01:00:02**\n\n# [3002.40s] Importance of Reusable Code in Client Connections\nWhen multiple hosts attempt to connect to the same data source, it becomes crucial to avoid redundant coding practices. Writing the same code repeatedly for each client can be tedious and inefficient. While some instances may involve simple code, others can require more complex and lengthy implementations. Additionally, ensuring best practices in the code is essential for production readiness. \n\nTo streamline this process, one can create a Managed Code Platform (MCP) server, allowing all clients and hosts to reuse the same logic. This approach is akin to the use of APIs, where reusable segments of code are created and integrated into a monolithic architecture. APIs are deployed and created only once, which simplifies the integration process.""]","The Model Context Protocol (MCP) standardizes integration processes by providing a universal port for agents and general integrations, which facilitates the connection of data and APIs with minimal effort. It ensures consistency across various applications by standardizing how tools, resources, and prompts interact. Tools refer to API calls and database queries, resources encompass data files and contextual information, and prompts are templates that guide the LLM's responses. Additionally, MCP supports the creation of a Managed Code Platform server, allowing all clients and hosts to reuse the same logic, akin to the use of APIs. This approach avoids redundant coding practices and simplifies the integration process, which is crucial for developing and implementing advanced tools in healthcare AI applications.",multi_hop_specific_query_synthesizer
"How does the H-LoRA mechanism, as described by Luo et al. 2024a, enhance the integration of comprehension and generation tasks in healthcare AI models?","['<1-hop>\n\nTo address the needs of various tasks, the hidden states\nare divided into two types: (i) Concrete-grained features\nFCon = {f1, f2, . . . , fk}, k < L, derived from the shal-\nlower layers of ViT, containing sufficient global features,\nsuitable for generation tasks; (ii) Abstract-grained features\nFAbs = {fk+1, fk+2, . . . , fL}, derived from the deeper\nlayers of ViT, which contain abstract semantic information\ncloser to the text space, suitable for comprehension tasks.\nThe task type T (comprehension or generation) deter-\nmines which set of features is selected as the input for the\ndownstream large language model:\nFimg\nT =\n(\nFCon, if T = generation task\nFAbs, if T = comprehension task (6)\nWe integrate the image featuresFimg\nT and text featuresT into\na joint sequence through simple concatenation, which is then\nfed into the LLM Mllm for autoregressive generation.\n4.3 Heterogeneous Knowledge Adaptation\nWe devise H-LoRA, which stores heterogeneous knowledge\nfrom comprehension and generation tasks in separate mod-\nules and dynamically routes to extract task-relevant knowl-\nedge from these modules. At the task level, for each task type\nT, we dynamically assign a dedicated H-LoRA submodule\nθT , which is expressed as:\nR = MLLM(U|θ, θT ), θ T = {AT , BT , RT\nouter}. (7)\nAt the feature level for a single task, H-LoRA integrates the\nidea of Mixture of Experts (MoE) (Masoudnia and Ebrahim-\npour 2014) and designs an efficient matrix merging and rout-\ning weight allocation mechanism, thus avoiding the signif-\nicant computational delay introduced by matrix splitting in\nexisting MoELoRA (Luo et al. 2024a). Specifically, we first\nmerge the low-rank matrices (rank = r) of k LoRA experts\ninto a unified matrix:\nAmerged, Bmerged = Concat({Ai}k\n1 ), Concat({Bi}k\n1 ), (8)\nwhere Amerged ∈ Rdin×rk and Bmerged ∈ Rrk×dout\n. The\nk-dimension routing layer generates expert weights W ∈\nRtoken num×k based on the input hidden state x, and these are\nexpanded to Rtoken num×rk as follows:\nWexpanded = αkW/r ⊗ 1r, (9)\nwhere ⊗ denotes the replication operation. The overall out-\nput of H-LoRA is computed as:\nOH-LoRA = (xAmerged ⊙ Wexpanded)Bmerged, (10)\nwhere ⊙ represents element-wise multiplication. Finally, the\noutput of H-LoRA is added to the frozen pre-trained weights\nto produce the final output:\nO = xW0 + OH-LoRA. (11)\n900\n800\n700\n600\n500\n400\n300\n200\n100\n0\nComp. Gen.\n(a) (b)\n783K765K\n（K）\nFigure 4: Data statistics of VL-Health.\n4.4 Training Pipeline\n1st Stage: Multi-modal Alignment. In the first stage, we\ndesign separate visual adapters and H-LoRA submodules for\nmedical unified tasks. For the medical comprehension task,\nwe train abstract-grained visual adapters using high-quality\nimage-text pairs to align visual embeddings with textual\nembeddings, thereby enabling the model to accurately de-\nscribe medical visual content. During this process, the pre-\ntrained LLM and its corresponding H-LoRA submodules\nremain frozen. In contrast, the medical generation task re-\nquires training concrete-grained adapters and H-LoRA sub-\nmodules while keeping the LLM frozen. Meanwhile, we ex-\ntend the textual vocabulary to include multimodal tokens,\nenabling the support of additional VQGAN vector quanti-\nzation indices. The model trains on image-VQ pairs, en-\ndowing the pre-trained LLM with the capability for image\nreconstruction. This design ensures pixel-level consistency\nof pre- and post-LVLM. The processes establish the initial\nalignment between the LLM’s outputs and the visual inputs.\n2nd Stage: Heterogeneous H-LoRA Plugin Adaptation.\nThe submodules of H-LoRA share the word embedding\nlayer and output head but may encounter issues such as\nbias and scale inconsistencies during training across dif-\nferent tasks. To ensure that the multiple H-LoRA plugins\nseamlessly interface with the LLMs and form a unified base,\nwe fine-tune the word embedding layer and output head us-\ning a small amount of mixed data to maintain consistency\nin the model weights. Specifically, during this stage, all H-\nLoRA submodules for different tasks are kept frozen, with\nonly the word embedding layer and output head being op-\ntimized. Through this stage, the model accumulates foun-\ndational knowledge for unified tasks by adapting H-LoRA\nplugins.\n3rd Stage: Visual Instruction Fine-Tuning. In the third\nstage, we introduce additional task-specific data to fur-\nther optimize the model and enhance its adaptability to\ndownstream tasks such as medical visual comprehension\n(e.g., medical QA, medical dialogues, and report generation)\nor generation tasks (e.g., super-resolution, denoising, and\n5']","The H-LoRA mechanism, as described by Luo et al. 2024a, enhances the integration of comprehension and generation tasks in healthcare AI models by storing heterogeneous knowledge from these tasks in separate modules and dynamically routing to extract task-relevant knowledge. For each task type, a dedicated H-LoRA submodule is dynamically assigned, which integrates the idea of Mixture of Experts (MoE) to efficiently manage matrix merging and routing weight allocation. This avoids significant computational delays associated with matrix splitting in existing models. The mechanism allows for the merging of low-rank matrices of LoRA experts into a unified matrix, and the routing layer generates expert weights based on the input hidden state. The output of H-LoRA is then added to the frozen pre-trained weights to produce the final output, ensuring efficient task-specific adaptation and integration.",multi_hop_specific_query_synthesizer
What Arshad say about AI and jobs?,"['<1-hop>\n\n# [1358.80s] Conclusion and Reflection\nIn conclusion, it is important to acknowledge the current apprehension surrounding AI, with concerns about its potential to replace jobs and industries. However, innovation should be viewed as an opportunity rather than a threat. This perspective is encapsulated in a quote by Steve Jobs, which remains highly relevant today. Thank you very much for your attention.\n\n**Time Range: 00:00:03 - 00:10:07**\n\n# [3.76s] Introduction\nIn this session, the speakers, Arshad and Aisha, welcome everyone and express their hope that the audience is ready to get started. They are here to discuss how to govern and secure AI services in a scalable manner.']","In the session, Arshad, along with Aisha, welcomed everyone and expressed their hope that the audience was ready to get started. They were there to discuss how to govern and secure AI services in a scalable manner. The conclusion highlighted the current apprehension surrounding AI, with concerns about its potential to replace jobs and industries, but emphasized that innovation should be viewed as an opportunity rather than a threat.",multi_hop_specific_query_synthesizer
"How does the model failover policy involving GPT-4 ensure high-quality responses, and what security measures are in place to protect connections between businesses and AI models like GPT-4?","['<1-hop>\n\n## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.', '<2-hop>\n\n## [2096.80s] Identity Representation and Security\nThis system introduced an extension to existing standards, enabling the identification of actions taken by agents on behalf of users. The staff allocation agent operated using its own token, proving its identity to the Guardio system and making API calls to backend services. This structure ensures that all users, applications, and agents have distinct identifications within the ecosystem.\n\n### [1024.40s] Securing AI Model Connections\nThe AI model, which could be based on various providers such as GPT-4, introduces another layer of security considerations. Connections between the business and the external AI model must be secured, and this is where governance layers and guardrails, as previously discussed, become critical.']","The model failover policy involving GPT-4 ensures high-quality responses by initially routing user requests to GPT-4, which provides informative and high-quality responses. Once the personal quota is exceeded, the system falls back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. This policy is managed by an AI gateway that routes requests to a primary endpoint until it is exhausted, then falls back to a secondary endpoint. To protect connections between businesses and AI models like GPT-4, security measures are implemented, including governance layers and guardrails. These measures ensure that connections are secure, and the identity of actions taken by agents on behalf of users is clearly represented and authenticated within the ecosystem.",multi_hop_specific_query_synthesizer
"How does Malit contribute to the evolution of AI agents, and what role does WSO2's AI strategy play in enhancing the development of AI applications?","['<1-hop>\n\n## [44.88s] WSO2\'s AI Strategy\nWSO2\'s AI strategy consists of two main components. The first is termed ""AI for Code,"" which focuses on enhancing the developer experience by integrating capabilities and features into their products. The second component, ""Code for AI,"" is centered around building AI applications and identifying the necessary abstractions for their development.\n\n# [85.12s] Evolution of AI Agents\nToday, Malit will discuss the evolution of AI agents. He emphasizes that this presentation will summarize key innovations driving the current adaptation of AI, referencing an article published by McKinsey.']","Malit contributes to the evolution of AI agents by summarizing key innovations that drive the current adaptation of AI, as referenced in an article published by McKinsey. This presentation highlights the advancements and changes in AI agents over time. WSO2's AI strategy complements this by focusing on two main components: 'AI for Code,' which enhances the developer experience by integrating AI capabilities into their products, and 'Code for AI,' which is centered around building AI applications and identifying necessary abstractions for their development. Together, these efforts contribute to the broader evolution and implementation of AI technologies.",multi_hop_specific_query_synthesizer
"Howw doess the use of a large language model (LLM) in generative AI contribute to AI transformation, and what are the implications for businesses that fail to adapt to these new capabilities?","['<1-hop>\n\n## [77.52s] Understanding AI Transformation\nAI transformation is a term that, while not universally adopted, is gaining traction in discussions about enhancing business operations. The fundamental idea is to leverage AI to improve various aspects of an organization, leading to increased productivity, efficiency, and user experience. Additionally, AI can unlock new capabilities that were previously unattainable.\n\nAI has emerged as a powerful tool, particularly with the advent of generative AI. This technology allows us to create solutions that were once complex and resource-intensive, such as chatbots. Previously, developing a chatbot required extensive rule-based or knowledge-based systems. Now, it is as simple as writing a prompt and connecting to a large language model (LLM) with minimal financial investment.\n\nThe current landscape presents numerous opportunities, and businesses must adapt to these new capabilities to remain competitive. Failing to embrace AI transformation could result in falling behind in a rapidly evolving market, where many organizations are striving to enhance their operations through AI.']","The use of a large language model (LLM) in generative AI significantly contributes to AI transformation by simplifying the creation of complex solutions, such as chatbots, which previously required extensive rule-based or knowledge-based systems. This transformation allows businesses to enhance productivity, efficiency, and user experience with minimal financial investment. The implications for businesses that fail to adapt to these new capabilities are severe, as they risk falling behind in a rapidly evolving market where many organizations are leveraging AI to improve their operations.",multi_hop_specific_query_synthesizer
How GPT-4 do on tests and what happens when quota exceeded?,"['<1-hop>\n\n## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.', '<2-hop>\n\n## [136.08s] Key Innovations in AI\nThe first key innovation is the increasing power of AI models, which are becoming more expert-like. For instance, models like GPT-4 have demonstrated the ability to achieve high scores on tests such as the SAT and the US medical exam. Additionally, reasoning capabilities are improving, as evidenced by advancements in prompting techniques that are no longer necessary for these advanced models.\n\nThe second innovation pertains to agentic capabilities, where agents can reason, act, and perform tasks autonomously. The third area of improvement is multi-modality, which extends beyond text to include advancements in video and voice interactions, making them more natural and real-time.']","GPT-4 has demonstrated the ability to achieve high scores on tests such as the SAT and the US medical exam, showcasing its increasing power and expert-like capabilities. However, when a user's personal quota for GPT-4 is exceeded, they may receive responses from a less capable version, such as GPT-4 Mini, resulting in subpar responses.",multi_hop_specific_query_synthesizer
"How does the integration of H-LoRA in HealthGPT enhance its performance in medical comprehension and generation tasks, and what are the benefits compared to MoELoRA?","['<1-hop>\n\nFigure 3: The HealthGPT architecture integrates hierarchical visual perception and H-LoRA, employing a task-specific hard\nrouter to select visual features and H-LoRA plugins, ultimately generating outputs with an autoregressive manner.\na design paradigm based on ViT, alignment adapters, and\npre-trained LLMs(Liu et al. 2023, 2024b), enabling quick\nadaptation to downstream tasks.\nVQGAN. VQGAN (Esser, Rombach, and Ommer 2021)\nemploys latent space compression and indexing mechanisms\nto effectively learn a complete discrete representation of im-\nages. VQGAN first maps the input imageximg to a latent rep-\nresentation z = E(x) through a encoder E. Then, the latent\nrepresentation is quantized using a codebookZ = {zk}K\nk=1,\ngenerating a discrete index sequence I = [im]N\nm=1, where\nim ∈ Zrepresents the quantized code index:\nI = Quantize(z|Z) = arg min\nzk∈Z\n∥z − zk∥2. (2)\nIn our approach, the discrete index sequence I serves as\na supervisory signal for the generation task, enabling the\nmodel to predict the index sequence ˆI from input conditions\nsuch as text or other modality signals. Finally, the predicted\nindex sequence ˆI is upsampled by the VQGAN decoder G,\ngenerating the high-quality image ˆximg = G(ˆI).\nLow Rank Adaptation. LoRA(Hu et al. 2021) effectively\ncaptures the characteristics of downstream tasks by intro-\nducing low-rank adapters. The core idea is to decompose\nthe bypass weight matrix ∆W ∈ Rdin×dout\ninto two low-\nrank matrices {A ∈ Rdin×r, B ∈ Rr×dout\n}, where r ≪\nmin{din, dout}, significantly reducing learnable parameters.\nThe output with the LoRA adapter for the input x is then\ngiven by:\nh = xW0 + αx∆W/r = xW0 + αxAB/r, (3)\nwhere matrix A is initialized with a Gaussian distribution,\nwhile the matrixB is initialized as a zero matrix. The scaling\nfactor α/r controls the impact of ∆W on the model.\n4 HealthGPT\n4.1 Unified Autoregressive Generation.\nHealthGPT (Figure 3) utilizes a discrete token representa-\ntion that covers both text and visual outputs, unifying visual\ncomprehension and generation as an autoregressive task. For\ncomprehension, Mllm receives the input joint sequence U\nand outputs a series of text token R = [ r1, r2, . . . , rNr ],\nwhere ri ∈ Vtxt, and Vtxt represents the LLM’s vocabulary:\nPθ(R | U) =\nNrY\ni=1\nPθ(ri | U, r<i). (4)\nFor generation, Mllm first receives a special start token\n⟨START IMG⟩, then generates a series of tokens corre-\nsponding to the VQGAN indices I = [ i1, i2, . . . , iNi ],\nwhere ij ∈ Vvq, and Vvq represents the index range of VQ-\nGAN. Upon completion of generation, the LLM outputs an\nend token ⟨END IMG⟩:\nPθ(I | U) =\nNiY\nj=1\nPθ(ij | U, i<j). (5)\nFinally, the generated index sequence I is fed into the de-\ncoder G, which reconstructs the target image ˆximg = G(I).\n4.2 Hierarchical Visual Perception\nGiven the differences in visual perception between compre-\nhension and generation tasks—where the former focuses on\nabstract semantics and the latter emphasizes complete se-\nmantics—we employ ViT to compress the image into dis-\ncrete visual tokens at multiple hierarchical levels. Specif-\nically, the image is converted into a series of features\n{f1, f2, . . . , fL} as it passes through L ViT blocks.\n4', '<2-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","The integration of H-LoRA in HealthGPT enhances its performance in medical comprehension and generation tasks by effectively capturing the characteristics of downstream tasks through low-rank adapters. H-LoRA decomposes the bypass weight matrix into two low-rank matrices, significantly reducing learnable parameters and avoiding additional training delays. Compared to MoELoRA, H-LoRA performs better without incurring extra training time, even as the number of experts increases. This is evident from experiments showing that while MoELoRA's training time significantly increases with more experts, H-LoRA maintains consistent performance and training time. Additionally, H-LoRA's integration into HealthGPT supports a unified model approach, mitigating performance degradation typically caused by generation tasks and achieving optimal results across various sub-tasks. This makes HealthGPT with H-LoRA particularly effective in medical scenarios, as demonstrated by its superior performance in medical comprehension and generation tasks.",multi_hop_specific_query_synthesizer
How Model Context Protocol help with AI integration and why it important for generative AI?,"['<1-hop>\n\n## [2741.04s] Technologies for Building Integrations\nTo develop and deploy general integrations, we can utilize the WSU IP pass, which supports the integration and deployment of various workflows, including agents and RAG. Developers can use their preferred programming languages and frameworks, such as Python, Semantic Kernel, or LangChain, to build and deploy these integrations.\n\n# [2786.08s] Standardizing Integration Processes\nNext, we will discuss how to standardize the integration of LLMs with external data and APIs. The Model Context Protocol (MCP) serves as a framework for this standardization, allowing for seamless connections between tools, resources, and prompts.', ""<2-hop>\n\n**Time Range: 00:00:03 - 00:10:04**\n\n# [3.76s] Introduction to AI and Generative AI\nGood morning, everybody. The focus of today's discussion is on artificial intelligence (AI), particularly generative AI. We will explore the significance of integration in building AI applications in the current landscape, especially with the rise of generative AI. This topic is crucial, and we will also cover common integration patterns associated with generative AI.\n\n## [42.32s] The Need for Retrieval-Augmented Generation\nIn addition to integration patterns, we will delve into the necessity of retrieval-augmented generation. This will be discussed in detail, along with the concept of agents, which is a hot topic in the AI community today. We will also examine the importance of the Model Context Protocol (MCP) and the responsibility that comes with building effective AI applications. It is essential that AI systems are designed with certain guardrails and governance in mind. We will touch upon the concept of zero trust design for AI agents, which, while traditionally applied to other domains, is now being adapted for AI.""]","The Model Context Protocol (MCP) helps with AI integration by serving as a framework for standardizing the integration of large language models (LLMs) with external data and APIs, allowing for seamless connections between tools, resources, and prompts. It is important for generative AI because it supports the integration and deployment of workflows, including agents and retrieval-augmented generation (RAG), which are crucial for building effective AI applications. Additionally, MCP ensures that AI systems are designed with guardrails and governance, which is essential for responsible AI development.",multi_hop_specific_query_synthesizer
How Guard AI help with PII masking?,"['<1-hop>\n\n## [3331.68s] Regex-Based PII Masking\nRegex-based PII (Personally Identifiable Information) masking allows users to define patterns, such as email addresses, that must not be matched in outgoing prompts. If an email is detected, the system replaces it with a dummy value, ensuring that sensitive information is not exposed while still allowing the LLM to function normally.\n\n## [3397.12s] Advanced PII Detection and Masking\nFor more ambiguous cases, advanced PII detection and masking techniques are employed. This involves using a framework called Guard AI, which utilizes LLMs to make decisions and perform reasoning. This combination of regex and advanced detection provides robust security for the egress gateway, preventing sensitive information from being leaked to the LLM.']","Guard AI helps with PII masking by utilizing LLMs to make decisions and perform reasoning in more ambiguous cases, providing advanced PII detection and masking techniques. This ensures robust security for the egress gateway, preventing sensitive information from being leaked to the LLM.",multi_hop_specific_query_synthesizer
What role does Rania Khalaf play in the discussion about agentic AI and identity access management?,"[""<1-hop>\n\n## [10.80s] Overview of Previous Discussion\nIn the first video of this series, Geethika discussed some of the capabilities already introduced for securing agent AI. Today's session will take a step back to explore concepts around identity access management for agent AI, providing real-world examples and discussing why traditional identity management will not suffice for securing agent AI.\n\n## [41.44s] Guest Introduction\nGeethika is joined by Rania Khalaf, the Chief AI Officer, and Ayesha Disanayake, who leads the R&D effort for identity access management for agentic AI.\n\n## [61.92s] Understanding Agentic AI\nRania begins by explaining the basics of agentic AI and providing real-world examples. She notes that with the advent of foundation models and generative AI, there has been a significant improvement in conversational AI. Initially, many applications embedded calls to generative AI systems, focusing primarily on question answering and natural language processing. For instance, ChatGPT is an application that utilizes the GPT family of models to facilitate interaction. Another example is Gmail, where users can refine their messages with the help of Gemini.""]","Rania Khalaf, as the Chief AI Officer, participates in the discussion by explaining the basics of agentic AI and providing real-world examples. She highlights the improvements in conversational AI with the advent of foundation models and generative AI, such as ChatGPT and Gmail's message refinement feature.",multi_hop_specific_query_synthesizer
"How does HuatuoGPT-Vision perform in the OmniMedVQA benchmark compared to other models, and what are its capabilities in modality transformation tasks?","['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15', '<2-hop>\n\nC.6 Case Study\nFigures 11 and 12 illustrate examples of modality transformation and super-resolution reconstruction. In Figure 11, the results\ngenerated by our method in the CT (MRI) to MRI (CT) transformation task are highly close to the ground truth, effectively\nguiding the model in the transformation across different regions. For the MRI super-resolution reconstruction task, Figure 12\ndemonstrates the accuracy of our method in restoring scan image details, accurately reconstructing the essential details of the\nimage.\nTable 11: The experimental results for the four reconstruction tasks.\nCT(Brain) CT(Pelvis) MRI (Brain) MRI(Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\nSEED-X 20.18 27.66 112.11 21.53 28.02 102.87 4.90 27.62 112.86 6.31 27.89 106.21\nUnified-IO 2 83.93 36.09 17.95 85.36 35.10 25.46 87.50 34.25 25.47 86.31 33.53 29.80\nHealthGPT-M3 91.73 36.42 15.46 94.26 37.30 12.53 88.76 33.97 27.05 84.40 33.11 32.62\n34.08\n15.87\n9.16\n5.62\n13.33\n21.94\nHealthGPT\nLLaVA-Med\nHuatuoGPT-Vision\nLlama-3.2\nInternVL-2\nShow-o\nHuman\nEvaluation\n(a) (b)\nFigure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.\n17']","HuatuoGPT-Vision, with 7 billion parameters, performs notably well in the OmniMedVQA benchmark, achieving an average score of 50.0. It excels in various medical imaging modalities such as CT, X-ray, and MRI, outperforming several other models like Med-Flamingo and LLaV A-Med. In modality transformation tasks, HuatuoGPT-Vision demonstrates high accuracy, effectively guiding the transformation between CT and MRI images, as shown in the case study. This capability is highlighted by its ability to produce results that closely match the ground truth, ensuring accurate transformation across different anatomical regions.",multi_hop_specific_query_synthesizer
"How does ChatGPT, as a large language model, contribute to the advancements in conversational AI, and what role does it play in the context of agentic AI and identity access management?","['<1-hop>\n\n## [115.60s] Defining Key Terminologies\nBefore we proceed, it is important to define some key terminologies. AI refers to any system that can simulate human intelligence. This can range from simple functions to complex machine learning models and deep learning architectures. Generative AI, a subset of AI, focuses on creating original content, which can include text, audio, and visual elements.\n\n### [155.28s] Understanding Large Language Models\nLarge language models (LLMs), such as ChatGPT from OpenAI, are examples of generative AI that specialize in natural language processing. They are designed to understand and generate text, making them a significant advancement in the field.', ""<2-hop>\n\n## [10.80s] Overview of Previous Discussion\nIn the first video of this series, Geethika discussed some of the capabilities already introduced for securing agent AI. Today's session will take a step back to explore concepts around identity access management for agent AI, providing real-world examples and discussing why traditional identity management will not suffice for securing agent AI.\n\n## [41.44s] Guest Introduction\nGeethika is joined by Rania Khalaf, the Chief AI Officer, and Ayesha Disanayake, who leads the R&D effort for identity access management for agentic AI.\n\n## [61.92s] Understanding Agentic AI\nRania begins by explaining the basics of agentic AI and providing real-world examples. She notes that with the advent of foundation models and generative AI, there has been a significant improvement in conversational AI. Initially, many applications embedded calls to generative AI systems, focusing primarily on question answering and natural language processing. For instance, ChatGPT is an application that utilizes the GPT family of models to facilitate interaction. Another example is Gmail, where users can refine their messages with the help of Gemini.""]","ChatGPT, as a large language model developed by OpenAI, is a significant advancement in the field of generative AI, specializing in natural language processing. It contributes to conversational AI by enabling sophisticated text understanding and generation, which enhances interaction capabilities. In the context of agentic AI, ChatGPT is utilized to facilitate interaction through its conversational abilities, as noted by Rania Khalaf. The integration of such generative AI systems into applications has improved question answering and natural language processing tasks. However, the discussion led by Geethika and Ayesha Disanayake highlights that traditional identity management is insufficient for securing agent AI, indicating the need for advanced identity access management solutions to address the unique challenges posed by these AI systems.",multi_hop_specific_query_synthesizer
"How do observability and logging policies contribute to the implementation of guardrails in AI systems, particularly in scenarios where inappropriate queries, such as those related to firearms, are posed?","['<1-hop>\n\n## [4142.16s] Observability and Logging\nFinally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant.\n\n**Time Range: 01:10:00 - 01:18:25**\n\n# [4200.40s] Introduction to API Usage with Guardrails\nBefore attempting to use the API with Guardrails, it is essential to understand how a use case would appear without these protective measures. In this demonstration, a query related to firearms is posed, which is not an appropriate topic for a hotel assistant.']","Observability and logging policies contribute to the implementation of guardrails in AI systems by ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant. In scenarios where inappropriate queries, such as those related to firearms, are posed, these policies help in identifying and managing such interactions, thereby maintaining the integrity and appropriateness of the AI system's responses.",multi_hop_specific_query_synthesizer
How does Anthropic contribute to the development of vertical AI frameworks in healthcare?,"['<1-hop>\n\n## [3340.72s] Custom Integration Development\nFor more customized solutions, such as triggering events from an FTP server, coding may be necessary. Although a new integration was not built during this session, a pre-existing integration was demonstrated to save time.\n\n## [474.56s] Trade-offs in AI Development\nThe conversation continues with a focus on the trade-offs involved in AI development. The moderator points out that teams often face decisions between optimizing for accuracy, latency, and cost. Alan Shmal responds by highlighting the three key metrics that matter: speed, quality, and cost. He explains that early in AI projects, engineers tend to prioritize accuracy to avoid user complaints about poor performance. However, this can lead to the use of expensive models that may not be efficient in terms of latency and cost.\n\nAlan shares his experience with high-quality models, such as those from Anthropic, which provide excellent reasoning but come with high operational costs. He notes the importance of balancing the need for speed in conversational assistants with the efficiency of the models used, ultimately leading to a focus on reducing latency while maintaining quality.', '<2-hop>\n\n### [350.72s] Framework for Vertical AI\nThe vertical AI layer is built on existing frameworks, utilizing core large language models (LLMs) from companies like OpenAI, Anthropic, and Gemini. These foundational models serve as the base for horizontal AI applications. On top of this, supporting frameworks such as retrieval-augmented generation (RAG) and data infrastructure are integrated. The vertical layer introduces industry-specific model tuning and regulatory compliance, ensuring that the AI solutions are tailored to meet the unique needs of specific sectors.\n\n## [424.88s] Example: Healthcare Customer Support\nTo illustrate the effectiveness of vertical AI, consider a healthcare customer support requirement. At the foundational level, general-purpose LLMs provide basic language capabilities. Companies like Sierra and Decagon enhance these capabilities with frameworks optimized for customer support. The vertical AI layer then adds the necessary clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems. Without this tailored vertical layer, the AI solution would lack the understanding of healthcare nuances and regulatory constraints essential for real-world deployment.']","Anthropic contributes to the development of vertical AI frameworks in healthcare by providing high-quality large language models (LLMs) that serve as the foundational base for these frameworks. These models are integrated into the vertical AI layer, which is tailored to meet the specific needs of the healthcare sector, including clinical expertise and regulatory compliance. This integration ensures that AI solutions are capable of understanding healthcare nuances and adhering to regulatory constraints, which are essential for effective deployment in real-world healthcare applications.",multi_hop_specific_query_synthesizer
How MCP server work with personalization agent in AI system?,"['<1-hop>\n\n# [4800.24s] Overview of MCP Server Configuration\nBy default, the configuration is set to two, but this particular MCP server only supports HTTP/1. This is something I confirmed through testing. You can edit the settings in local code or in pro code mode; either method works. Regardless of the approach taken, the diagram and the code remain in sync.\n\n## [4823.12s] Executing a Query\nThe system is currently running, and I should access the chat window. Here it is. We will proceed with our usual query: ""Plan me a trip for 5 days in Sri Lanka."" The system is taking some time to process the request. We will wait for the response, and then I will walk through the verbose logs.', ""<2-hop>\n\n## [651.84s] Personalization Agent\nA key component of the updated architecture is the personalization agent. This agent interacts with other components within the system. Upon receiving user consent, it utilizes the user's name and company information to conduct an internet search, thereby creating a personalized profile. The personalization agent employs two tools: the Surfer API, which retrieves a set of links relevant to the user, and the Scraper Web Scraper API, which scrapes content from those links. This process is iterative, continuing until the agent achieves its goal.\n\n## [720.96s] Introduction to MCP\nBefore delving into multi-agent systems, it is essential to briefly discuss the concept of the Multi-Component Protocol (MCP). The MCP standardizes how AI applications interact with external tools. The architecture of MCP includes concepts such as tools, resources, and prompts, which have been extensively discussed in AI labs.\n\nThe MCP introduces two new components to agent applications: the MCP client and the MCP server. The MCP client connects to the MCP host, allowing developers to access the MCP server without needing to write code for each individual tool connection. This simplifies the development process, enabling developers to focus on functionality rather than connectivity.""]","The MCP server, as part of the Multi-Component Protocol (MCP), standardizes interactions between AI applications and external tools. It simplifies the development process by allowing developers to access the MCP server without writing code for each tool connection. In the AI system, the personalization agent is a key component that interacts with other system components. It uses tools like the Surfer API and the Scraper Web Scraper API to create personalized profiles based on user consent. The MCP server supports these interactions by providing a standardized way for the personalization agent to connect with external resources and tools, thereby enhancing the system's functionality and personalization capabilities.",multi_hop_specific_query_synthesizer
How do AI agents utilize large language models for reasoning and what role do they play in creating personalized profiles without the need for retrieval-augmented generation?,"['<1-hop>\n\n## [2030.64s] The Functionality of AI Agents\nTo understand how AI agents operate, it is essential to recognize their components. An agent receives tasks from humans, has access to various tools (such as web services, APIs, and databases), and is connected to a large language model (LLM) for reasoning. Additionally, agents possess both short-term and long-term memory capabilities.\n\n### [2109.76s] Traits of AI Agents\nAI agents exhibit traits that enable them to reason, plan, act, learn, and adapt to their environment. They can also delegate tasks to other agents when necessary, leading to a multi-agent system, a concept that will be discussed in further detail in future sessions.', '<2-hop>\n\n## [2816.00s] Calling the LLM for Personalized Profiles\nWith the data structure established, the next step involves calling the LLM (Large Language Model) using the gathered data. The objective is to create a personalized profile for the user. This process does not require an agent or retrieval-augmented generation; instead, it focuses on directly utilizing the LLM.\n\nTo facilitate this, a connection to the model provider has been created. A prompt will be generated for the LLM, specifying the need for a personalized profile. It is crucial to be precise in the prompt to ensure an accurate response. A comprehensive prompt has been prepared and will be used to guide the LLM in generating the desired output.']","AI agents utilize large language models (LLMs) for reasoning by connecting to them as part of their operational framework. These agents receive tasks from humans and use LLMs to process and reason through the information. In the context of creating personalized profiles, the LLM is directly called using gathered data to generate a profile without the need for an agent or retrieval-augmented generation. This process involves creating a precise prompt for the LLM to ensure an accurate response, highlighting the LLM's role in generating personalized outputs based on the provided data.",multi_hop_specific_query_synthesizer
How does the Egress AI Gateway help manage outgoing AI model interactions and what challenges does it address?,"['<1-hop>\n\n### [2605.04s] Egress AI Gateway Introduction\nThe egress AI gateway functions similarly to the ingress gateway, with a set of customized policies and rules enforced to ensure that all outgoing calls from the organization are properly governed and managed. This provides visibility into the interactions occurring outside the organization.\n\nFor instance, consider an AI-powered booking assistant and a staff allocation agent accessing different deployments of OpenAI in various regions. This scenario illustrates the complexity of tracking calls to different models and deployments, which can lead to hidden costs and management challenges. The egress AI gateway addresses these issues by sitting between backend systems and LLM services, ensuring proper governance.']","The Egress AI Gateway helps manage outgoing AI model interactions by enforcing customized policies and rules to ensure that all outgoing calls from the organization are properly governed and managed. It provides visibility into interactions occurring outside the organization, addressing challenges such as tracking calls to different models and deployments, which can lead to hidden costs and management difficulties. By sitting between backend systems and LLM services, it ensures proper governance.",multi_hop_specific_query_synthesizer
"How does LLaV A-Med enhance visual-text alignment in medical contexts, and how does it compare to HealthGPT in terms of performance on medical visual comprehension tasks?","['<1-hop>\n\ntential task interference. TLS: In the first and second stages,\ngiven the heterogeneity between comprehension and gener-\nation tasks, we first train H-LoRA plugins for HealthGPT\nto incorporate both medical comprehension and generation\nknowledge, thus endowing the LLMs with capabilities for\nvision-language alignment and vision-to-vision reconstruc-\ntion. Additionally, through minimal mixed-task training, we\nbuilt fusion embedding layers and output heads that merge\ntext and visual tokens, establishing a unified LVLM founda-\ntion for visual instruction fine-tuning. In the third stage, by\nonly training the H-LoRA plugins, HealthGPT is able to\nrapidly adapt to a wide range of downstream medical tasks,\ncovering various types of medical comprehension and gen-\neration tasks.\nTo effectively implement our approach, we have cu-\nrated a dataset for training unified medical LVLMs, called\nVL-Health, including seven comprehension tasks and five\ngeneration tasks (Figure 1). Through quantitative analysis\nand validation on multi-modal tasks, the results demonstrate\nthat HealthGPT is capable of unifying medical multi-\nmodal abilities in data-constrained scenarios, achieving per-\nformance comparable to or better than existing state-of-the-\nart (SOTA) models across multiple metrics. Overall, the\nmain contributions of this paper are summarized as follows:\n• Unified Med-LVLM. We introduce HealthGPT,\nwhich, to the best of our knowledge, is the first unified\nframework for multi-modal comprehension and genera-\ntion in complex medical scenarios.\n• Effective Learning Paradigm. We present H-LoRA, an\noptimized multi-LoRA PEFT architecture based on task-\ngated decoupling, is designed to effectively mitigate data\nconflict issues.\n• Holistic Training Dataset. We curated VL-Health, a\ncomprehensive dataset designed for both comprehension\nand generation tasks.\n• Superior Downstream Improvements : Extensive ex-\nperiments are conducted and the results confirm\nHealthGPT’s effectiveness in medical vision-language\ncomprehension and generation.\n2 Related Work\nMedical Vision Large Language Models. Recently, medi-\ncal vision large language models (Med-VLLMs) have made\nsignificant progress, demonstrating excellent performance\nin understanding medical images and responding to human\nqueries based on these images (Zhou et al. 2023; Tian et al.\n2023). XrayGPT (Thawkar et al. 2023) combines a med-\nical visual encoder (MedClip) (Wang et al. 2022) with a\nfine-tuned LLM , using a simple linear transformation layer\nto achieve alignment between visual and textual informa-\ntion, significantly enhancing the understanding of medical\nimages. On this basis, LLaV A-Med (Li et al. 2024b) fur-\nther enhances visual-text alignment in medical contexts by\nselecting high-quality image-text pairs from PubMed pa-\npers and synthesized VQA datasets. BiomedGPT (Luo et al.\n2024b) employs a BERT-style encoder and GPT-style de-\ncoder architecture, pre-trained on interdisciplinary datasets.\nCompared to commercial models like Med-PaLM (Singhal\net al. 2023), BiomedGPT significantly reduces model size\nwhile maintaining superior performance. However, issues\nof language adaptability and dataset specificity still remain.\nTo address these, HuatuoGPT-Vision (Chen et al. 2024a)\nintroduces the PubMedVision dataset, which contains 1.3\nmillion high-quality medical samples, significantly improv-\ning the model’s adaptability across diverse medical applica-\ntions. However, current Med-VLLMs mainly focus on med-\nical comprehension and lack the capability for the medical\nvision-language generation.\nUnified Visual Comprehension and Generation Mod-\nels. Recent research has increasingly concentrated on cre-\nating unified LVLMs that are adept at understanding and\nproducing content across various visual modalities. NExT-\nGPT (Wu et al. 2023) achieves perception and generation for\narbitrary combinations of multi-modal inputs and outputs by\naligning LLMs. Similarly, SEED (Ge et al. 2023), SEED-\nX (Ge et al. 2024), and DreamLLM (Dong et al. 2023) em-\nploy learnable queries and leverage next-token prediction to\ngenerate visual tokens, providing conditional inputs to exter-\nnal generation modules. Unlike these methods, which func-\ntion as external conditioners, Unified-IO (Lu et al. 2022),\nUnified-IO 2 (Lu et al. 2024), and Chameleon (Team 2024)\ninternalize multi-modal generation tasks within a unified\nTransformer architecture by extending multi-modal vocab-\nularies, enabling direct generation based on next-token pre-\ndiction. Building on this concept, Lumina-mGPT (Liu et al.\n2024a) and ANOLE (Chern et al. 2024) further enhance the\ngeneration capabilities of unified models using high-quality\ndata, particularly improving the quality and flexibility of im-\nage generation.\n3 Preliminaries\nLarge Vision-Language Models.The input to a LVLM typ-\nically consists of an image ximg and a discrete text sequence\nxtxt. The visual encoder Eimg converts the input image ximg\ninto a sequence of visual tokens V = [ vi]Nv\ni=1, while the\ntext sequence xtxt is mapped into a sequence of text to-\nkens T = [ ti]Nt\ni=1 using an embedding function Etxt. The\nLLM MLLM(·|θ) models the joint probability of the token\nsequence U = {V, T }, which is expressed as:\nPθ(R|U) =\nNrY\ni=1\nPθ(ri|{U, r<i}), (1)\nwhere R = [ri]Nr\ni=1 is the text response sequence. The LVLM\niteratively generates the next token ri based on r<i. The op-\ntimization objective is to minimize the cross-entropy loss of\nthe response R. It is worth noting that most LVLMs adopt\n3', '<2-hop>\n\nTable 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","LLaV A-Med enhances visual-text alignment in medical contexts by selecting high-quality image-text pairs from PubMed papers and synthesized VQA datasets. In terms of performance on medical visual comprehension tasks, LLaV A-Med achieves a score of 60.2 on VQA-RAD, 48.1 on SLAKE, and 58.4 on PathVQA. In comparison, HealthGPT-M3 and HealthGPT-L14 outperform LLaV A-Med with scores of 73.7 and 77.7 on VQA-RAD, 55.9 and 58.3 on SLAKE, and 74.6 and 76.4 on PathVQA, respectively, indicating superior performance in medical visual comprehension tasks.",multi_hop_specific_query_synthesizer
How does the integration of H-LoRA in HealthGPT enhance its performance on SLAKE and other medical visual comprehension tasks?,"['<1-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8', '<2-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","The integration of H-LoRA in HealthGPT enhances its performance on SLAKE and other medical visual comprehension tasks by consistently outperforming other methods in all scenarios, as demonstrated in the experimental results. H-LoRA's three-stage learning strategy effectively decouples comprehension and generation tasks, reducing performance degradation from task conflicts. This approach allows HealthGPT to achieve significant performance improvements across multiple medical comprehension and generation tasks, showcasing its potential for healthcare applications. Specifically, HealthGPT with H-LoRA achieves optimal or near-optimal results with an average score of 74.4, significantly surpassing other models. Additionally, H-LoRA incurs no additional training delay compared to LoRA, while outperforming MoELoRA, which faces significant training time increases as the number of experts grows.",multi_hop_specific_query_synthesizer
"How does HealthGPT-M3 outperform other models in medical visual comprehension and modality conversion tasks, and what are the specific metrics that highlight its effectiveness?","['<1-hop>\n\nTable 3: Comparison results of super-resolution task.\nModel SSIM↑ PSNR↑ MSE↓ LPIPS↓\nSRGAN 71.34 32.01 41.27 24.50\nDASR 71.57 32.34 38.25 19.17\nReal-ESRGAN 67.30 31.87 42.57 20.64\nLIIF 73.27 32.13 40.14 22.93\nBSRGAN 69.97 31.97 41.52 28.72\nHealthGPT-M3 78.19 32.76 34.47 12.02\nHealthGPT-L14 77.94 32.71 35.19 12.43\nFigure 5: Performance comparison of LoRA, MoELoRA,\nand H-LoRA under different rank settings.\net al. 2024b), Llama-3.2 (Dubey et al. 2024)). Addition-\nally, we test several SOTA unified visual comprehension\nand generation models, including Show-o (Xie et al. 2024),\nUnified-IO 2 (Lu et al. 2024), and Janus (Wu et al.\n2024). The experimental results are shown in Table 1, with\nthe following key observations: (i) SOTA Results Com-\npared with LVLMs: In medical visual comprehension\ntasks, HealthGPT demonstrates superior performance,\nsignificantly outperforming both medical-specific models\n(e.g., HuatuoGPT-Vision) and general-purpose models (e.g.,\nLlama-3.2). (ii) Surpassing Current Unified LVLMs: De-\nspite being trained on billions of data points, unified mod-\nels still exhibit poor generalization performance in medi-\ncal visual comprehension. For instance, Unified-IO 2 scored\nonly 33.8. In contrast,HealthGPT-M3, with only 3.8B pa-\nrameters, scored 61.3 on the medical multi-modal unified\ntask, significantly outperforming existing unified models in\nmedical downstream scenarios. (iii) Stable Improvement\nwith Large Base Model: Our method demonstrates excel-\nlent scalability, with HealthGPT-L14 achieving a score\nof 66.4 in the larger model configuration. This result signif-\nicantly outperforms all other models, highlighting the effec-\ntiveness of scaling up the base model for enhanced perfor-\nmance in medical tasks.\nGeneration. We study three key tasks in medical imag-\ning. (i) Modality Conversion: In this task, we focus on\nthe conversion between CT and MRI modalities for the\nbrain and pelvic regions, designing four specific sub-tasks.\nAll comparative models (Pix2Pix (Isola et al. 2017), Cy-\ncleGAN (Zhu et al. 2017), BBDM (Li et al. 2023a),\n(%)\n(%)\n（a） （b）\nFigure 6: The loss visualization (a) and performance com-\nparison (b) with respect to different visual perceptions.\nVmamba (Liu et al. 2024e), and DiffMa (Wang et al.\n2024b)) trained a separate model for each sub-task, while\nHealthGPT unify all tasks into a single training process.\nThe experimental results, shown in Table 11, demonstrate\nthat our approach outperforms other methods across multi-\nple evaluation metrics. For instance, in the CT2MRI-Brain\ntask, HealthGPT-M3 achieves an SSIM of 79.38, signif-\nicantly surpassing traditional methods like Pix2Pix (71.09)\nand the recent DiffMa (71.47). (ii) Super-Resolution: We\nconduct 4× super-resolution experiments on the IXI dataset,\nwith the results presented in Table 3. Notably, most exist-\ning methods fail to fully leverage the prior knowledge of key\nstructures in medical images, resulting in significant short-\ncomings in detail recovery. In contrast, our method signif-\nicantly mitigates this issue. Specifically, HealthGPT-M3\nexcels in key metrics such as SSIM, PSNR, and ISE, achiev-\ning scores of 78.19, 32.76, and 34.47, respectively. Ad-\nditionally, HealthGPT-M3 achieves the lowest score of\n12.34, further validating its exceptional performance in hu-\nman visual perception. (iii) Reconstruction: We compare\nHealthGPT-M3 with unified models with reconstruction\ncapabilities, such as Unified-IO 2 and SEED-X. The results\nshow that our approach performs better controllability for vi-\nsual reconstruction. We also trainHealthGPT-L14 with a\nsimilar number of trainable parameters to the M3 version.\nHence, the similar performance between the two models\nmeets our expectations. Details are in the Appendix.\n5.3 In-Depth Study\nEffect of Heterogeneous Low-Rank Adaptation.H-LoRA\nprovides an optimized multi-LoRA architecture for multi-\ntask learning. We conduct extensive validation of this struc-\nture, with results presented in Table 4, comparing the per-\nformance of LoRA, MoELoRA, and H-LoRA in medical\nunified comprehension and generation tasks. In the majority\nof comprehension tasks and all generation tasks, H-LoRA\ndemonstrates superior performance, particularly in the Om-\nniMedVQA benchmark, where it improved from 64.90 to\n68.50. Notably, despite some applications of MoELoRA in\ncertain scenarios, it do not show advantages in this task and\n7', '<2-hop>\n\nC.6 Case Study\nFigures 11 and 12 illustrate examples of modality transformation and super-resolution reconstruction. In Figure 11, the results\ngenerated by our method in the CT (MRI) to MRI (CT) transformation task are highly close to the ground truth, effectively\nguiding the model in the transformation across different regions. For the MRI super-resolution reconstruction task, Figure 12\ndemonstrates the accuracy of our method in restoring scan image details, accurately reconstructing the essential details of the\nimage.\nTable 11: The experimental results for the four reconstruction tasks.\nCT(Brain) CT(Pelvis) MRI (Brain) MRI(Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\nSEED-X 20.18 27.66 112.11 21.53 28.02 102.87 4.90 27.62 112.86 6.31 27.89 106.21\nUnified-IO 2 83.93 36.09 17.95 85.36 35.10 25.46 87.50 34.25 25.47 86.31 33.53 29.80\nHealthGPT-M3 91.73 36.42 15.46 94.26 37.30 12.53 88.76 33.97 27.05 84.40 33.11 32.62\n34.08\n15.87\n9.16\n5.62\n13.33\n21.94\nHealthGPT\nLLaVA-Med\nHuatuoGPT-Vision\nLlama-3.2\nInternVL-2\nShow-o\nHuman\nEvaluation\n(a) (b)\nFigure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.\n17']","HealthGPT-M3 outperforms other models in medical visual comprehension and modality conversion tasks by achieving superior performance across multiple evaluation metrics. In medical visual comprehension tasks, HealthGPT-M3 scored 61.3 on the medical multi-modal unified task, significantly outperforming existing unified models like Unified-IO 2, which scored only 33.8. For modality conversion tasks, HealthGPT-M3 excels in converting between CT and MRI modalities, achieving an SSIM of 79.38 in the CT2MRI-Brain task, surpassing traditional methods like Pix2Pix (71.09) and DiffMa (71.47). Additionally, in super-resolution tasks, HealthGPT-M3 achieves high scores in key metrics such as SSIM (78.19), PSNR (32.76), and MSE (34.47), demonstrating its exceptional performance in human visual perception. These metrics highlight HealthGPT-M3's effectiveness in accurately reconstructing essential image details and guiding transformations across different regions.",multi_hop_specific_query_synthesizer
How does the PathVQA dataset contribute to the performance of HealthGPT in medical visual comprehension tasks?,"['<1-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8', '<2-hop>\n\n（a） （b）\nFigure 8: VL-Health dataset collection distribution.\nA.3 VL-Health\nThe construction of theVL-Health dataset involves two key steps:(i) data collection, (ii) data processing, as detailed below:\nData Collection: During the collection phase, we carefully considered the diversity of medical images and the complexity of\nthe tasks, selecting appropriate subsets for comprehension and generation tasks. For comprehension tasks, we selected datasets\nsuch as VQA-RAD (Lau et al. 2018), SLAKE (Liu et al. 2021), PathVQA (He et al. 2020), and MIMIC-CXR-VQA (Bae et al.\n2024), which cover various medical imaging modalities like radiology and pathology, and include professional annotations\nto assist the model in learning tasks such as lesion detection and disease diagnosis. Additionally, large-scale multi-modal\ndatasets like LLaV A-Med (Li et al. 2024b) and PubMedVision (Chen et al. 2024a) were included to provide broader medical\nknowledge support and facilitate the training of complex reasoning tasks. For generation tasks, we focused on four mainstream\ntask categories: super-resolution image generation, modality conversion, text-to-image generation, and image reconstruction.\nThe IXI (Davies et al. 2014) dataset, containing a large number of healthy brain MRI images, is suitable for training super-\nresolution models; the MIMIC-CHEST-XRAY (Bae et al. 2024) dataset, with X-ray images and their corresponding textual\nreports, is appropriate for text-to-image generation tasks; the SynthRAD2023 (Thummerer et al. 2023) dataset provides a large\nnumber of paired CT and MRI images, supporting modality conversion model training; for image reconstruction tasks, we\nrewrote and adjusted the LLaV A-558k (Liu et al. 2024b) dataset.\nData Processing: After data collection, we performed filtering and processing of the raw data. For VisualQA tasks, we stan-\ndardized the data entries into two forms: open-ended questions and single-choice questions, enabling flexible training and\nevaluation. Additionally, considering that multi-image data has a minimal impact on performance but introduces extra padding\nand training time, we excluded multi-image data. For the scanned image data in generation tasks, we applied slicing extrac-\ntion, image registration, data augmentation, and normalization to treat 2D images as visual inputs for model training or used\nVQGAN-generated indices to supervise the generation tasks.\nData Statistics This section provides detailed statistical information about the VL-Health dataset to offer a more compre-\nhensive understanding.\nData Overview: To ensure a balanced development of the model’s comprehension and generation capabilities, in addition\nto the LLaV A-558k and PubMedVision-PT datasets used for alignment, the VL-Health dataset ultimately selected 765,802\nadditional visual question-answering (VQA) training samples (to endow the model with visual comprehension and instruction-\nfollowing capabilities) and 783,045 generation training samples (to provide the model with reconstruction and visual generation\ninstruction-following abilities). This contributes to the transfer of knowledge between comprehension and generation tasks, en-\nhancing the model’s overall performance. For medical image comprehension tasks, images were selected from VQA-RAD (ap-\nproximately 450 images), SLAKE (approximately 630 images), PathVQA (approximately 2,600 images), MIMIC-CXR-VQA\n(approximately 52,000 images), LLaV A-Med (approximately 61,000 images), and PubMedVision (approximately 500,000 im-\nages). Multiple question-answer pairs were retained for each image to enhance the model’s understanding and generalization\nof the image content. Table 8 shows the data distribution ofVL-Health for three-stage learning strategy, where mixed-47k is\nbased on the sampling of all data in stage-1.\nDiversity and Quality Assessment: VL-Health covers 11 modalities, including CT, MRI, X-ray, microscopy, OCT, ultra-\nsound, and fundus photography, which aids the model in learning features from various modalities. The dataset also encom-\npasses a wide range of diseases, from common to rare, and from localized lesions to systemic diseases, including pulmonary\ndiseases, skeletal abnormalities, brain lesions, tumors, cardiovascular diseases, and cellular abnormalities. This provides com-\nprehensive training support to the model, enabling it to learn the characteristics and diagnosis of various diseases.\n13']","The PathVQA dataset contributes to the performance of HealthGPT in medical visual comprehension tasks by providing a diverse set of medical images and professional annotations that assist the model in learning tasks such as lesion detection and disease diagnosis. This dataset, along with others like VQA-RAD and SLAKE, covers various medical imaging modalities, enhancing the model's ability to comprehend and generalize across different types of medical images. The inclusion of PathVQA in the VL-Health dataset supports the training of complex reasoning tasks, thereby improving HealthGPT's overall performance in medical visual comprehension.",multi_hop_specific_query_synthesizer
Howw does SAR client-initiated back channnel authenticationn work in the context of AI agents andd what are the endless possibilities forr enhancing customer experiences?,"['<1-hop>\n\n## [1297.20s] Back Channel Authentication\nFor the push notification, the standard used is SAR client-initiated back channel authentication. The AI agent initiates a back channel authentication request with the bank, which then sends a notification to the user for approval. Upon receiving approval, the bank provides a token to the AI agent, allowing it to call the endpoint.\n\n# [1320.96s] Endless Possibilities\nWith these capabilities, the possibilities are endless. It is encouraged for everyone to consider how they can leverage this technology to enhance customer experiences and improve their systems. Assistance is available to help implement these solutions, as every example and scenario discussed can be executed using WSO software. Collaboration with various customers is already underway to achieve these implementations.']","SAR client-initiated back channel authentication works by having the AI agent initiate a back channel authentication request with the bank. The bank then sends a notification to the user for approval. Once the user approves, the bank provides a token to the AI agent, allowing it to call the endpoint. The endless possibilities for enhancing customer experiences include leveraging this technology to improve systems and customer interactions, with assistance available for implementing these solutions using WSO software.",multi_hop_specific_query_synthesizer
How does MoELoRA compare to H-LoRA in terms of training time and performance in medical tasks?,"['<1-hop>\n\nTable 3: Comparison results of super-resolution task.\nModel SSIM↑ PSNR↑ MSE↓ LPIPS↓\nSRGAN 71.34 32.01 41.27 24.50\nDASR 71.57 32.34 38.25 19.17\nReal-ESRGAN 67.30 31.87 42.57 20.64\nLIIF 73.27 32.13 40.14 22.93\nBSRGAN 69.97 31.97 41.52 28.72\nHealthGPT-M3 78.19 32.76 34.47 12.02\nHealthGPT-L14 77.94 32.71 35.19 12.43\nFigure 5: Performance comparison of LoRA, MoELoRA,\nand H-LoRA under different rank settings.\net al. 2024b), Llama-3.2 (Dubey et al. 2024)). Addition-\nally, we test several SOTA unified visual comprehension\nand generation models, including Show-o (Xie et al. 2024),\nUnified-IO 2 (Lu et al. 2024), and Janus (Wu et al.\n2024). The experimental results are shown in Table 1, with\nthe following key observations: (i) SOTA Results Com-\npared with LVLMs: In medical visual comprehension\ntasks, HealthGPT demonstrates superior performance,\nsignificantly outperforming both medical-specific models\n(e.g., HuatuoGPT-Vision) and general-purpose models (e.g.,\nLlama-3.2). (ii) Surpassing Current Unified LVLMs: De-\nspite being trained on billions of data points, unified mod-\nels still exhibit poor generalization performance in medi-\ncal visual comprehension. For instance, Unified-IO 2 scored\nonly 33.8. In contrast,HealthGPT-M3, with only 3.8B pa-\nrameters, scored 61.3 on the medical multi-modal unified\ntask, significantly outperforming existing unified models in\nmedical downstream scenarios. (iii) Stable Improvement\nwith Large Base Model: Our method demonstrates excel-\nlent scalability, with HealthGPT-L14 achieving a score\nof 66.4 in the larger model configuration. This result signif-\nicantly outperforms all other models, highlighting the effec-\ntiveness of scaling up the base model for enhanced perfor-\nmance in medical tasks.\nGeneration. We study three key tasks in medical imag-\ning. (i) Modality Conversion: In this task, we focus on\nthe conversion between CT and MRI modalities for the\nbrain and pelvic regions, designing four specific sub-tasks.\nAll comparative models (Pix2Pix (Isola et al. 2017), Cy-\ncleGAN (Zhu et al. 2017), BBDM (Li et al. 2023a),\n(%)\n(%)\n（a） （b）\nFigure 6: The loss visualization (a) and performance com-\nparison (b) with respect to different visual perceptions.\nVmamba (Liu et al. 2024e), and DiffMa (Wang et al.\n2024b)) trained a separate model for each sub-task, while\nHealthGPT unify all tasks into a single training process.\nThe experimental results, shown in Table 11, demonstrate\nthat our approach outperforms other methods across multi-\nple evaluation metrics. For instance, in the CT2MRI-Brain\ntask, HealthGPT-M3 achieves an SSIM of 79.38, signif-\nicantly surpassing traditional methods like Pix2Pix (71.09)\nand the recent DiffMa (71.47). (ii) Super-Resolution: We\nconduct 4× super-resolution experiments on the IXI dataset,\nwith the results presented in Table 3. Notably, most exist-\ning methods fail to fully leverage the prior knowledge of key\nstructures in medical images, resulting in significant short-\ncomings in detail recovery. In contrast, our method signif-\nicantly mitigates this issue. Specifically, HealthGPT-M3\nexcels in key metrics such as SSIM, PSNR, and ISE, achiev-\ning scores of 78.19, 32.76, and 34.47, respectively. Ad-\nditionally, HealthGPT-M3 achieves the lowest score of\n12.34, further validating its exceptional performance in hu-\nman visual perception. (iii) Reconstruction: We compare\nHealthGPT-M3 with unified models with reconstruction\ncapabilities, such as Unified-IO 2 and SEED-X. The results\nshow that our approach performs better controllability for vi-\nsual reconstruction. We also trainHealthGPT-L14 with a\nsimilar number of trainable parameters to the M3 version.\nHence, the similar performance between the two models\nmeets our expectations. Details are in the Appendix.\n5.3 In-Depth Study\nEffect of Heterogeneous Low-Rank Adaptation.H-LoRA\nprovides an optimized multi-LoRA architecture for multi-\ntask learning. We conduct extensive validation of this struc-\nture, with results presented in Table 4, comparing the per-\nformance of LoRA, MoELoRA, and H-LoRA in medical\nunified comprehension and generation tasks. In the majority\nof comprehension tasks and all generation tasks, H-LoRA\ndemonstrates superior performance, particularly in the Om-\nniMedVQA benchmark, where it improved from 64.90 to\n68.50. Notably, despite some applications of MoELoRA in\ncertain scenarios, it do not show advantages in this task and\n7', '<2-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","MoELoRA and H-LoRA were compared in terms of training time and performance within a multi-LoRA architecture. As the number of experts increases, MoELoRA's training time significantly prolongs, with the training time for MoELoRA being twice that of LoRA at n=8, and potentially reaching eight times at n=32, preventing it from completing training and inference. In contrast, H-LoRA incurs no additional training delay and performs better. Specifically, H-LoRA demonstrates superior performance in medical unified comprehension and generation tasks, particularly in the OmniMedVQA benchmark, where it improved from 64.90 to 68.50. This indicates that H-LoRA not only avoids additional training delays compared to LoRA but also outperforms MoELoRA.",multi_hop_specific_query_synthesizer
How does PubMedVision-PT contribute to the VL-Health dataset in the context of medical visual comprehension tasks?,"['<1-hop>\n\nTable 8: Data distribution of VL-Health in three-stage learning strategy.\nMedical Task Stage-1 Stage-2\nComp. LLaV A-558k, PubMedVision-PT Mixed-47kGen. LLaV A-558k\nMedical Task Stage-3\nComp. LLaV A Med, MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, VQA-RAD\nGen. IXI, SynthRAD2023, MIMIC-CHEST-XRAY\nData Format. All data samples are converted into a unified instruction-response format for training and evaluation. Specifi-\ncally, the VL-Health dataset consists of the following components:\n• Task Type: Specifies the granularity of visual features output by the visual encoder and selects the corresponding H-\nLoRA submodule. For generation tasks, the response also includes multi-modal tokens corresponding to VQ indices.\n• Task Instruction: Guides the model to interpret the image and generate a response, covering various aspects of the\nimage and specifying the output format.\n• Response: The textual output generated based on the task instruction and input image, ensuring it meets the question and\nformatting requirements.\n• Input Image: Provides the visual signal for the model to process.\n• Target Image Index: In generation tasks, this is added as a multi-modal token to the response for autoregressive\ngeneration.\nB Analysis of Heterogeneous Low-Rank Adaptation\nWe propose H-LoRA, which utilizes hard routing selection to allocate plugins for knowledge learning and representation across\ntasks, thereby preventing conflicts arising from heterogeneous knowledge. Furthermore, within each task, we optimized based\non MoELoRA, enhancing performance while reducing computational overhead. The pseudocode is detailed Algorithm 1.\nAlgorithm 1: H-LoRA Algorithm\nInput: concrete-grained visual features FCon, abstract-grained visual featuresFAbs, comprehension-based H-LoRA modules\n({AComp.\ni }k\ni=1, RComp.\nouter ), generation-based H-LoRA modules({AGen.\ni }k\ni=1, RGen.\nouter), task type T (comprehension or generation),\nnumber of LoRA experts k, origin linear layer weights W0, text features T , hidden state h\nOutput: final output O\n// Select task-specific image features\nif T = generation task then\nFimg ← FCon\nelse if T = comprehension task then\nFimg ← FAbs\nend if\nU ←concat(Fimg, T ) // Concatenate image features and text features\n{Ai}k\ni=1, {Bi}k\ni=1, Router ← {AT\ni }k\ni=1, {BT\ni }k\ni=1, RT\nouter // Assign task-specific H-LoRA submodule\n// Merge LoRA experts’ matrices\nAmerged ← concat({Ai}k\ni=1)\nBmerged ← concat({Bi}k\ni=1)\nW ←R(h) // Generate routing weights based on input hidden state x\nWexpanded ← α × W/r ⊗ 1r // Expand routing weights to match merged matrices\nOH-LoRA ← (x · Amerged ⊙ Wexpanded) · Bmerged // Compute H-LoRA output using element-wise multiplication\nO ←x · W0 + OH-LoRA // Add H-LoRA output to pre-trained weights to get final output\nReturn O\nWe further analyzed the computational overhead differences between MoELoRA and H-LoRA. Assuming that both methods\nuse the same number of LoRA experts k, we can compare their time complexity from the perspective of the operational steps\ninvolved.\nComputational Overhead of MoELoRA. In MoELoRA, the operations involving the expert matrix mainly include the fol-\nlowing steps: (i) Expert Multiplication : MoELoRA requires 2k multiplications with the LoRA experts. (ii) Router Multi-\nplication: One multiplication with the Router is required. (iii) Router Output Expansion : MoELoRA needs to perform k\n14']","PubMedVision-PT is part of the data distribution strategy for the VL-Health dataset, specifically contributing to the comprehension tasks. In Stage-1 of the learning strategy, PubMedVision-PT is included alongside other datasets like LLaV A-558k. In Stage-3, it is used in conjunction with datasets such as LLaV A Med, MIMIC CXR VQA, and others. The dataset samples are converted into a unified instruction-response format, which aids in training and evaluation for medical visual comprehension tasks.",multi_hop_specific_query_synthesizer
How can the MCP server be utilized for weather considerations in AI itinerary planning?,"['<1-hop>\n\n## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.', '<2-hop>\n\n# [4800.24s] Overview of MCP Server Configuration\nBy default, the configuration is set to two, but this particular MCP server only supports HTTP/1. This is something I confirmed through testing. You can edit the settings in local code or in pro code mode; either method works. Regardless of the approach taken, the diagram and the code remain in sync.\n\n## [4823.12s] Executing a Query\nThe system is currently running, and I should access the chat window. Here it is. We will proceed with our usual query: ""Plan me a trip for 5 days in Sri Lanka."" The system is taking some time to process the request. We will wait for the response, and then I will walk through the verbose logs.']","The MCP server can be utilized for weather considerations in AI itinerary planning by connecting to it to provide weather information. This allows the integration of a weather tool into the planning process, enhancing the AI agent's ability to consider weather conditions when planning an itinerary.",multi_hop_specific_query_synthesizer
"How does Rana Kalaf suggest organizations should approach the challenge of delivering business value through AI products, and what are the key considerations she highlights?","['<1-hop>\n\n## [301.52s] The Challenge of Delivering Business Value\nThe discussion shifts to the challenges of delivering business value through AI products. Rana Kalaf addresses the initial excitement of building AI products and the subsequent concerns about whether they truly deliver value. She notes the evolution of AI development, contrasting traditional data science practices with the current need for real-time, distributed systems. Rana emphasizes that building AI applications is now a collaborative effort, requiring a focus on scalability and production readiness. She stresses the importance of measuring the effectiveness of AI tools, suggesting that organizations should view AI as a means to enhance processes rather than an end goal.']","Rana Kalaf suggests that organizations should approach the challenge of delivering business value through AI products by focusing on the evolution of AI development. She highlights the importance of contrasting traditional data science practices with the current need for real-time, distributed systems. Rana emphasizes that building AI applications is a collaborative effort that requires attention to scalability and production readiness. She also stresses the importance of measuring the effectiveness of AI tools, suggesting that organizations should view AI as a means to enhance processes rather than an end goal.",multi_hop_specific_query_synthesizer
"How does the OmniMedVQA benchmark demonstrate the efficiency of HealthGPT models compared to other medical LVLMs, and what role does H-LoRA play in enhancing model performance?","['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15', '<2-hop>\n\ngeneral LVLMs; (ii) the unified model demonstrates relatively weak performance on OmniMedVQA; however, our approach\neffectively mitigates performance degradation caused by generation tasks, serving as a unified model; (iii) HealthGPT-L14\nexcels across all sub-tasks, achieving optimal or near-optimal results with an average score of 74.4, significantly surpassing\nother models.\nC.2 Stability Analysis of Number of Experts\nWe investigated the impact of the number of LoRA experts on model performance within a multi-LoRA architecture, conducting\nextensive experiments on MoELoRA and H-LoRA with varying numbers of experts. The experimental results are presented\nin Table 10. As the number of experts increases, the training time for MoELoRA is significantly prolonged. When n = 8 ,\nthe training time for MoELoRA is twice that of LoRA, whereas H-LoRA incurs no additional training delay and performs\nbetter. It is estimated that at n = 32, the training time for MoELoRA could reach eight times that of LoRA, preventing it from\ncompleting training and inference. This result aligns with the analysis in Appendix B, indicating that H-LoRA not only avoids\nintroducing additional training delays compared to LoRA but also outperforms MoELoRA.\nTable 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n = 32 ,\nMoELoRA was unable to complete training.\nn=2 n=4 n=8 n=32Model Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time Comp. Gen. Time\n+MoELoRA 50.3 62.98 1.22 × 50.0 64.33 1.49 × 50.8 63.71 2.09 × / / 5.81 ×HealthGPT w/ +H-LoRA 51.5 63.48 0.99× 52.8 64.71 1.00× 53.6 64.98 0.99× 53.5 64.74 1.01×\nC.3 Impact of Heterogeneous Knowledge Fusion on Performance\nTraditional unified models often utilize mixed training methods, which may result in performance degradation due to variations\nin task modes. To address this, we propose a three-phase learning strategy to support H-LoRA, effectively mitigating inter-task\nconflicts. Specifically, the second phase (Heterogeneous H-LoRA Plugin Adaptation) integrates LLMs with different H-LoRA\nplugins into a new unified foundation by mixing the training of the embedding layers and output heads for two tasks. Figure\n9 illustrates the impact of this phase on the performance of medical comprehension and generation tasks. We observe that the\nsecond phase effectively unifies the model with minimal impact on overall performance, significantly alleviating the conflict\nissues arising from mixed training in medical scenarios.\nC.4 Human Evaluation.\n65.7 65.4 67.7 67.0\nFigure 9: Performance changes before and after the\nstage-2.\nWe further conduct human evaluation on the VQA-RAD, SLAKE,\nand PathVQA benchmarks, which contain 1,000 open-ended ques-\ntions. Specifically, we recruit 5 clinicians to rank the randomly shuf-\nfled responses from HealthGPT-L14, LLaV A-Med, HuatuoGPT-\nVision, Llama-3.2, InternVL-2 and Show-o. During the evaluation,\nquestions were randomly selected, and the model-generated responses\nwere anonymized and ranked. The results, as shown in Figure 10, in-\ndicate that HealthGPT was frequently selected as the best answer.\nThis suggests that HealthGPT has further application potential in\nmedical care scenarios.\nC.5 Reconstruction Performance\nCurrently, unified models that align visual features based on recon-\nstruction tasks include pre-LVLMs, post-LVLMs, as well as Unified-\nIO 2 (Lu et al. 2024) and SEED-X (Ge et al. 2024). To investigate the\ncontrollability of visual generation in rigorous settings such as med-\nical contexts, we evaluated the performance of these models in med-\nical image reconstruction in Table 11. Experimental results demon-\nstrate that HealthGPT exhibits the most stable reconstruction per-\nformance with a small amount of data.\n16']","The OmniMedVQA benchmark is a large-scale medical visual question answering benchmark designed to encompass various modalities and anatomical regions. According to the experimental results, HealthGPT models, particularly HealthGPT-M3 and HealthGPT-L14, outperform other models in several sub-tasks, achieving higher average scores than cutting-edge medical Large Vision-Language Models (LVLMs). HealthGPT-L14 excels across all sub-tasks with an average score of 74.4, significantly surpassing other models. The role of H-LoRA in enhancing model performance is evident in its ability to reduce computational overhead compared to MoELoRA. H-LoRA achieves this by merging all LoRA experts into larger matrices, resulting in a fixed additional time complexity of O(6), independent of the number of experts. This efficiency allows H-LoRA to avoid additional training delays and perform better than MoELoRA, particularly as the number of experts increases, making it suitable for large-scale tasks.",multi_hop_specific_query_synthesizer
How does HealthGPT utilize LoRA to enhance its performance in medical visual comprehension and generation tasks?,"['<1-hop>\n\nFigure 3: The HealthGPT architecture integrates hierarchical visual perception and H-LoRA, employing a task-specific hard\nrouter to select visual features and H-LoRA plugins, ultimately generating outputs with an autoregressive manner.\na design paradigm based on ViT, alignment adapters, and\npre-trained LLMs(Liu et al. 2023, 2024b), enabling quick\nadaptation to downstream tasks.\nVQGAN. VQGAN (Esser, Rombach, and Ommer 2021)\nemploys latent space compression and indexing mechanisms\nto effectively learn a complete discrete representation of im-\nages. VQGAN first maps the input imageximg to a latent rep-\nresentation z = E(x) through a encoder E. Then, the latent\nrepresentation is quantized using a codebookZ = {zk}K\nk=1,\ngenerating a discrete index sequence I = [im]N\nm=1, where\nim ∈ Zrepresents the quantized code index:\nI = Quantize(z|Z) = arg min\nzk∈Z\n∥z − zk∥2. (2)\nIn our approach, the discrete index sequence I serves as\na supervisory signal for the generation task, enabling the\nmodel to predict the index sequence ˆI from input conditions\nsuch as text or other modality signals. Finally, the predicted\nindex sequence ˆI is upsampled by the VQGAN decoder G,\ngenerating the high-quality image ˆximg = G(ˆI).\nLow Rank Adaptation. LoRA(Hu et al. 2021) effectively\ncaptures the characteristics of downstream tasks by intro-\nducing low-rank adapters. The core idea is to decompose\nthe bypass weight matrix ∆W ∈ Rdin×dout\ninto two low-\nrank matrices {A ∈ Rdin×r, B ∈ Rr×dout\n}, where r ≪\nmin{din, dout}, significantly reducing learnable parameters.\nThe output with the LoRA adapter for the input x is then\ngiven by:\nh = xW0 + αx∆W/r = xW0 + αxAB/r, (3)\nwhere matrix A is initialized with a Gaussian distribution,\nwhile the matrixB is initialized as a zero matrix. The scaling\nfactor α/r controls the impact of ∆W on the model.\n4 HealthGPT\n4.1 Unified Autoregressive Generation.\nHealthGPT (Figure 3) utilizes a discrete token representa-\ntion that covers both text and visual outputs, unifying visual\ncomprehension and generation as an autoregressive task. For\ncomprehension, Mllm receives the input joint sequence U\nand outputs a series of text token R = [ r1, r2, . . . , rNr ],\nwhere ri ∈ Vtxt, and Vtxt represents the LLM’s vocabulary:\nPθ(R | U) =\nNrY\ni=1\nPθ(ri | U, r<i). (4)\nFor generation, Mllm first receives a special start token\n⟨START IMG⟩, then generates a series of tokens corre-\nsponding to the VQGAN indices I = [ i1, i2, . . . , iNi ],\nwhere ij ∈ Vvq, and Vvq represents the index range of VQ-\nGAN. Upon completion of generation, the LLM outputs an\nend token ⟨END IMG⟩:\nPθ(I | U) =\nNiY\nj=1\nPθ(ij | U, i<j). (5)\nFinally, the generated index sequence I is fed into the de-\ncoder G, which reconstructs the target image ˆximg = G(I).\n4.2 Hierarchical Visual Perception\nGiven the differences in visual perception between compre-\nhension and generation tasks—where the former focuses on\nabstract semantics and the latter emphasizes complete se-\nmantics—we employ ViT to compress the image into dis-\ncrete visual tokens at multiple hierarchical levels. Specif-\nically, the image is converted into a series of features\n{f1, f2, . . . , fL} as it passes through L ViT blocks.\n4', '<2-hop>\n\nTable 3: Comparison results of super-resolution task.\nModel SSIM↑ PSNR↑ MSE↓ LPIPS↓\nSRGAN 71.34 32.01 41.27 24.50\nDASR 71.57 32.34 38.25 19.17\nReal-ESRGAN 67.30 31.87 42.57 20.64\nLIIF 73.27 32.13 40.14 22.93\nBSRGAN 69.97 31.97 41.52 28.72\nHealthGPT-M3 78.19 32.76 34.47 12.02\nHealthGPT-L14 77.94 32.71 35.19 12.43\nFigure 5: Performance comparison of LoRA, MoELoRA,\nand H-LoRA under different rank settings.\net al. 2024b), Llama-3.2 (Dubey et al. 2024)). Addition-\nally, we test several SOTA unified visual comprehension\nand generation models, including Show-o (Xie et al. 2024),\nUnified-IO 2 (Lu et al. 2024), and Janus (Wu et al.\n2024). The experimental results are shown in Table 1, with\nthe following key observations: (i) SOTA Results Com-\npared with LVLMs: In medical visual comprehension\ntasks, HealthGPT demonstrates superior performance,\nsignificantly outperforming both medical-specific models\n(e.g., HuatuoGPT-Vision) and general-purpose models (e.g.,\nLlama-3.2). (ii) Surpassing Current Unified LVLMs: De-\nspite being trained on billions of data points, unified mod-\nels still exhibit poor generalization performance in medi-\ncal visual comprehension. For instance, Unified-IO 2 scored\nonly 33.8. In contrast,HealthGPT-M3, with only 3.8B pa-\nrameters, scored 61.3 on the medical multi-modal unified\ntask, significantly outperforming existing unified models in\nmedical downstream scenarios. (iii) Stable Improvement\nwith Large Base Model: Our method demonstrates excel-\nlent scalability, with HealthGPT-L14 achieving a score\nof 66.4 in the larger model configuration. This result signif-\nicantly outperforms all other models, highlighting the effec-\ntiveness of scaling up the base model for enhanced perfor-\nmance in medical tasks.\nGeneration. We study three key tasks in medical imag-\ning. (i) Modality Conversion: In this task, we focus on\nthe conversion between CT and MRI modalities for the\nbrain and pelvic regions, designing four specific sub-tasks.\nAll comparative models (Pix2Pix (Isola et al. 2017), Cy-\ncleGAN (Zhu et al. 2017), BBDM (Li et al. 2023a),\n(%)\n(%)\n（a） （b）\nFigure 6: The loss visualization (a) and performance com-\nparison (b) with respect to different visual perceptions.\nVmamba (Liu et al. 2024e), and DiffMa (Wang et al.\n2024b)) trained a separate model for each sub-task, while\nHealthGPT unify all tasks into a single training process.\nThe experimental results, shown in Table 11, demonstrate\nthat our approach outperforms other methods across multi-\nple evaluation metrics. For instance, in the CT2MRI-Brain\ntask, HealthGPT-M3 achieves an SSIM of 79.38, signif-\nicantly surpassing traditional methods like Pix2Pix (71.09)\nand the recent DiffMa (71.47). (ii) Super-Resolution: We\nconduct 4× super-resolution experiments on the IXI dataset,\nwith the results presented in Table 3. Notably, most exist-\ning methods fail to fully leverage the prior knowledge of key\nstructures in medical images, resulting in significant short-\ncomings in detail recovery. In contrast, our method signif-\nicantly mitigates this issue. Specifically, HealthGPT-M3\nexcels in key metrics such as SSIM, PSNR, and ISE, achiev-\ning scores of 78.19, 32.76, and 34.47, respectively. Ad-\nditionally, HealthGPT-M3 achieves the lowest score of\n12.34, further validating its exceptional performance in hu-\nman visual perception. (iii) Reconstruction: We compare\nHealthGPT-M3 with unified models with reconstruction\ncapabilities, such as Unified-IO 2 and SEED-X. The results\nshow that our approach performs better controllability for vi-\nsual reconstruction. We also trainHealthGPT-L14 with a\nsimilar number of trainable parameters to the M3 version.\nHence, the similar performance between the two models\nmeets our expectations. Details are in the Appendix.\n5.3 In-Depth Study\nEffect of Heterogeneous Low-Rank Adaptation.H-LoRA\nprovides an optimized multi-LoRA architecture for multi-\ntask learning. We conduct extensive validation of this struc-\nture, with results presented in Table 4, comparing the per-\nformance of LoRA, MoELoRA, and H-LoRA in medical\nunified comprehension and generation tasks. In the majority\nof comprehension tasks and all generation tasks, H-LoRA\ndemonstrates superior performance, particularly in the Om-\nniMedVQA benchmark, where it improved from 64.90 to\n68.50. Notably, despite some applications of MoELoRA in\ncertain scenarios, it do not show advantages in this task and\n7']","HealthGPT employs LoRA (Low Rank Adaptation) to enhance its performance in medical visual comprehension and generation tasks by introducing low-rank adapters that decompose the bypass weight matrix into two low-rank matrices. This significantly reduces the number of learnable parameters while capturing the characteristics of downstream tasks. In the context of HealthGPT, LoRA is integrated into the architecture to improve the model's adaptability and efficiency in handling complex medical imaging tasks. The use of LoRA, along with hierarchical visual perception and H-LoRA, allows HealthGPT to outperform other models in medical visual comprehension tasks, as evidenced by its superior performance metrics such as SSIM, PSNR, and MSE in super-resolution tasks. Additionally, HealthGPT-M3 and HealthGPT-L14 demonstrate exceptional performance in medical imaging tasks, surpassing traditional and recent methods in various evaluation metrics.",multi_hop_specific_query_synthesizer
Howw does AI Gateway Analitics help healthcare AI innovators in understandingg system performance and optimizingg vendor model usage?,"['<1-hop>\n\n# [3146.56s] AI Gateway Analytics\nAI gateway analytics involves publishing specific analytic details for AI use cases. For example, a casual analytic scenario may count requests, identify headers used, and track errors. This provides a breakdown that helps AI developers understand system performance. The analytics dashboard is purpose-driven, allowing developers to identify issues, such as which services or applications are consuming more data or tokens. \n\nThe dashboard offers detailed insights into vendor model usage, identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.']","AI Gateway Analytics assists healthcare AI innovators by providing a detailed breakdown of system performance through specific analytic details. It helps in counting requests, identifying headers used, and tracking errors, which allows developers to understand which services or applications are consuming more data or tokens. Additionally, the analytics dashboard offers insights into vendor model usage, identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.",multi_hop_specific_query_synthesizer
"How does HealthGPT address the challenges of integrating LVLMs in medical scenarios, and how does it compare to other models in terms of performance on medical visual comprehension tasks?","['<1-hop>\n\nSpecifically, recent studies (Li et al. 2024a; Tu et al. 2024)\nhave utilized pre-trained large language models (LLMs) and\nvisual instruction data to build interactive diagnostic tools\nand treatment planning systems, revealing the immense po-\ntential of LVLMs in medical scenarios. However, these stud-\nies primarily concentrate on visual comprehension tasks that\nproduce text-based outputs, such as medical visual ques-\ntion answering (Li et al. 2024a) or report generation (Nath\net al. 2024), and deficient the “drawing” capability needed\nfor medical visual generation. In practice, integrating visual\ncomprehension and generation can significantly enhance the\nmultifunctionality of medical LVLMs.\nRecent studies have increasingly focused on developing\nunified LVLMs capable of comprehending and generating\ncontent across diverse visual modalities. Earlier approaches\npredominantly utilized continuous visual tokens fed into\nLLMs, using the LLMs themselves as conditional genera-\ntors for external generative models (Ge et al. 2024; Wu et al.\n2023; Dong et al. 2023). More recent research has explored\nthe use of discrete visual tokens for image representation and\ngeneration within a fully autoregressive framework (Team\n2024; Wang et al. 2024a; Xie et al. 2024). These meth-\nods not only enhance controllability but also demonstrate\nearly success in open-world, any-to-any tasks, highlighting\nthe preliminary potential of a unified autoregressive learning\nparadigm in multi-modal tasks.\nWhile unified LVLMs have achieved initial success in\ngeneral scenarios, such a unified framework remains under-\nexplored in the medical domain. Adapting the aforemen-\ntioned general unified model paradigm to the medical do-\nmain presents two major challenges: (i) High-scale and\n-quality Data Limitations . Open-world models necessi-\ntate extensive pre-training on billions or even more diverse,\nmulti-modal data samples for comprehension and genera-\ntion tasks (Lu et al. 2024; Team 2024). However, the ac-\ncessible medical data significantly lacks in scale and qual-\nity compared to natural multi-modal datasets. Its special-\nized and domain-specific characteristics make it challenging\nto develop a unified medical model from scratch. (ii) Con-\nflicts between Comprehension and Generation . Compre-\nhension tasks often strip away visual details to focus on\nabstraction, while generation tasks require detailed preser-\nvation, making tokens sensitive to all visual alterations. As\nshown in Figure 2, which features experiments conducted on\nmedical images, the performance in comprehension (or gen-\neration) tasks steadily decreases as the proportion of genera-\ntion (or comprehension) data increases, and vice versa. This\nhighlights a dilemma in autoregressive multi-modal training,\nstemming from the need to maintain consistency between\npre- and post-LVLMs. While some methods have explored\nmutual enhancement between comprehension and genera-\ntion (Pan et al. 2024; Tong et al. 2024), improvements still\nexhibit diminishing returns, with performance degradation\nremaining a significant issue.\n(a) (b)\nFigure 2: With a fixed amount of comprehension (genera-\ntion) data, increasing the proportion of the other type leads\nto significant performance degradation.\nTo tackle the aforementioned challenges, we propose\nHealthGPT (see Figure 1) , which progressively adapts a\npre-trained LLM as an unified medical multi-modal model\nwith a small amount of visual instruction data. We de-\nvise innovative Parameter-Efficient Fine-Tuning (PEFT) ap-\nproach (Ding et al. 2023), calledHeterogeneous Low-Rank\nAdaptation (H-LoRA), which decouples the learning pro-\ncess of LVLMs for comprehension and generation tasks. In-\nspired by the plug-and-play nature of LoRA (Hu et al. 2021),\nH-LoRA enables the model to store heterogeneous compre-\nhension and generation knowledge in independent “plug-\nins”, thus avoiding joint optimization issues caused by con-\nflicts between comprehension and generation tasks. In addi-\ntion, we also consider the variety of sub-tasks among com-\nprehension or generation tasks. Qualitative research high-\nlights the limitations of a single LoRA in handling multi-\ndimensional task scenarios, mainly due to catastrophic for-\ngetting and interference (Liu et al. 2024d; Lin et al. 2024).\nTo address this, we draw on the concept of Mixture of Ex-\nperts (MoE) (Masoudnia and Ebrahimpour 2014) and in-\ntroduce LoRA experts. The aim is to dynamically transfer\ntask-shared knowledge to adapt to downstream tasks. Unlike\nMoELoRA (Luo et al. 2024a), H-LoRA employs reversible\nmatrix block multiplication to combine LoRA experts, sig-\nnificantly reducing the overhead of multiple matrix multi-\nplications. Notably, when using four experts, it requires\nonly 67% of the MoELoRA training time.\nTo effectively leverage H-LoRA inHealthGPT, we fur-\nther introduce a Hierarchical Visual Perception (HVP)\nand devise a correspondingThree-stage Learning Strategy\n(TLS). HVP: we separate visual details learning from Vi-\nsion transformer (ViT) for comprehension and generation.\nAs is widely recognized, the ViT encodes visual concepts\nwith increasing abstraction, generally, becoming finer as we\nprogress over levels (Vig 2019). Thus, we maintain the vi-\nsual features of the anterior and posterior layers to accom-\nmodate the differing requirements for visual granularity in\ncomprehension and generation tasks while preventing po-\n2', '<2-hop>\n\nTable 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","HealthGPT addresses the challenges of integrating LVLMs in medical scenarios by proposing a Parameter-Efficient Fine-Tuning approach called Heterogeneous Low-Rank Adaptation (H-LoRA), which decouples the learning process for comprehension and generation tasks. This approach avoids joint optimization issues caused by conflicts between these tasks. Additionally, HealthGPT introduces a Hierarchical Visual Perception (HVP) and a Three-stage Learning Strategy (TLS) to separate visual details learning for comprehension and generation, accommodating differing requirements for visual granularity. In terms of performance, HealthGPT outperforms other models on medical visual comprehension tasks. For instance, HealthGPT-M3 and HealthGPT-L14 achieve higher scores across various tasks such as VQA-RAD, SLAKE, and PathVQA compared to other models like Med-Flamingo, LLaVA-Med, and HuatuoGPT-Vision, demonstrating its superior adaptability and flexibility across different tasks.",multi_hop_specific_query_synthesizer
"How does the integration of the 'get personalized profile' tool into an AI agent enhance its functionality in the hotel industry, and what additional tools are available to support this process?","['<1-hop>\n\n## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.', '<2-hop>\n\n# [2147.60s] Example: AI Agent in the Hotel Industry\nTo illustrate the functionality of AI agents, consider an application designed for the hotel industry. This application assists customers in planning trips and reserving hotels, functioning similarly to an AI assistant for booking platforms.\n\n**Time Range: 00:40:01 - 00:50:04**\n\n## [2210.80s] Tools Available to the AI Agent\nIn this scenario, the AI agent has access to various tools, including hotel APIs for searching and booking hotels, a weather API for forecasts, a user profile API for personalization, and a location API for fetching nearby attractions.']","The integration of the 'get personalized profile' tool into an AI agent enhances its functionality in the hotel industry by allowing the agent to gather information about user preferences, thereby personalizing the trip planning and hotel reservation process. In addition to this tool, the AI agent has access to various other tools, including hotel APIs for searching and booking hotels, a weather API for forecasts, a user profile API for personalization, and a location API for fetching nearby attractions. These tools collectively enable the AI agent to function as an effective assistant for booking platforms, providing comprehensive support for customers planning trips.",multi_hop_specific_query_synthesizer
"How has Arabic AI, under the leadership of Yad Ahmed, evolved its focus from translation and content generation to advanced AI applications, and what role does fine-tuning SLMs play in enhancing their agent performance?","[""<1-hop>\n\n## [11.84s] Panelist Introductions\nYad Ahmed shares his background, stating that he has 24 years of experience in technology, with eight years focused on natural language processing (NLP) and AI. He explains that Arabic AI, which operates under the name Turjim, has been in business for 17 years, initially focusing on translation and content generation. In 2016, the company expanded into technology, developing automated systems for translation and content generation. Recently, they secured a Series A funding round of $50 million to further their work in AI, particularly in model fine-tuning and workflow automation.\n\nRana Kalaf introduces herself as the Chief AI Officer at WSO2. She emphasizes the company's focus on two main areas in their AI journey: accelerating user engagement with their products through embedded agents and co-pilots, and integrating AI into applications via connectors and an agent-building framework.\n\nAlan Shmal from Vistra describes the company as a corporate services provider that handles accounting, payroll, and legal entity management. He explains that their AI initiatives include a conversational agent built with Aentic AI frameworks, which serves three main functions: advisory, reporting on customer data, and executing workflows. He also mentions the use of asynchronous systems to process unstructured data, such as legal documents and voice notes.\n\nMahesh Saloria represents Canada HSBC Life Insurance, a joint venture between Canara Bank and HSBC. He discusses their focus on securing individuals' futures through insurance and highlights a recent initiative involving an underwriting co-pilot designed to assist underwriters in assessing risk."", ""<2-hop>\n\n### [1683.04s] Conclusion\nIn conclusion, the discussion highlights the ongoing work in fine-tuning SLMs to enhance agent performance and accuracy. The session wraps up with gratitude for the audience's attention and a transition to the next segment.\n\n**Time Range: 00:00:03 - 00:10:03**\n\n# [3.36s] Introduction to the Panel\nThe panel discussion begins with a warm welcome to the audience. The moderator introduces the panelists, highlighting their roles and affiliations. The panelists include Yad Ahmed, the CTO of Arabic AI; Rana Kalaf, the Chief AI Officer at WSO2; Alan Shmal, the Executive Vice President of Platform at Vistra; and Mahesh Saloria, the Head of Architecture at HSBC.""]","Arabic AI, operating under the name Turjim, initially concentrated on translation and content generation for 17 years. Under the leadership of Yad Ahmed, who has extensive experience in technology and AI, the company expanded into technology in 2016, developing automated systems for translation and content generation. Recently, they secured a Series A funding round of $50 million to further their work in AI, particularly focusing on model fine-tuning and workflow automation. The ongoing work in fine-tuning SLMs is crucial for enhancing agent performance and accuracy, as highlighted in the panel discussion's conclusion.",multi_hop_specific_query_synthesizer
"How does the LLaV A-Med dataset contribute to the development of unified medical vision-language models like HealthGPT, and what role does it play in enhancing visual-text alignment?","['<1-hop>\n\ntential task interference. TLS: In the first and second stages,\ngiven the heterogeneity between comprehension and gener-\nation tasks, we first train H-LoRA plugins for HealthGPT\nto incorporate both medical comprehension and generation\nknowledge, thus endowing the LLMs with capabilities for\nvision-language alignment and vision-to-vision reconstruc-\ntion. Additionally, through minimal mixed-task training, we\nbuilt fusion embedding layers and output heads that merge\ntext and visual tokens, establishing a unified LVLM founda-\ntion for visual instruction fine-tuning. In the third stage, by\nonly training the H-LoRA plugins, HealthGPT is able to\nrapidly adapt to a wide range of downstream medical tasks,\ncovering various types of medical comprehension and gen-\neration tasks.\nTo effectively implement our approach, we have cu-\nrated a dataset for training unified medical LVLMs, called\nVL-Health, including seven comprehension tasks and five\ngeneration tasks (Figure 1). Through quantitative analysis\nand validation on multi-modal tasks, the results demonstrate\nthat HealthGPT is capable of unifying medical multi-\nmodal abilities in data-constrained scenarios, achieving per-\nformance comparable to or better than existing state-of-the-\nart (SOTA) models across multiple metrics. Overall, the\nmain contributions of this paper are summarized as follows:\n• Unified Med-LVLM. We introduce HealthGPT,\nwhich, to the best of our knowledge, is the first unified\nframework for multi-modal comprehension and genera-\ntion in complex medical scenarios.\n• Effective Learning Paradigm. We present H-LoRA, an\noptimized multi-LoRA PEFT architecture based on task-\ngated decoupling, is designed to effectively mitigate data\nconflict issues.\n• Holistic Training Dataset. We curated VL-Health, a\ncomprehensive dataset designed for both comprehension\nand generation tasks.\n• Superior Downstream Improvements : Extensive ex-\nperiments are conducted and the results confirm\nHealthGPT’s effectiveness in medical vision-language\ncomprehension and generation.\n2 Related Work\nMedical Vision Large Language Models. Recently, medi-\ncal vision large language models (Med-VLLMs) have made\nsignificant progress, demonstrating excellent performance\nin understanding medical images and responding to human\nqueries based on these images (Zhou et al. 2023; Tian et al.\n2023). XrayGPT (Thawkar et al. 2023) combines a med-\nical visual encoder (MedClip) (Wang et al. 2022) with a\nfine-tuned LLM , using a simple linear transformation layer\nto achieve alignment between visual and textual informa-\ntion, significantly enhancing the understanding of medical\nimages. On this basis, LLaV A-Med (Li et al. 2024b) fur-\nther enhances visual-text alignment in medical contexts by\nselecting high-quality image-text pairs from PubMed pa-\npers and synthesized VQA datasets. BiomedGPT (Luo et al.\n2024b) employs a BERT-style encoder and GPT-style de-\ncoder architecture, pre-trained on interdisciplinary datasets.\nCompared to commercial models like Med-PaLM (Singhal\net al. 2023), BiomedGPT significantly reduces model size\nwhile maintaining superior performance. However, issues\nof language adaptability and dataset specificity still remain.\nTo address these, HuatuoGPT-Vision (Chen et al. 2024a)\nintroduces the PubMedVision dataset, which contains 1.3\nmillion high-quality medical samples, significantly improv-\ning the model’s adaptability across diverse medical applica-\ntions. However, current Med-VLLMs mainly focus on med-\nical comprehension and lack the capability for the medical\nvision-language generation.\nUnified Visual Comprehension and Generation Mod-\nels. Recent research has increasingly concentrated on cre-\nating unified LVLMs that are adept at understanding and\nproducing content across various visual modalities. NExT-\nGPT (Wu et al. 2023) achieves perception and generation for\narbitrary combinations of multi-modal inputs and outputs by\naligning LLMs. Similarly, SEED (Ge et al. 2023), SEED-\nX (Ge et al. 2024), and DreamLLM (Dong et al. 2023) em-\nploy learnable queries and leverage next-token prediction to\ngenerate visual tokens, providing conditional inputs to exter-\nnal generation modules. Unlike these methods, which func-\ntion as external conditioners, Unified-IO (Lu et al. 2022),\nUnified-IO 2 (Lu et al. 2024), and Chameleon (Team 2024)\ninternalize multi-modal generation tasks within a unified\nTransformer architecture by extending multi-modal vocab-\nularies, enabling direct generation based on next-token pre-\ndiction. Building on this concept, Lumina-mGPT (Liu et al.\n2024a) and ANOLE (Chern et al. 2024) further enhance the\ngeneration capabilities of unified models using high-quality\ndata, particularly improving the quality and flexibility of im-\nage generation.\n3 Preliminaries\nLarge Vision-Language Models.The input to a LVLM typ-\nically consists of an image ximg and a discrete text sequence\nxtxt. The visual encoder Eimg converts the input image ximg\ninto a sequence of visual tokens V = [ vi]Nv\ni=1, while the\ntext sequence xtxt is mapped into a sequence of text to-\nkens T = [ ti]Nt\ni=1 using an embedding function Etxt. The\nLLM MLLM(·|θ) models the joint probability of the token\nsequence U = {V, T }, which is expressed as:\nPθ(R|U) =\nNrY\ni=1\nPθ(ri|{U, r<i}), (1)\nwhere R = [ri]Nr\ni=1 is the text response sequence. The LVLM\niteratively generates the next token ri based on r<i. The op-\ntimization objective is to minimize the cross-entropy loss of\nthe response R. It is worth noting that most LVLMs adopt\n3', '<2-hop>\n\n（a） （b）\nFigure 8: VL-Health dataset collection distribution.\nA.3 VL-Health\nThe construction of theVL-Health dataset involves two key steps:(i) data collection, (ii) data processing, as detailed below:\nData Collection: During the collection phase, we carefully considered the diversity of medical images and the complexity of\nthe tasks, selecting appropriate subsets for comprehension and generation tasks. For comprehension tasks, we selected datasets\nsuch as VQA-RAD (Lau et al. 2018), SLAKE (Liu et al. 2021), PathVQA (He et al. 2020), and MIMIC-CXR-VQA (Bae et al.\n2024), which cover various medical imaging modalities like radiology and pathology, and include professional annotations\nto assist the model in learning tasks such as lesion detection and disease diagnosis. Additionally, large-scale multi-modal\ndatasets like LLaV A-Med (Li et al. 2024b) and PubMedVision (Chen et al. 2024a) were included to provide broader medical\nknowledge support and facilitate the training of complex reasoning tasks. For generation tasks, we focused on four mainstream\ntask categories: super-resolution image generation, modality conversion, text-to-image generation, and image reconstruction.\nThe IXI (Davies et al. 2014) dataset, containing a large number of healthy brain MRI images, is suitable for training super-\nresolution models; the MIMIC-CHEST-XRAY (Bae et al. 2024) dataset, with X-ray images and their corresponding textual\nreports, is appropriate for text-to-image generation tasks; the SynthRAD2023 (Thummerer et al. 2023) dataset provides a large\nnumber of paired CT and MRI images, supporting modality conversion model training; for image reconstruction tasks, we\nrewrote and adjusted the LLaV A-558k (Liu et al. 2024b) dataset.\nData Processing: After data collection, we performed filtering and processing of the raw data. For VisualQA tasks, we stan-\ndardized the data entries into two forms: open-ended questions and single-choice questions, enabling flexible training and\nevaluation. Additionally, considering that multi-image data has a minimal impact on performance but introduces extra padding\nand training time, we excluded multi-image data. For the scanned image data in generation tasks, we applied slicing extrac-\ntion, image registration, data augmentation, and normalization to treat 2D images as visual inputs for model training or used\nVQGAN-generated indices to supervise the generation tasks.\nData Statistics This section provides detailed statistical information about the VL-Health dataset to offer a more compre-\nhensive understanding.\nData Overview: To ensure a balanced development of the model’s comprehension and generation capabilities, in addition\nto the LLaV A-558k and PubMedVision-PT datasets used for alignment, the VL-Health dataset ultimately selected 765,802\nadditional visual question-answering (VQA) training samples (to endow the model with visual comprehension and instruction-\nfollowing capabilities) and 783,045 generation training samples (to provide the model with reconstruction and visual generation\ninstruction-following abilities). This contributes to the transfer of knowledge between comprehension and generation tasks, en-\nhancing the model’s overall performance. For medical image comprehension tasks, images were selected from VQA-RAD (ap-\nproximately 450 images), SLAKE (approximately 630 images), PathVQA (approximately 2,600 images), MIMIC-CXR-VQA\n(approximately 52,000 images), LLaV A-Med (approximately 61,000 images), and PubMedVision (approximately 500,000 im-\nages). Multiple question-answer pairs were retained for each image to enhance the model’s understanding and generalization\nof the image content. Table 8 shows the data distribution ofVL-Health for three-stage learning strategy, where mixed-47k is\nbased on the sampling of all data in stage-1.\nDiversity and Quality Assessment: VL-Health covers 11 modalities, including CT, MRI, X-ray, microscopy, OCT, ultra-\nsound, and fundus photography, which aids the model in learning features from various modalities. The dataset also encom-\npasses a wide range of diseases, from common to rare, and from localized lesions to systemic diseases, including pulmonary\ndiseases, skeletal abnormalities, brain lesions, tumors, cardiovascular diseases, and cellular abnormalities. This provides com-\nprehensive training support to the model, enabling it to learn the characteristics and diagnosis of various diseases.\n13']","The LLaV A-Med dataset contributes significantly to the development of unified medical vision-language models like HealthGPT by providing a large-scale multi-modal dataset that supports broader medical knowledge and facilitates the training of complex reasoning tasks. Specifically, LLaV A-Med enhances visual-text alignment in medical contexts by selecting high-quality image-text pairs from PubMed papers and synthesized VQA datasets. This alignment is crucial for models like HealthGPT, which aim to unify medical multi-modal abilities in data-constrained scenarios, achieving performance comparable to or better than existing state-of-the-art models. The dataset's inclusion in the VL-Health dataset collection further aids in training models for both comprehension and generation tasks, thereby improving the overall performance and adaptability of these models in diverse medical applications.",multi_hop_specific_query_synthesizer
"How does the integration of A2A protocols influence the development of domain-specific applications in AI, and what role does agent-to-agent communication play in this process?","['<1-hop>\n\n### [1300.00s] Functionality of Specialized Agents\nFor instance, the observability agent connects to numerous internal APIs to retrieve data. While it primarily focuses on data retrieval, other agents, such as those involved in deployment, can perform actions as well. This illustrates the diverse capabilities of the agents within the Coro ecosystem.\n\n# [1330.96s] Importance of Agent-to-Agent Communication\nAnother significant topic is the communication between agents. Standard protocols are emerging to facilitate agent-to-agent communication, similar to how the MCP standardizes communication between AI applications and tools. These protocols are still evolving, with several options available, including A2A by Google and ACP by IBM.', '<2-hop>\n\n# [1262.24s] Short-Term Predictions and Challenges in AI\nAs the discussion shifts to the future of AI, it is acknowledged that predicting developments over the next decade is challenging. In the short term, the focus is on the evolution of generic use cases into more domain-specific applications. The integration of A2A protocols and other technologies will play a significant role in this transition. Currently, developers are stitching together numerous APIs and data sources, but the future will likely emphasize context and integration, leading to reduced development cycles and the emergence of new business use cases.']","The integration of A2A protocols significantly influences the development of domain-specific applications in AI by facilitating seamless communication between agents. This agent-to-agent communication is crucial as it allows for the efficient retrieval and exchange of data across various internal APIs, as seen in the Coro ecosystem. As these protocols evolve, they are expected to reduce development cycles and enable the creation of new business use cases by emphasizing context and integration. This transition from generic use cases to more specialized applications is a key focus in the short-term evolution of AI.",multi_hop_specific_query_synthesizer
How does vertikal AI improve helthcare customer support using genral AI frameworks?,"[""<1-hop>\n\n## [25.28s] Discussion on Vertical AI\nThe focus of today's discussion is on vertical AI, which is a significant aspect of the ongoing track dedicated to specialized AI applications. Before delving into vertical AI, it is essential to clarify what generic AI entails.\n\n### [38.24s] Understanding Generic AI\nGeneric AI, often referred to as general-purpose AI, has been widely used for various personal and business tasks. It is designed to handle a broad range of applications. However, we are transitioning from this general-purpose AI, which is built for diverse uses, to a more specialized form known as vertical AI. This shift allows for the development of specific AI solutions tailored to industries such as healthcare, legal, and financial services."", '<2-hop>\n\n### [350.72s] Framework for Vertical AI\nThe vertical AI layer is built on existing frameworks, utilizing core large language models (LLMs) from companies like OpenAI, Anthropic, and Gemini. These foundational models serve as the base for horizontal AI applications. On top of this, supporting frameworks such as retrieval-augmented generation (RAG) and data infrastructure are integrated. The vertical layer introduces industry-specific model tuning and regulatory compliance, ensuring that the AI solutions are tailored to meet the unique needs of specific sectors.\n\n## [424.88s] Example: Healthcare Customer Support\nTo illustrate the effectiveness of vertical AI, consider a healthcare customer support requirement. At the foundational level, general-purpose LLMs provide basic language capabilities. Companies like Sierra and Decagon enhance these capabilities with frameworks optimized for customer support. The vertical AI layer then adds the necessary clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems. Without this tailored vertical layer, the AI solution would lack the understanding of healthcare nuances and regulatory constraints essential for real-world deployment.']","Vertical AI improves healthcare customer support by building on general-purpose AI frameworks, such as large language models from companies like OpenAI, Anthropic, and Gemini. These foundational models provide basic language capabilities. The vertical AI layer then introduces industry-specific model tuning and regulatory compliance, ensuring the AI solutions are tailored to meet the unique needs of the healthcare sector. This includes adding clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems, which are essential for understanding healthcare nuances and regulatory constraints.",multi_hop_specific_query_synthesizer
"How does the Egress AI Gateway facilitate the management of interactions with multiple AI providers, and what are its key features that support this functionality?","['<1-hop>\n\n## [2721.68s] Features of the Egress AI Gateway\nAs organizations grow their AI teams and adopt various AI services, the need for a mediation layer becomes apparent. This layer allows organizations to manage interactions with multiple AI providers without being dependent on a single one. \n\nThe egress AI gateway offers several features, including model routing, token-based rate limiting, AI guard, prompt management, adaptive routing, and semantic caching. Additionally, it retains the standard capabilities of an ingress gateway, such as analytics, identity access management, and mediation capabilities. Organizations can connect with any AI service, and the product comes pre-configured with a set of services while allowing for custom configurations.']","The Egress AI Gateway facilitates the management of interactions with multiple AI providers by acting as a mediation layer that allows organizations to connect with any AI service without being dependent on a single provider. Its key features that support this functionality include model routing, which directs requests to the appropriate AI models; token-based rate limiting, which controls the number of requests to prevent overuse; AI guard, which ensures security and compliance; prompt management, which handles the input queries efficiently; adaptive routing, which optimizes the path for requests based on current conditions; and semantic caching, which stores frequently accessed data for quicker retrieval. Additionally, it retains standard capabilities of an ingress gateway, such as analytics, identity access management, and mediation capabilities, and comes pre-configured with a set of services while allowing for custom configurations.",multi_hop_specific_query_synthesizer
"How does the LLaV A-Med model perform in medical visual comprehension tasks compared to other models, and what are the computational advantages of using H-LoRA over MoELoRA?","['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15', '<2-hop>\n\nTable 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","The LLaV A-Med model, with 7 billion parameters, performs well in medical visual comprehension tasks, achieving an average score of 41.3 on the OmniMedVQA benchmark. It outperforms several other models like Med-Flamingo and BLIP-2 in specific tasks, although it is surpassed by models like HealthGPT-M3 and HealthGPT-L14 in overall performance. In terms of computational efficiency, H-LoRA offers significant advantages over MoELoRA. While MoELoRA introduces a linear increase in additional time complexity with respect to the number of experts k, resulting in a complexity of O(5k + 1), H-LoRA maintains a fixed additional time complexity of O(6), independent of k. This makes H-LoRA more computationally efficient, especially in large-scale tasks, as it reduces the computational overhead significantly compared to MoELoRA.",multi_hop_specific_query_synthesizer
How does AI Gateway Analytics assist AI developers in optimizing system performance and understanding vendor model usage?,"['<1-hop>\n\n# [3146.56s] AI Gateway Analytics\nAI gateway analytics involves publishing specific analytic details for AI use cases. For example, a casual analytic scenario may count requests, identify headers used, and track errors. This provides a breakdown that helps AI developers understand system performance. The analytics dashboard is purpose-driven, allowing developers to identify issues, such as which services or applications are consuming more data or tokens. \n\nThe dashboard offers detailed insights into vendor model usage, identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.']","AI Gateway Analytics assists AI developers in optimizing system performance by providing a detailed breakdown of analytic details for AI use cases. It counts requests, identifies headers used, and tracks errors, which helps developers understand system performance. The purpose-driven analytics dashboard allows developers to identify issues such as which services or applications are consuming more data or tokens. Additionally, it offers insights into vendor model usage by identifying the most in-demand models, those that take longer to respond, and those that are quickly rate-limited. This information enables organizations to adjust their systems for optimal performance.",multi_hop_specific_query_synthesizer
What are the security considerations when integrating agentic AI for staff allocation in a booking system?,"[""<1-hop>\n\n### [920.32s] Staff Allocation Agent\nThe second agent operates in the background as a staff allocation agent. It is triggered when a booking is made, accessing the user's personal profile to assign appropriate staff for that booking instance. This integration raises important considerations regarding security boundaries within the agentic AI framework.\n\n## [948.00s] Security Boundaries in Agentic AI\nWhen introducing agentic AI into the platform, it is essential to establish various security boundaries. The user-agent interaction forms one boundary, while the backend systems represent another. These backend systems may interact with external parties, necessitating secure management of incoming and outgoing requests. Additionally, the ambient agent receives requests to perform tasks, requiring secure communication with the business's backend APIs and the ability to update existing bookings.""]","When integrating agentic AI for staff allocation in a booking system, it is essential to establish various security boundaries. The user-agent interaction forms one boundary, while the backend systems represent another. These backend systems may interact with external parties, necessitating secure management of incoming and outgoing requests. Additionally, the ambient agent receives requests to perform tasks, requiring secure communication with the business's backend APIs and the ability to update existing bookings. These considerations are crucial to ensure the secure operation of the agentic AI framework.",multi_hop_specific_query_synthesizer
"How does the integration of vertical AI in healthcare enhance medical comprehension and visualization, and what are the specific value additions it provides?","['<1-hop>\n\n### [518.96s] Value Additions of Vertical AI\nThe vertical AI layer includes several value additions, such as:\n\n- **Industry-Specific Model Adaptation**: Tailored knowledge and terminology relevant to healthcare customers.\n- **Proprietary Data Utilization**: Incorporation of industry-specific workflows and decision-making logic that aligns with established processes.\n- **Seamless Integration**: The ability to connect with industry-specific systems, such as healthcare systems and open banking APIs.\n- **Regulatory Compliance**: Development of API products that adhere to industry regulations, ensuring that the solutions are both effective and compliant.', ""<2-hop>\n\n## [25.28s] Discussion on Vertical AI\nThe focus of today's discussion is on vertical AI, which is a significant aspect of the ongoing track dedicated to specialized AI applications. Before delving into vertical AI, it is essential to clarify what generic AI entails.\n\n### [38.24s] Understanding Generic AI\nGeneric AI, often referred to as general-purpose AI, has been widely used for various personal and business tasks. It is designed to handle a broad range of applications. However, we are transitioning from this general-purpose AI, which is built for diverse uses, to a more specialized form known as vertical AI. This shift allows for the development of specific AI solutions tailored to industries such as healthcare, legal, and financial services.""]","The integration of vertical AI in healthcare enhances medical comprehension and visualization by providing industry-specific model adaptation, which includes tailored knowledge and terminology relevant to healthcare customers. It also utilizes proprietary data to incorporate industry-specific workflows and decision-making logic that align with established processes. Furthermore, vertical AI ensures seamless integration with healthcare systems and adheres to regulatory compliance, making the solutions both effective and compliant. This specialized approach allows for the development of AI solutions that are specifically tailored to the healthcare industry, thereby improving the overall efficiency and effectiveness of medical practices.",multi_hop_specific_query_synthesizer
"How does the LLaV A-Med model perform on the OmniMedVQA benchmark compared to other models, and what are the computational advantages of H-LoRA over MoELoRA in large-scale tasks?","['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15']","The LLaV A-Med model, with 7 billion parameters, achieves an average score of 41.3 on the OmniMedVQA benchmark, outperforming models like Med-Flamingo and BLIP-2 but falling behind models such as HuatuoGPT-Vision and HealthGPT-L14. In terms of computational efficiency, H-LoRA offers significant advantages over MoELoRA in large-scale tasks. While MoELoRA introduces a linear increase in additional time complexity with respect to the number of experts k, resulting in a complexity of O(5k + 1), H-LoRA maintains a fixed additional time complexity of O(6), independent of k. This makes H-LoRA more computationally efficient, particularly as the number of experts increases.",multi_hop_specific_query_synthesizer
How HealthGPT-M3 do in MRI super-resolution reconstruction?,"['<1-hop>\n\nC.6 Case Study\nFigures 11 and 12 illustrate examples of modality transformation and super-resolution reconstruction. In Figure 11, the results\ngenerated by our method in the CT (MRI) to MRI (CT) transformation task are highly close to the ground truth, effectively\nguiding the model in the transformation across different regions. For the MRI super-resolution reconstruction task, Figure 12\ndemonstrates the accuracy of our method in restoring scan image details, accurately reconstructing the essential details of the\nimage.\nTable 11: The experimental results for the four reconstruction tasks.\nCT(Brain) CT(Pelvis) MRI (Brain) MRI(Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\nSEED-X 20.18 27.66 112.11 21.53 28.02 102.87 4.90 27.62 112.86 6.31 27.89 106.21\nUnified-IO 2 83.93 36.09 17.95 85.36 35.10 25.46 87.50 34.25 25.47 86.31 33.53 29.80\nHealthGPT-M3 91.73 36.42 15.46 94.26 37.30 12.53 88.76 33.97 27.05 84.40 33.11 32.62\n34.08\n15.87\n9.16\n5.62\n13.33\n21.94\nHealthGPT\nLLaVA-Med\nHuatuoGPT-Vision\nLlama-3.2\nInternVL-2\nShow-o\nHuman\nEvaluation\n(a) (b)\nFigure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.\n17']","HealthGPT-M3 demonstrates high accuracy in MRI super-resolution reconstruction, with a SSIM of 88.76, PSNR of 33.97, and MSE of 27.05, effectively restoring scan image details and accurately reconstructing essential details of the image.",multi_hop_specific_query_synthesizer
What role does Rania Khalaf play in the development of agentic AI and identity access management?,"[""<1-hop>\n\n## [10.80s] Overview of Previous Discussion\nIn the first video of this series, Geethika discussed some of the capabilities already introduced for securing agent AI. Today's session will take a step back to explore concepts around identity access management for agent AI, providing real-world examples and discussing why traditional identity management will not suffice for securing agent AI.\n\n## [41.44s] Guest Introduction\nGeethika is joined by Rania Khalaf, the Chief AI Officer, and Ayesha Disanayake, who leads the R&D effort for identity access management for agentic AI.\n\n## [61.92s] Understanding Agentic AI\nRania begins by explaining the basics of agentic AI and providing real-world examples. She notes that with the advent of foundation models and generative AI, there has been a significant improvement in conversational AI. Initially, many applications embedded calls to generative AI systems, focusing primarily on question answering and natural language processing. For instance, ChatGPT is an application that utilizes the GPT family of models to facilitate interaction. Another example is Gmail, where users can refine their messages with the help of Gemini.""]","Rania Khalaf is the Chief AI Officer who explains the basics of agentic AI and provides real-world examples. She highlights the improvements in conversational AI with the advent of foundation models and generative AI. Her role involves discussing the integration of these advancements in applications like ChatGPT and Gmail, which utilize generative AI systems for enhanced interaction and message refinement.",multi_hop_specific_query_synthesizer
"What role does Aishad play in the governance and security of agent access, and how does it relate to AI models?","[""<1-hop>\n\n## [2456.80s] Governance and Security of Agent Access\nTo secure agents' access to various systems, it is necessary to consider the governance aspect. This involves understanding the different trust boundaries, particularly the line connecting agents to AI models. Governance and guardrail requirements arise from this relationship, and Aishad will elaborate on this with examples.\n\n### [2493.84s] Transition to Governance\nThe governance side of things is crucial. Initially, Aayisha covered the security aspect, which involves granting necessary permissions and ensuring that agents are properly tracked and auditable. Now, we will delve into the governance aspect, where our AI gateway offering plays a significant role. \n\nOur API management team has been refining this offering over the past few years to make it more user-friendly and scalable, with input from customers and users. We are continuously evolving, and I will present our current capabilities and future plans.""]","Aishad plays a role in elaborating on the governance and security of agent access by providing examples that highlight the governance aspect. This involves understanding the trust boundaries, particularly the connection between agents and AI models. Governance and guardrail requirements arise from this relationship, which Aishad will further explain.",multi_hop_specific_query_synthesizer
How does MoELoRA's computational complexity compare to H-LoRA in medical visual comprehension tasks?,"['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15', '<2-hop>\n\nTable 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual\ncomprehension and generation tasks.\nComp. Gen.\nVQA-RAD SLAKE PathVQAModel\nclose all close all close all\nMMMU\n-Med OMVQA RECOM MTRANS SR\nTraining\nTime\nHealthGPT w/\n+LoRA 71.3 57.2 70.0 53.4 76.4 38.6 41.30 65.10 62.67 59.99 65.88 1.00×\n+MoELoRA 72.5 57.2 66.4 52.4 73.2 36.0 39.30 64.90 67.31 59.76 65.91 1.49×\n+H-LoRA 73.7 55.9 74.6 56.4 78.7 39.7 43.30 68.50 67.69 60.30 66.14 1.00×\nTable 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.\nComp. Gen.\nVQA-RAD SLAKE PathVQA CT MRITraining Strategy\nclose all close all close all\nMMMU\n-Med OMVQA Brain Pelvis Brain Pelvis\nMixed-Training 56.6 37.9 45.0 32.9 65.7 33.6 44.0 48.9 65.64 62.75 56.61 50.77HealthGPT w/ 3-stage-Training 72.5 55.2 77.9 59.6 79.7 49.0 42.7 68.5 70.84 72.99 65.26 61.33\nFigure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c)\nillustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.\nhad a training time approximately 50% longer than LoRA.\nFigure 5 illustrates the performance of the three PEFT meth-\nods in medical visual comprehension and generation tasks\nacross different ranks, with H-LoRA consistently outper-\nforming the other methods in all scenarios, demonstrating\nsignificant advantages in handling diverse tasks.\nDifferent Learning Strategy. We propose a three-stage\nlearning strategy for H-LoRA that decouples comprehension\nand generation tasks. Unlike methods that train both tasks\nsimultaneously, our approach reduces performance degra-\ndation from task conflicts (see Table 5). In the medical vi-\nsual comprehension task, mixed training causes catastrophic\nforgetting and degrades visual reconstruction, whereas our\nstrategy effectively uses the medical embedding knowledge\nin pre-trained LLMs to mitigate these conflicts. Meanwhile,\nwe examine how fusing heterogeneous H-LoRA plugins in\nthe second training stage results in minimal performance\ndegradation. Detailed results are in the Appendix.\nHierarchical Visual Perception Analysis. We conduct an\nablation analysis on visual perceptual inputs for comprehen-\nsion and generation tasks. Figure 6 shows that comprehen-\nsion tasks converge more efficiently with abstract-grained\ninputs, while generation tasks perform better with concrete-\ngrained inputs. This highlights the importance of the hier-\narchical visual perception we propose, suggesting that tai-\nloring visual inputs for specific tasks at different hierarchies\ncan significantly improve efficiency.\nReport-to-CXR Task. We further explore the medical im-\nage generation task without reference images, using a small\namount of MIMIC-CXR data (Johnson et al. 2019) for in-\nstruction fine-tuning. Figure 7 annotates images with vary-\ning injury degrees and locations, comparing them to healthy\nCXR images. We observe thatHealthGPT effectively gen-\nerates CXR images based on the instructions, showcasing its\npotential in healthcare education and auxiliary diagnosis.\n6 Conclusion\nIn this paper, we introduceHealthGPT, a Med-LVLM that\nunifies medical vision-language comprehension and gen-\neration through a novel heterogeneous knowledge adap-\ntation approach. Experimental results demonstrate that\nHealthGPT achieves significant performance improve-\nments across multiple medical comprehension and genera-\ntion tasks, showcasing its potential for healthcare applica-\n8']","MoELoRA introduces a linear increase in additional time complexity with respect to the number of experts k, resulting in a complexity of O(5k + 1). In contrast, H-LoRA's additional time complexity is fixed at O(6), independent of k. This makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. In medical visual comprehension tasks, H-LoRA consistently outperforms MoELoRA, demonstrating significant advantages in handling diverse tasks.",multi_hop_specific_query_synthesizer
How does retrieval-augmented generation improve the efficiency of large language models in processing medical data?,"[""<1-hop>\n\n**Time Range: 00:10:01 - 00:20:02**\n\n# [1253.20s] Introduction to Retrieval-Augmented Generation\nTo address these challenges, the solution lies in retrieval-augmented generation (RAG). This approach is gaining attention as it allows for more efficient use of data within large language models (LLMs). The core idea is straightforward: rather than inputting all available information into the model's prompt, only the relevant data should be included. However, determining what is relevant poses a significant challenge.\n\n## [1298.16s] The RAG Process\nRAG suggests that before incorporating data into prompts, one should first index the data. This can be achieved using vector embeddings and a vector database. The process involves creating a search index, which allows for efficient retrieval of relevant information when a question or task arises. For instance, similar to how Google retrieves links based on a search query, RAG utilizes an index to find pertinent information, which is then fed to the LLM to generate answers.""]","Retrieval-augmented generation (RAG) improves the efficiency of large language models (LLMs) in processing medical data by allowing only relevant data to be included in the model's prompt. This is achieved by first indexing the data using vector embeddings and a vector database, creating a search index. This index enables efficient retrieval of pertinent information, similar to how search engines like Google operate, which is then fed to the LLM to generate answers. This approach addresses the challenge of determining relevance and optimizes the use of data within LLMs.",multi_hop_specific_query_synthesizer
"How does the AI agent enhance the appointment rescheduling process for Sarah, and what are the broader implications of AI in personalized service delivery?","[""<1-hop>\n\n### [1109.52s] AI Agent for Appointment Rescheduling\nIn contrast, an AI agent can streamline this process. For instance, an AI receptionist can quickly access Sarah's health records and provide her with information about upcoming appointments. Sarah can then request to move her cardiology appointment to the next week, and the AI agent can offer several options for her to choose from, confirming the appointment and sending an SMS without the need for manual intervention.\n\n## [27.04s] Overview of the AI Landscape\nThe earlier sessions provided insights into the current AI landscape, highlighting the opportunities available in this space. The speakers emphasize the main areas where organizations can capitalize and achieve various use cases. AI can facilitate personalized service delivery, enabling 24/7 support and assistance to users, thereby increasing operational efficiency and fostering innovation in previously unexplored areas.""]","The AI agent enhances the appointment rescheduling process for Sarah by quickly accessing her health records and providing her with information about upcoming appointments. Sarah can request to move her cardiology appointment to the next week, and the AI agent offers several options for her to choose from, confirming the appointment and sending an SMS without manual intervention. Broader implications of AI in personalized service delivery include enabling 24/7 support and assistance to users, increasing operational efficiency, and fostering innovation in previously unexplored areas.",multi_hop_specific_query_synthesizer
How does the LLaV A-Med dataset contribute to the performance of medical visual comprehension tasks compared to other models?,"['<1-hop>\n\n（a） （b）\nFigure 8: VL-Health dataset collection distribution.\nA.3 VL-Health\nThe construction of theVL-Health dataset involves two key steps:(i) data collection, (ii) data processing, as detailed below:\nData Collection: During the collection phase, we carefully considered the diversity of medical images and the complexity of\nthe tasks, selecting appropriate subsets for comprehension and generation tasks. For comprehension tasks, we selected datasets\nsuch as VQA-RAD (Lau et al. 2018), SLAKE (Liu et al. 2021), PathVQA (He et al. 2020), and MIMIC-CXR-VQA (Bae et al.\n2024), which cover various medical imaging modalities like radiology and pathology, and include professional annotations\nto assist the model in learning tasks such as lesion detection and disease diagnosis. Additionally, large-scale multi-modal\ndatasets like LLaV A-Med (Li et al. 2024b) and PubMedVision (Chen et al. 2024a) were included to provide broader medical\nknowledge support and facilitate the training of complex reasoning tasks. For generation tasks, we focused on four mainstream\ntask categories: super-resolution image generation, modality conversion, text-to-image generation, and image reconstruction.\nThe IXI (Davies et al. 2014) dataset, containing a large number of healthy brain MRI images, is suitable for training super-\nresolution models; the MIMIC-CHEST-XRAY (Bae et al. 2024) dataset, with X-ray images and their corresponding textual\nreports, is appropriate for text-to-image generation tasks; the SynthRAD2023 (Thummerer et al. 2023) dataset provides a large\nnumber of paired CT and MRI images, supporting modality conversion model training; for image reconstruction tasks, we\nrewrote and adjusted the LLaV A-558k (Liu et al. 2024b) dataset.\nData Processing: After data collection, we performed filtering and processing of the raw data. For VisualQA tasks, we stan-\ndardized the data entries into two forms: open-ended questions and single-choice questions, enabling flexible training and\nevaluation. Additionally, considering that multi-image data has a minimal impact on performance but introduces extra padding\nand training time, we excluded multi-image data. For the scanned image data in generation tasks, we applied slicing extrac-\ntion, image registration, data augmentation, and normalization to treat 2D images as visual inputs for model training or used\nVQGAN-generated indices to supervise the generation tasks.\nData Statistics This section provides detailed statistical information about the VL-Health dataset to offer a more compre-\nhensive understanding.\nData Overview: To ensure a balanced development of the model’s comprehension and generation capabilities, in addition\nto the LLaV A-558k and PubMedVision-PT datasets used for alignment, the VL-Health dataset ultimately selected 765,802\nadditional visual question-answering (VQA) training samples (to endow the model with visual comprehension and instruction-\nfollowing capabilities) and 783,045 generation training samples (to provide the model with reconstruction and visual generation\ninstruction-following abilities). This contributes to the transfer of knowledge between comprehension and generation tasks, en-\nhancing the model’s overall performance. For medical image comprehension tasks, images were selected from VQA-RAD (ap-\nproximately 450 images), SLAKE (approximately 630 images), PathVQA (approximately 2,600 images), MIMIC-CXR-VQA\n(approximately 52,000 images), LLaV A-Med (approximately 61,000 images), and PubMedVision (approximately 500,000 im-\nages). Multiple question-answer pairs were retained for each image to enhance the model’s understanding and generalization\nof the image content. Table 8 shows the data distribution ofVL-Health for three-stage learning strategy, where mixed-47k is\nbased on the sampling of all data in stage-1.\nDiversity and Quality Assessment: VL-Health covers 11 modalities, including CT, MRI, X-ray, microscopy, OCT, ultra-\nsound, and fundus photography, which aids the model in learning features from various modalities. The dataset also encom-\npasses a wide range of diseases, from common to rare, and from localized lesions to systemic diseases, including pulmonary\ndiseases, skeletal abnormalities, brain lesions, tumors, cardiovascular diseases, and cellular abnormalities. This provides com-\nprehensive training support to the model, enabling it to learn the characteristics and diagnosis of various diseases.\n13', '<2-hop>\n\nTable 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension\ntasks. Bold and underlined text indicates the best performance and second-best performance, respectively.\nVQA-RAD↑ SLAKE↑ PathVQA↑Type Model # Params Medical\nLVLM close all close all close all\nMMMU\n-Med ↑ OMVQA↑ Avg.↑\nComp. Only\nMed-Flamingo 8.3B ✓ 58.6 43.0 47.0 25.5 61.9 31.3 28.7 34.9 41.4\nLLaV A-Med 7B ✓ 60.2 48.1 58.4 44.8 62.3 35.7 30.0 41.3 47.6\nHuatuoGPT-Vision 7B ✓ 66.9 53.0 59.8 49.1 52.9 32.0 42.0 50.0 50.7\nBLIP-2 6.7B ✗ 43.4 36.8 41.6 35.3 48.5 28.8 27.3 26.9 36.1\nLLaV A-v1.5 7B ✗ 51.8 42.8 37.1 37.7 53.5 31.4 32.7 44.7 41.5\nInstructBLIP 7B ✗ 61.0 44.8 66.8 43.3 56.0 32.3 25.3 29.0 44.8\nYi-VL 6B ✗ 52.6 42.1 52.4 38.4 54.9 30.9 38.0 50.2 44.9\nInternVL2 8B ✗ 64.9 49.0 66.6 50.1 60.0 31.9 43.3 54.5 52.5\nLlama-3.2 11B ✗ 68.9 45.5 72.4 52.1 62.8 33.6 39.3 63.2 54.7\nComp. & Gen.\nShow-o 1.3B ✗ 50.6 33.9 31.5 17.9 52.9 28.2 22.7 45.7 42.6\nUnified-IO 2 7B ✗ 46.2 32.6 35.9 21.9 52.5 27.0 25.3 33.0 33.8\nJanus 1.3B ✗ 70.9 52.8 34.7 26.9 51.9 27.9 30.0 26.8 33.5\nHealthGPT-M3 3.8B ✓ 73.7 55.9 74.6 56.4 78.7 39.7 43.3 68.5 61.3\nHealthGPT-L14 14B ✓ 77.7 58.3 76.4 64.5 85.9 44.4 49.2 74.4 66.4\nTable 2: The experimental results for the four modality conversion tasks.\nCT to MRI (Brain) CT to MRI (Pelvis) MRI to CT (Brain) MRI to CT (Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\npix2pix 71.09 32.65 36.85 59.17 31.02 51.91 78.79 33.85 28.33 72.31 32.98 36.19\nCycleGAN 54.76 32.23 40.56 54.54 30.77 55.00 63.75 31.02 52.78 50.54 29.89 67.78\nBBDM 71.69 32.91 34.44 57.37 31.37 48.06 86.40 34.12 26.61 79.26 33.15 33.60\nVmanba 69.54 32.67 36.42 63.01 31.47 46.99 79.63 34.12 26.49 77.45 33.53 31.85\nDiffMa 71.47 32.74 35.77 62.56 31.43 47.38 79.00 34.13 26.45 78.53 33.68 30.51\nHealthGPT-M3 79.38 33.03 33.48 71.81 31.83 43.45 85.06 34.40 25.49 84.23 34.29 27.99\nHealthGPT-L14 79.73 33.10 32.96 71.92 31.87 43.09 85.31 34.29 26.20 84.96 34.14 28.13\nmodality conversion). Notably, by this stage, the word em-\nbedding layer and output head have been fine-tuned, only the\nH-LoRA modules and adapter modules need to be trained.\nThis strategy significantly improves the model’s adaptability\nand flexibility across different tasks.\n5 Experiments\n5.1 Data and Experimental Setup\nData Details. We curate VL-Health dataset (see Fig-\nure 4). For medical visual comprehension, we leverage\nmultiple medical-specific datasets, including PubMedVi-\nsion (Chen et al. 2024a), LLaV A-Med (Li et al. 2024b),\nPathVQA (He et al. 2020), MIMIC-CXR-VQA (Bae et al.\n2024), SLAKE (Liu et al. 2021), and VQA-RAD (Lau\net al. 2018). Additionally, we incorporate high-quality open-\nworld data from LLaV A-1.5 (Liu et al. 2024b) to preserve\nthe model’s general knowledge and instruction-following\ncapabilities. For generation tasks, we construct a recon-\nstruction dataset based on LLaV A-558k (Liu et al. 2024b),\nand also explore two key tasks in personalized medical\nimage enhancement—super-resolution and modality con-\nversion—using the IXI (Davies et al. 2014) and Syn-\nthRAD2023 (Thummerer et al. 2023) datasets. Detailed data\nselection and instruction templates are in the Appendix.\nModel Details. We select CLIP-L/14 (Radford et al. 2021)\nas the visual encoder and used the hidden states of its\nsecond and penultimate layers as concrete-grained and\nabstract-grained features for model’s dynamic hierarchical\nvisual perception. Drawing on the successful experiences of\nLLaV A, we employ a MLP to align the multi-modal fea-\nture embeddings. We choose the parameter-efficient phi-3-\nmini (Abdin et al. 2024) and phi-4 (Abdin et al. 2024) as the\nbase model. For visual comprehension and generation tasks,\nwe set the rank of H-LoRA to 16 and 64, with four experts.\nAdditionally, we use the f8-8192 version of VQGAN as the\nimage indexing and upsampling module.\n5.2 Main Experiments\nComprehension. We compare HealthGPT with several\nexisting models, including medical-specific LVLMs (e.g.,\nMed-Flamingo (Moor et al. 2023), LLaV A-Med (Li et al.\n2024b), HuatuoGPT-Vision (Chen et al. 2024a)) as well\nas recent open-world LVLMs (e.g., BLIP-2 (Li et al.\n2023b), LLaV A-v1.5 (Liu et al. 2024b), InstructBLIP (Dai\net al. 2023), Yi-VL (Young et al. 2024), InternVL2 (Chen\n6']","The LLaV A-Med dataset, as part of the VL-Health dataset, provides a substantial number of images (approximately 61,000) for medical image comprehension tasks, which aids in enhancing the model's understanding and generalization of image content. In comparison to other models, LLaV A-Med, with 7 billion parameters, achieves notable performance on medical visual comprehension tasks, scoring 60.2 on VQA-RAD, 48.1 on SLAKE, and 58.4 on PathVQA. These scores indicate that LLaV A-Med performs competitively, with its average score of 47.6 being higher than several other models like Med-Flamingo and BLIP-2, but slightly lower than models like HuatuoGPT-Vision and HealthGPT variants, which achieve higher scores across various tasks.",multi_hop_specific_query_synthesizer
"How does the LLaV A-Med model perform on the OmniMedVQA benchmark, and what role does the VL-Health dataset play in its training?","['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15', '<2-hop>\n\n（a） （b）\nFigure 8: VL-Health dataset collection distribution.\nA.3 VL-Health\nThe construction of theVL-Health dataset involves two key steps:(i) data collection, (ii) data processing, as detailed below:\nData Collection: During the collection phase, we carefully considered the diversity of medical images and the complexity of\nthe tasks, selecting appropriate subsets for comprehension and generation tasks. For comprehension tasks, we selected datasets\nsuch as VQA-RAD (Lau et al. 2018), SLAKE (Liu et al. 2021), PathVQA (He et al. 2020), and MIMIC-CXR-VQA (Bae et al.\n2024), which cover various medical imaging modalities like radiology and pathology, and include professional annotations\nto assist the model in learning tasks such as lesion detection and disease diagnosis. Additionally, large-scale multi-modal\ndatasets like LLaV A-Med (Li et al. 2024b) and PubMedVision (Chen et al. 2024a) were included to provide broader medical\nknowledge support and facilitate the training of complex reasoning tasks. For generation tasks, we focused on four mainstream\ntask categories: super-resolution image generation, modality conversion, text-to-image generation, and image reconstruction.\nThe IXI (Davies et al. 2014) dataset, containing a large number of healthy brain MRI images, is suitable for training super-\nresolution models; the MIMIC-CHEST-XRAY (Bae et al. 2024) dataset, with X-ray images and their corresponding textual\nreports, is appropriate for text-to-image generation tasks; the SynthRAD2023 (Thummerer et al. 2023) dataset provides a large\nnumber of paired CT and MRI images, supporting modality conversion model training; for image reconstruction tasks, we\nrewrote and adjusted the LLaV A-558k (Liu et al. 2024b) dataset.\nData Processing: After data collection, we performed filtering and processing of the raw data. For VisualQA tasks, we stan-\ndardized the data entries into two forms: open-ended questions and single-choice questions, enabling flexible training and\nevaluation. Additionally, considering that multi-image data has a minimal impact on performance but introduces extra padding\nand training time, we excluded multi-image data. For the scanned image data in generation tasks, we applied slicing extrac-\ntion, image registration, data augmentation, and normalization to treat 2D images as visual inputs for model training or used\nVQGAN-generated indices to supervise the generation tasks.\nData Statistics This section provides detailed statistical information about the VL-Health dataset to offer a more compre-\nhensive understanding.\nData Overview: To ensure a balanced development of the model’s comprehension and generation capabilities, in addition\nto the LLaV A-558k and PubMedVision-PT datasets used for alignment, the VL-Health dataset ultimately selected 765,802\nadditional visual question-answering (VQA) training samples (to endow the model with visual comprehension and instruction-\nfollowing capabilities) and 783,045 generation training samples (to provide the model with reconstruction and visual generation\ninstruction-following abilities). This contributes to the transfer of knowledge between comprehension and generation tasks, en-\nhancing the model’s overall performance. For medical image comprehension tasks, images were selected from VQA-RAD (ap-\nproximately 450 images), SLAKE (approximately 630 images), PathVQA (approximately 2,600 images), MIMIC-CXR-VQA\n(approximately 52,000 images), LLaV A-Med (approximately 61,000 images), and PubMedVision (approximately 500,000 im-\nages). Multiple question-answer pairs were retained for each image to enhance the model’s understanding and generalization\nof the image content. Table 8 shows the data distribution ofVL-Health for three-stage learning strategy, where mixed-47k is\nbased on the sampling of all data in stage-1.\nDiversity and Quality Assessment: VL-Health covers 11 modalities, including CT, MRI, X-ray, microscopy, OCT, ultra-\nsound, and fundus photography, which aids the model in learning features from various modalities. The dataset also encom-\npasses a wide range of diseases, from common to rare, and from localized lesions to systemic diseases, including pulmonary\ndiseases, skeletal abnormalities, brain lesions, tumors, cardiovascular diseases, and cellular abnormalities. This provides com-\nprehensive training support to the model, enabling it to learn the characteristics and diagnosis of various diseases.\n13']","The LLaV A-Med model, with 7 billion parameters, achieves an average score of 41.3 on the OmniMedVQA benchmark, outperforming several other models in specific tasks such as CT and X-ray. The VL-Health dataset plays a crucial role in training models like LLaV A-Med by providing a diverse collection of medical images and tasks. It includes approximately 61,000 images specifically for medical image comprehension tasks, which helps enhance the model's understanding and generalization capabilities across various medical imaging modalities.",multi_hop_specific_query_synthesizer
"How does the retrieval-augmented generation (RAG) process enhance the efficiency of large language models in healthcare applications, and what challenges does it address?","[""<1-hop>\n\n**Time Range: 00:10:01 - 00:20:02**\n\n# [1253.20s] Introduction to Retrieval-Augmented Generation\nTo address these challenges, the solution lies in retrieval-augmented generation (RAG). This approach is gaining attention as it allows for more efficient use of data within large language models (LLMs). The core idea is straightforward: rather than inputting all available information into the model's prompt, only the relevant data should be included. However, determining what is relevant poses a significant challenge.\n\n## [1298.16s] The RAG Process\nRAG suggests that before incorporating data into prompts, one should first index the data. This can be achieved using vector embeddings and a vector database. The process involves creating a search index, which allows for efficient retrieval of relevant information when a question or task arises. For instance, similar to how Google retrieves links based on a search query, RAG utilizes an index to find pertinent information, which is then fed to the LLM to generate answers.""]","The retrieval-augmented generation (RAG) process enhances the efficiency of large language models (LLMs) in healthcare applications by allowing for the inclusion of only relevant data in the model's prompt, rather than inputting all available information. This is achieved by first indexing the data using vector embeddings and a vector database, creating a search index that facilitates efficient retrieval of pertinent information when a question or task arises. This approach addresses the challenge of determining what information is relevant, thereby optimizing the use of data within LLMs and improving their performance in generating accurate and contextually appropriate responses.",multi_hop_specific_query_synthesizer
"How does LLaVA-Med perform in modality transformation and super-resolution reconstruction tasks compared to other models, and what are the implications for medical visual comprehension?","['<1-hop>\n\nC.6 Case Study\nFigures 11 and 12 illustrate examples of modality transformation and super-resolution reconstruction. In Figure 11, the results\ngenerated by our method in the CT (MRI) to MRI (CT) transformation task are highly close to the ground truth, effectively\nguiding the model in the transformation across different regions. For the MRI super-resolution reconstruction task, Figure 12\ndemonstrates the accuracy of our method in restoring scan image details, accurately reconstructing the essential details of the\nimage.\nTable 11: The experimental results for the four reconstruction tasks.\nCT(Brain) CT(Pelvis) MRI (Brain) MRI(Pelvis)Model SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓ SSIM↑ PSNR↑ MSE↓\nSEED-X 20.18 27.66 112.11 21.53 28.02 102.87 4.90 27.62 112.86 6.31 27.89 106.21\nUnified-IO 2 83.93 36.09 17.95 85.36 35.10 25.46 87.50 34.25 25.47 86.31 33.53 29.80\nHealthGPT-M3 91.73 36.42 15.46 94.26 37.30 12.53 88.76 33.97 27.05 84.40 33.11 32.62\n34.08\n15.87\n9.16\n5.62\n13.33\n21.94\nHealthGPT\nLLaVA-Med\nHuatuoGPT-Vision\nLlama-3.2\nInternVL-2\nShow-o\nHuman\nEvaluation\n(a) (b)\nFigure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.\n17']","LLaVA-Med is evaluated in the context of modality transformation and super-resolution reconstruction tasks, as illustrated in Figures 11 and 12. The results show that LLaVA-Med's performance is highly close to the ground truth in CT to MRI and MRI to CT transformation tasks, effectively guiding the model across different regions. In the MRI super-resolution reconstruction task, LLaVA-Med accurately restores scan image details, reconstructing essential details with high precision. The experimental results in Table 11 indicate that LLaVA-Med, along with other models like HealthGPT-M3 and Unified-IO 2, achieves high scores in metrics such as SSIM, PSNR, and MSE across various tasks, demonstrating its effectiveness in medical visual comprehension and modality conversion tasks.",multi_hop_specific_query_synthesizer
How LLaV A-Med help in training AI models for medical visual comprehension and modality conversion tasks?,"['<1-hop>\n\n（a） （b）\nFigure 8: VL-Health dataset collection distribution.\nA.3 VL-Health\nThe construction of theVL-Health dataset involves two key steps:(i) data collection, (ii) data processing, as detailed below:\nData Collection: During the collection phase, we carefully considered the diversity of medical images and the complexity of\nthe tasks, selecting appropriate subsets for comprehension and generation tasks. For comprehension tasks, we selected datasets\nsuch as VQA-RAD (Lau et al. 2018), SLAKE (Liu et al. 2021), PathVQA (He et al. 2020), and MIMIC-CXR-VQA (Bae et al.\n2024), which cover various medical imaging modalities like radiology and pathology, and include professional annotations\nto assist the model in learning tasks such as lesion detection and disease diagnosis. Additionally, large-scale multi-modal\ndatasets like LLaV A-Med (Li et al. 2024b) and PubMedVision (Chen et al. 2024a) were included to provide broader medical\nknowledge support and facilitate the training of complex reasoning tasks. For generation tasks, we focused on four mainstream\ntask categories: super-resolution image generation, modality conversion, text-to-image generation, and image reconstruction.\nThe IXI (Davies et al. 2014) dataset, containing a large number of healthy brain MRI images, is suitable for training super-\nresolution models; the MIMIC-CHEST-XRAY (Bae et al. 2024) dataset, with X-ray images and their corresponding textual\nreports, is appropriate for text-to-image generation tasks; the SynthRAD2023 (Thummerer et al. 2023) dataset provides a large\nnumber of paired CT and MRI images, supporting modality conversion model training; for image reconstruction tasks, we\nrewrote and adjusted the LLaV A-558k (Liu et al. 2024b) dataset.\nData Processing: After data collection, we performed filtering and processing of the raw data. For VisualQA tasks, we stan-\ndardized the data entries into two forms: open-ended questions and single-choice questions, enabling flexible training and\nevaluation. Additionally, considering that multi-image data has a minimal impact on performance but introduces extra padding\nand training time, we excluded multi-image data. For the scanned image data in generation tasks, we applied slicing extrac-\ntion, image registration, data augmentation, and normalization to treat 2D images as visual inputs for model training or used\nVQGAN-generated indices to supervise the generation tasks.\nData Statistics This section provides detailed statistical information about the VL-Health dataset to offer a more compre-\nhensive understanding.\nData Overview: To ensure a balanced development of the model’s comprehension and generation capabilities, in addition\nto the LLaV A-558k and PubMedVision-PT datasets used for alignment, the VL-Health dataset ultimately selected 765,802\nadditional visual question-answering (VQA) training samples (to endow the model with visual comprehension and instruction-\nfollowing capabilities) and 783,045 generation training samples (to provide the model with reconstruction and visual generation\ninstruction-following abilities). This contributes to the transfer of knowledge between comprehension and generation tasks, en-\nhancing the model’s overall performance. For medical image comprehension tasks, images were selected from VQA-RAD (ap-\nproximately 450 images), SLAKE (approximately 630 images), PathVQA (approximately 2,600 images), MIMIC-CXR-VQA\n(approximately 52,000 images), LLaV A-Med (approximately 61,000 images), and PubMedVision (approximately 500,000 im-\nages). Multiple question-answer pairs were retained for each image to enhance the model’s understanding and generalization\nof the image content. Table 8 shows the data distribution ofVL-Health for three-stage learning strategy, where mixed-47k is\nbased on the sampling of all data in stage-1.\nDiversity and Quality Assessment: VL-Health covers 11 modalities, including CT, MRI, X-ray, microscopy, OCT, ultra-\nsound, and fundus photography, which aids the model in learning features from various modalities. The dataset also encom-\npasses a wide range of diseases, from common to rare, and from localized lesions to systemic diseases, including pulmonary\ndiseases, skeletal abnormalities, brain lesions, tumors, cardiovascular diseases, and cellular abnormalities. This provides com-\nprehensive training support to the model, enabling it to learn the characteristics and diagnosis of various diseases.\n13']","LLaV A-Med, as part of the VL-Health dataset, provides large-scale multi-modal data that supports broader medical knowledge and facilitates the training of complex reasoning tasks. It contributes to the model's visual comprehension capabilities by being part of the visual question-answering (VQA) training samples, which enhance the model's understanding and generalization of medical image content. Additionally, LLaV A-Med aids in modality conversion tasks by being included in the dataset that covers various medical imaging modalities, allowing the model to learn features from different types of medical images.",multi_hop_specific_query_synthesizer
"How does LLaV A-Med enhance visual-text alignment in medical contexts, and how does it compare to other models in the OmniMedVQA benchmark?","['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15', '<2-hop>\n\ntential task interference. TLS: In the first and second stages,\ngiven the heterogeneity between comprehension and gener-\nation tasks, we first train H-LoRA plugins for HealthGPT\nto incorporate both medical comprehension and generation\nknowledge, thus endowing the LLMs with capabilities for\nvision-language alignment and vision-to-vision reconstruc-\ntion. Additionally, through minimal mixed-task training, we\nbuilt fusion embedding layers and output heads that merge\ntext and visual tokens, establishing a unified LVLM founda-\ntion for visual instruction fine-tuning. In the third stage, by\nonly training the H-LoRA plugins, HealthGPT is able to\nrapidly adapt to a wide range of downstream medical tasks,\ncovering various types of medical comprehension and gen-\neration tasks.\nTo effectively implement our approach, we have cu-\nrated a dataset for training unified medical LVLMs, called\nVL-Health, including seven comprehension tasks and five\ngeneration tasks (Figure 1). Through quantitative analysis\nand validation on multi-modal tasks, the results demonstrate\nthat HealthGPT is capable of unifying medical multi-\nmodal abilities in data-constrained scenarios, achieving per-\nformance comparable to or better than existing state-of-the-\nart (SOTA) models across multiple metrics. Overall, the\nmain contributions of this paper are summarized as follows:\n• Unified Med-LVLM. We introduce HealthGPT,\nwhich, to the best of our knowledge, is the first unified\nframework for multi-modal comprehension and genera-\ntion in complex medical scenarios.\n• Effective Learning Paradigm. We present H-LoRA, an\noptimized multi-LoRA PEFT architecture based on task-\ngated decoupling, is designed to effectively mitigate data\nconflict issues.\n• Holistic Training Dataset. We curated VL-Health, a\ncomprehensive dataset designed for both comprehension\nand generation tasks.\n• Superior Downstream Improvements : Extensive ex-\nperiments are conducted and the results confirm\nHealthGPT’s effectiveness in medical vision-language\ncomprehension and generation.\n2 Related Work\nMedical Vision Large Language Models. Recently, medi-\ncal vision large language models (Med-VLLMs) have made\nsignificant progress, demonstrating excellent performance\nin understanding medical images and responding to human\nqueries based on these images (Zhou et al. 2023; Tian et al.\n2023). XrayGPT (Thawkar et al. 2023) combines a med-\nical visual encoder (MedClip) (Wang et al. 2022) with a\nfine-tuned LLM , using a simple linear transformation layer\nto achieve alignment between visual and textual informa-\ntion, significantly enhancing the understanding of medical\nimages. On this basis, LLaV A-Med (Li et al. 2024b) fur-\nther enhances visual-text alignment in medical contexts by\nselecting high-quality image-text pairs from PubMed pa-\npers and synthesized VQA datasets. BiomedGPT (Luo et al.\n2024b) employs a BERT-style encoder and GPT-style de-\ncoder architecture, pre-trained on interdisciplinary datasets.\nCompared to commercial models like Med-PaLM (Singhal\net al. 2023), BiomedGPT significantly reduces model size\nwhile maintaining superior performance. However, issues\nof language adaptability and dataset specificity still remain.\nTo address these, HuatuoGPT-Vision (Chen et al. 2024a)\nintroduces the PubMedVision dataset, which contains 1.3\nmillion high-quality medical samples, significantly improv-\ning the model’s adaptability across diverse medical applica-\ntions. However, current Med-VLLMs mainly focus on med-\nical comprehension and lack the capability for the medical\nvision-language generation.\nUnified Visual Comprehension and Generation Mod-\nels. Recent research has increasingly concentrated on cre-\nating unified LVLMs that are adept at understanding and\nproducing content across various visual modalities. NExT-\nGPT (Wu et al. 2023) achieves perception and generation for\narbitrary combinations of multi-modal inputs and outputs by\naligning LLMs. Similarly, SEED (Ge et al. 2023), SEED-\nX (Ge et al. 2024), and DreamLLM (Dong et al. 2023) em-\nploy learnable queries and leverage next-token prediction to\ngenerate visual tokens, providing conditional inputs to exter-\nnal generation modules. Unlike these methods, which func-\ntion as external conditioners, Unified-IO (Lu et al. 2022),\nUnified-IO 2 (Lu et al. 2024), and Chameleon (Team 2024)\ninternalize multi-modal generation tasks within a unified\nTransformer architecture by extending multi-modal vocab-\nularies, enabling direct generation based on next-token pre-\ndiction. Building on this concept, Lumina-mGPT (Liu et al.\n2024a) and ANOLE (Chern et al. 2024) further enhance the\ngeneration capabilities of unified models using high-quality\ndata, particularly improving the quality and flexibility of im-\nage generation.\n3 Preliminaries\nLarge Vision-Language Models.The input to a LVLM typ-\nically consists of an image ximg and a discrete text sequence\nxtxt. The visual encoder Eimg converts the input image ximg\ninto a sequence of visual tokens V = [ vi]Nv\ni=1, while the\ntext sequence xtxt is mapped into a sequence of text to-\nkens T = [ ti]Nt\ni=1 using an embedding function Etxt. The\nLLM MLLM(·|θ) models the joint probability of the token\nsequence U = {V, T }, which is expressed as:\nPθ(R|U) =\nNrY\ni=1\nPθ(ri|{U, r<i}), (1)\nwhere R = [ri]Nr\ni=1 is the text response sequence. The LVLM\niteratively generates the next token ri based on r<i. The op-\ntimization objective is to minimize the cross-entropy loss of\nthe response R. It is worth noting that most LVLMs adopt\n3']","LLaV A-Med enhances visual-text alignment in medical contexts by selecting high-quality image-text pairs from PubMed papers and synthesized VQA datasets. In the OmniMedVQA benchmark, LLaV A-Med, with 7 billion parameters, achieves an average score of 41.3, outperforming Med-Flamingo and BLIP-2 but falling behind models like HuatuoGPT-Vision and HealthGPT-M3. This indicates that while LLaV A-Med is effective in aligning visual and textual information, there are other models that achieve higher performance in medical visual question answering tasks.",multi_hop_specific_query_synthesizer
"How does the W2 Integrator facilitate the implementation of AI systems in healthcare, considering the historical context of verticalization?","[""<1-hop>\n\n## [1492.00s] Final Architecture Overview\nThe final architecture includes two new components: one for collecting and indexing information from hotel owners and another for querying the database to find answers. The AI agent will ask questions from the RAG, which will not only fetch data but also provide natural language responses back to the agent.\n\n# [1560.96s] Transition to Implementation\nAt this point, Anja will take over to discuss how to build this system using the W2 Integrator.\n\n### [139.44s] Historical Context\nThe concept of verticalization is not new. Even the largest horizontal tech companies have historically tailored their sales organizations and product features to cater to specific customer needs within particular domains. For instance, WSO2's solutions team exemplifies this approach by offering vertical solutions built on top of their core products, such as integration, identity and access management, and API management. This enables them to communicate effectively with customers and provide precise solutions in areas like open healthcare and open banking.""]","The W2 Integrator facilitates the implementation of AI systems in healthcare by providing a framework that allows for the collection and indexing of information, as well as querying databases to find answers. This aligns with the historical context of verticalization, where companies like WSO2 have tailored their solutions to meet specific domain needs, such as open healthcare. By using the W2 Integrator, AI systems can be effectively built to cater to the unique requirements of the healthcare sector, enhancing medical comprehension and visualization.",multi_hop_specific_query_synthesizer
How machine learning change AI landscape and make it more accessible with large language models?,"['<1-hop>\n\n## [115.60s] Defining Key Terminologies\nBefore we proceed, it is important to define some key terminologies. AI refers to any system that can simulate human intelligence. This can range from simple functions to complex machine learning models and deep learning architectures. Generative AI, a subset of AI, focuses on creating original content, which can include text, audio, and visual elements.\n\n### [155.28s] Understanding Large Language Models\nLarge language models (LLMs), such as ChatGPT from OpenAI, are examples of generative AI that specialize in natural language processing. They are designed to understand and generate text, making them a significant advancement in the field.', '<2-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.']","Machine learning has significantly changed the AI landscape by making it more accessible to a broader audience. In the past, building AI applications required extensive work with numerical and categorical features, including data processing and cleaning, which was primarily the domain of AI developers and machine learning experts. However, with the advent of large language models, such as ChatGPT from OpenAI, users can now perform various tasks like text summarization or sentiment analysis without needing to fine-tune the model. These models are versatile, available as APIs, and can be applied across different domains, allowing users to interact with them through conversational interfaces, thus simplifying the process and making AI more user-friendly.",multi_hop_specific_query_synthesizer
How is GPT utilized in agentic AI applications like ChatGPT and Gmail?,"[""<1-hop>\n\n## [10.80s] Overview of Previous Discussion\nIn the first video of this series, Geethika discussed some of the capabilities already introduced for securing agent AI. Today's session will take a step back to explore concepts around identity access management for agent AI, providing real-world examples and discussing why traditional identity management will not suffice for securing agent AI.\n\n## [41.44s] Guest Introduction\nGeethika is joined by Rania Khalaf, the Chief AI Officer, and Ayesha Disanayake, who leads the R&D effort for identity access management for agentic AI.\n\n## [61.92s] Understanding Agentic AI\nRania begins by explaining the basics of agentic AI and providing real-world examples. She notes that with the advent of foundation models and generative AI, there has been a significant improvement in conversational AI. Initially, many applications embedded calls to generative AI systems, focusing primarily on question answering and natural language processing. For instance, ChatGPT is an application that utilizes the GPT family of models to facilitate interaction. Another example is Gmail, where users can refine their messages with the help of Gemini.""]","GPT is utilized in agentic AI applications such as ChatGPT and Gmail to enhance conversational AI capabilities. ChatGPT uses the GPT family of models to facilitate interaction, focusing on question answering and natural language processing. In Gmail, users can refine their messages with the help of Gemini, which is another application of generative AI.",multi_hop_specific_query_synthesizer
Wht role does the AI gateway play in managing model failover and prompt management?,"['<1-hop>\n\n# [3897.20s] Prompt Management\nThe final section addresses prompt management, which involves templating and decorating prompts. This aspect is crucial for development use cases that interact with the AI gateway. While the AI gateway primarily handles governance, it also allows for the implementation of policies.\n\n### [373.68s] Unique Challenges of Agentic AI\nAyesha notes that traditional access management is not a new concept, but it faces unique challenges in the AI landscape. As agents gain access to APIs and operate autonomously, they can perform tasks on behalf of multiple users, complicating permission management. For example, an agent assisting with recruitment may interact with applicants and managers, necessitating a nuanced understanding of permissions and access rights.', '<2-hop>\n\n## [3770.80s] Model Failover Policy\nFor example, the model failover policy can be illustrated using ChatGPT. Initially, users receive responses from GPT-4, which are informative and high-quality. However, once the personal quota is exceeded, users may fall back to a less capable version, such as GPT-4 Mini, resulting in subpar responses. The AI gateway can emulate this behavior by routing requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region.\n\n## [3843.12s] Incorporating New Models\nOrganizations may also want to incorporate new models into their systems. For instance, if a new model is released, the system can initially route a small percentage of requests to it and gradually increase this percentage as confidence in the model grows.']","The AI gateway plays a crucial role in managing both model failover and prompt management. In terms of model failover, the AI gateway can route requests to a primary endpoint until it is exhausted, at which point it can fall back to a secondary endpoint, potentially in a different region. This ensures continuity in service even when the primary model's quota is exceeded. For prompt management, the AI gateway handles governance and allows for the implementation of policies, which is essential for development use cases that interact with it.",multi_hop_specific_query_synthesizer
What Malit say about WSO2 app and how agents help?,"['<1-hop>\n\n## [503.36s] Defining an Agent\nAgents introduce proactivity, allowing them to perform actions autonomously. An agent is defined as a system or entity capable of executing tasks by interacting with tools, such as APIs and databases, with the assistance of a large language model.\n\n# [556.40s] WSO2 Mobile App Development\nMalit discusses a WSO2 mobile app developed for the last WSO2 conference. Initially, the app was static and lacked AI features. To enhance user experience, the team added various features, including personalized scheduling and a chatbot for user interaction.\n\n**Time Range: 00:10:00 - 00:20:08**']","Malit discusses a WSO2 mobile app developed for the last WSO2 conference, which was initially static and lacked AI features. To enhance user experience, the team added features like personalized scheduling and a chatbot for user interaction. Agents, defined as systems capable of executing tasks autonomously by interacting with tools, could potentially assist in further enhancing such applications by introducing proactivity and autonomy.",multi_hop_specific_query_synthesizer
What is LLaV A Med and how it used in VL-Health data?,"['<1-hop>\n\nTable 8: Data distribution of VL-Health in three-stage learning strategy.\nMedical Task Stage-1 Stage-2\nComp. LLaV A-558k, PubMedVision-PT Mixed-47kGen. LLaV A-558k\nMedical Task Stage-3\nComp. LLaV A Med, MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, VQA-RAD\nGen. IXI, SynthRAD2023, MIMIC-CHEST-XRAY\nData Format. All data samples are converted into a unified instruction-response format for training and evaluation. Specifi-\ncally, the VL-Health dataset consists of the following components:\n• Task Type: Specifies the granularity of visual features output by the visual encoder and selects the corresponding H-\nLoRA submodule. For generation tasks, the response also includes multi-modal tokens corresponding to VQ indices.\n• Task Instruction: Guides the model to interpret the image and generate a response, covering various aspects of the\nimage and specifying the output format.\n• Response: The textual output generated based on the task instruction and input image, ensuring it meets the question and\nformatting requirements.\n• Input Image: Provides the visual signal for the model to process.\n• Target Image Index: In generation tasks, this is added as a multi-modal token to the response for autoregressive\ngeneration.\nB Analysis of Heterogeneous Low-Rank Adaptation\nWe propose H-LoRA, which utilizes hard routing selection to allocate plugins for knowledge learning and representation across\ntasks, thereby preventing conflicts arising from heterogeneous knowledge. Furthermore, within each task, we optimized based\non MoELoRA, enhancing performance while reducing computational overhead. The pseudocode is detailed Algorithm 1.\nAlgorithm 1: H-LoRA Algorithm\nInput: concrete-grained visual features FCon, abstract-grained visual featuresFAbs, comprehension-based H-LoRA modules\n({AComp.\ni }k\ni=1, RComp.\nouter ), generation-based H-LoRA modules({AGen.\ni }k\ni=1, RGen.\nouter), task type T (comprehension or generation),\nnumber of LoRA experts k, origin linear layer weights W0, text features T , hidden state h\nOutput: final output O\n// Select task-specific image features\nif T = generation task then\nFimg ← FCon\nelse if T = comprehension task then\nFimg ← FAbs\nend if\nU ←concat(Fimg, T ) // Concatenate image features and text features\n{Ai}k\ni=1, {Bi}k\ni=1, Router ← {AT\ni }k\ni=1, {BT\ni }k\ni=1, RT\nouter // Assign task-specific H-LoRA submodule\n// Merge LoRA experts’ matrices\nAmerged ← concat({Ai}k\ni=1)\nBmerged ← concat({Bi}k\ni=1)\nW ←R(h) // Generate routing weights based on input hidden state x\nWexpanded ← α × W/r ⊗ 1r // Expand routing weights to match merged matrices\nOH-LoRA ← (x · Amerged ⊙ Wexpanded) · Bmerged // Compute H-LoRA output using element-wise multiplication\nO ←x · W0 + OH-LoRA // Add H-LoRA output to pre-trained weights to get final output\nReturn O\nWe further analyzed the computational overhead differences between MoELoRA and H-LoRA. Assuming that both methods\nuse the same number of LoRA experts k, we can compare their time complexity from the perspective of the operational steps\ninvolved.\nComputational Overhead of MoELoRA. In MoELoRA, the operations involving the expert matrix mainly include the fol-\nlowing steps: (i) Expert Multiplication : MoELoRA requires 2k multiplications with the LoRA experts. (ii) Router Multi-\nplication: One multiplication with the Router is required. (iii) Router Output Expansion : MoELoRA needs to perform k\n14']","LLaV A Med is part of the data distribution used in the VL-Health dataset, specifically in the third stage of the learning strategy for comprehension tasks. It is combined with other datasets like MIMIC CXR VQA, PubMedVision-FT, LLaV A-665k, PathVQA, SLAKE, and VQA-RAD to train and evaluate models in a unified instruction-response format.",multi_hop_specific_query_synthesizer
How large language models make AI more accessible and what role retrieval-augmented generation play in using these models efficiently?,"['<1-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.', ""<2-hop>\n\n**Time Range: 00:10:01 - 00:20:02**\n\n# [1253.20s] Introduction to Retrieval-Augmented Generation\nTo address these challenges, the solution lies in retrieval-augmented generation (RAG). This approach is gaining attention as it allows for more efficient use of data within large language models (LLMs). The core idea is straightforward: rather than inputting all available information into the model's prompt, only the relevant data should be included. However, determining what is relevant poses a significant challenge.\n\n## [1298.16s] The RAG Process\nRAG suggests that before incorporating data into prompts, one should first index the data. This can be achieved using vector embeddings and a vector database. The process involves creating a search index, which allows for efficient retrieval of relevant information when a question or task arises. For instance, similar to how Google retrieves links based on a search query, RAG utilizes an index to find pertinent information, which is then fed to the LLM to generate answers.""]","Large language models have made AI more accessible by allowing users to perform tasks like text summarization or sentiment analysis without needing to fine-tune the models. These models are versatile and available as APIs, making them easily accessible for developers. Retrieval-augmented generation (RAG) plays a role in using these models efficiently by ensuring that only relevant data is included in the model's prompt. This is achieved by indexing data using vector embeddings and a vector database, allowing for efficient retrieval of pertinent information, which is then fed to the large language model to generate answers.",multi_hop_specific_query_synthesizer
How does the AI gateway facilitate prompt management and address the unique challenges of agentic AI in terms of governance and permission management?,"['<1-hop>\n\n# [3897.20s] Prompt Management\nThe final section addresses prompt management, which involves templating and decorating prompts. This aspect is crucial for development use cases that interact with the AI gateway. While the AI gateway primarily handles governance, it also allows for the implementation of policies.\n\n### [373.68s] Unique Challenges of Agentic AI\nAyesha notes that traditional access management is not a new concept, but it faces unique challenges in the AI landscape. As agents gain access to APIs and operate autonomously, they can perform tasks on behalf of multiple users, complicating permission management. For example, an agent assisting with recruitment may interact with applicants and managers, necessitating a nuanced understanding of permissions and access rights.']","The AI gateway facilitates prompt management by allowing for the templating and decorating of prompts, which is crucial for development use cases. It primarily handles governance by implementing policies that ensure proper management of AI interactions. In terms of addressing the unique challenges of agentic AI, the gateway helps manage the complexities of permission management as agents gain access to APIs and operate autonomously. This involves a nuanced understanding of permissions and access rights, especially when agents perform tasks on behalf of multiple users, such as interacting with applicants and managers in recruitment scenarios.",multi_hop_specific_query_synthesizer
"Howw does the W integratorr play a role in the AI transformationn processs, especiallyy in the contextt of Vertical AI and its importannce in B2B and B2C scenarioss?","['<1-hop>\n\n## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.']","The W integrator plays a crucial role in the AI transformation process by providing the necessary toolkit for development, which is essential for implementing AI concepts in real life. This is particularly important in the context of Vertical AI, where a narrow and specific focus is more advantageous than a broad and generalized approach. In B2B and B2C scenarios, consumers demand solutions tailored to their unique business needs, and the W integrator facilitates this transformation by enabling the step-by-step implementation of AI solutions.",multi_hop_specific_query_synthesizer
How does the use of a Large Language Model (LLM) for creating personalized profiles exemplify AI transformation in business operations?,"['<1-hop>\n\n## [2816.00s] Calling the LLM for Personalized Profiles\nWith the data structure established, the next step involves calling the LLM (Large Language Model) using the gathered data. The objective is to create a personalized profile for the user. This process does not require an agent or retrieval-augmented generation; instead, it focuses on directly utilizing the LLM.\n\nTo facilitate this, a connection to the model provider has been created. A prompt will be generated for the LLM, specifying the need for a personalized profile. It is crucial to be precise in the prompt to ensure an accurate response. A comprehensive prompt has been prepared and will be used to guide the LLM in generating the desired output.', '<2-hop>\n\n## [77.52s] Understanding AI Transformation\nAI transformation is a term that, while not universally adopted, is gaining traction in discussions about enhancing business operations. The fundamental idea is to leverage AI to improve various aspects of an organization, leading to increased productivity, efficiency, and user experience. Additionally, AI can unlock new capabilities that were previously unattainable.\n\nAI has emerged as a powerful tool, particularly with the advent of generative AI. This technology allows us to create solutions that were once complex and resource-intensive, such as chatbots. Previously, developing a chatbot required extensive rule-based or knowledge-based systems. Now, it is as simple as writing a prompt and connecting to a large language model (LLM) with minimal financial investment.\n\nThe current landscape presents numerous opportunities, and businesses must adapt to these new capabilities to remain competitive. Failing to embrace AI transformation could result in falling behind in a rapidly evolving market, where many organizations are striving to enhance their operations through AI.']","The use of a Large Language Model (LLM) for creating personalized profiles exemplifies AI transformation in business operations by showcasing how AI can enhance productivity and efficiency. In the process described, the LLM is directly utilized to generate personalized profiles without the need for an agent or retrieval-augmented generation, highlighting the streamlined and efficient nature of AI applications. This approach aligns with the broader concept of AI transformation, which involves leveraging AI to improve various organizational aspects, leading to increased productivity and user experience. The ability to create complex solutions, such as personalized profiles, with minimal financial investment and effort, demonstrates the transformative potential of AI in modern business practices.",multi_hop_specific_query_synthesizer
How does the integration of Gemini and vertical AI frameworks enhance healthcare customer support systems?,"[""<1-hop>\n\n## [10.80s] Overview of Previous Discussion\nIn the first video of this series, Geethika discussed some of the capabilities already introduced for securing agent AI. Today's session will take a step back to explore concepts around identity access management for agent AI, providing real-world examples and discussing why traditional identity management will not suffice for securing agent AI.\n\n## [41.44s] Guest Introduction\nGeethika is joined by Rania Khalaf, the Chief AI Officer, and Ayesha Disanayake, who leads the R&D effort for identity access management for agentic AI.\n\n## [61.92s] Understanding Agentic AI\nRania begins by explaining the basics of agentic AI and providing real-world examples. She notes that with the advent of foundation models and generative AI, there has been a significant improvement in conversational AI. Initially, many applications embedded calls to generative AI systems, focusing primarily on question answering and natural language processing. For instance, ChatGPT is an application that utilizes the GPT family of models to facilitate interaction. Another example is Gmail, where users can refine their messages with the help of Gemini."", '<2-hop>\n\n### [350.72s] Framework for Vertical AI\nThe vertical AI layer is built on existing frameworks, utilizing core large language models (LLMs) from companies like OpenAI, Anthropic, and Gemini. These foundational models serve as the base for horizontal AI applications. On top of this, supporting frameworks such as retrieval-augmented generation (RAG) and data infrastructure are integrated. The vertical layer introduces industry-specific model tuning and regulatory compliance, ensuring that the AI solutions are tailored to meet the unique needs of specific sectors.\n\n## [424.88s] Example: Healthcare Customer Support\nTo illustrate the effectiveness of vertical AI, consider a healthcare customer support requirement. At the foundational level, general-purpose LLMs provide basic language capabilities. Companies like Sierra and Decagon enhance these capabilities with frameworks optimized for customer support. The vertical AI layer then adds the necessary clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems. Without this tailored vertical layer, the AI solution would lack the understanding of healthcare nuances and regulatory constraints essential for real-world deployment.']","The integration of Gemini and vertical AI frameworks enhances healthcare customer support systems by utilizing core large language models (LLMs) from companies like Gemini to provide foundational language capabilities. These are then optimized with frameworks tailored for customer support, such as those from Sierra and Decagon. The vertical AI layer further adds clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems, ensuring that the AI solutions are specifically tuned to meet the unique needs and regulatory constraints of the healthcare sector.",multi_hop_specific_query_synthesizer
How does MoELoRA compare to H-LoRA in terms of computational efficiency and performance in medical visual comprehension tasks?,"['<1-hop>\n\nexpansion operations on the Router’s output weights to generate the appropriate shapes that match the dimensions of the in-\nput and LoRA experts while iterating through the experts. (iv) Dot Product: For each expanded Router weight, a dot product\nwith the intermediate state of the expert is required, resulting in k multiplications. (v) Addition: Finally, k addition operations\nare required to accumulate the results from each LoRA expert into the final output. Assuming the time complexity of each\noperation is the same, the additional time complexity introduced when equipping a fully connected layer with MoELoRA is:\nO(2k+1+ k+k+k) = O(5k+1). Thus, MoELoRA introduces an additional time overhead ofO(5k+1) during computation.\nH-LoRA. In contrast to MoELoRA, H-LoRA reduces the computational overhead by concatenating the LoRA expert matrices.\nSpecifically: (i) Expert Multiplication: H-LoRA merges all LoRA experts by directly creating a larger A and B matrix, instead\nof performing independent operations for each expert. This process can be implemented through matrix initialization without\nadditional concatenation operations. Therefore, only 2 multiplications with the LoRA experts are required. (ii) Router Multi-\nplication: H-LoRA still requires one multiplication with the Router. (iii) Router Output Expansion : H-LoRA only requires\none expansion operation on the Router’s output weights. (iv) Dot Product: H-LoRA only requires one dot product between\nthe Router’s output and the expert’s intermediate state. (v) Addition: Finally, H-LoRA only requires one addition operation\nto accumulate the LoRA expert results into the intermediate state. Therefore, the additional time complexity introduced by\nH-LoRA is: O(2 + 1 + 1 + 1 + 1) =O(6).\nComparing the two, we see that MoELoRA introduces a linear increase in additional time complexity with respect to the\nnumber of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6),\nindependent of k. We observe that when k is small, the time complexity differences between MoELoRA and H-LoRA are\nnegligible. However, as k increases, MoELoRA’s computational overhead grows linearly, while H-LoRA’s remains constant.\nThis makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. We will\nfurther demonstrate the significant advantage of H-LoRA in training time in subsequent experiments, validating its efficiency\nin practical applications.\nC Supplemental Experimental Results\nIn this section, we include additional experiments to demonstrate the superiority of HealthGPT and articulate our design\nphilosophy.\nC.1 Results: OmniMedVQA Benchmark\nOmniMedVQA (Hu et al. 2024) is a novel, large-scale medical visual question answering (VQA) benchmark designed to\nencompass various modalities and anatomical regions by collecting diverse images from multiple medical datasets. Our exper-\nimental results are presented in Table 9.\nTable 9: Performance comparison of OmniMedVQA Benchmark.\nOmniMedVQA↑Type Model # Params Medical\nLVLM CT X-ray FDM MiS OCT MRI USS Avg.\nComp. Only\nMed-Flamingo 8.3B ✓ 30.1 33.9 25.5 37.0 60.0 27.6 30.4 34.9\nLLaV A-Med 7B ✓ 28.4 32.8 42.7 31.6 55.3 45.0 53.6 41.3\nHuatuoGPT-Vision 7B ✓ 35.3 41.5 51.4 62.3 59.3 40.4 60.1 50.0\nBLIP-2 6.7B ✗ 26.6 29.1 22.3 36.9 29.1 22.7 21.4 26.9\nLLaV A-v1.5 7B ✗ 28.0 55.7 35.5 42.1 49.2 52.9 49.7 44.7\nInstructBLIP 7B ✗ 20.1 22.2 34.1 30.6 38.6 31.9 25.5 29.0\nYi-VL 6B ✗ 51.2 47.1 27.7 62.6 67.6 55.0 40.3 50.2\nInternVL2 8B ✗ 40.2 57.9 53.2 64.0 59.1 58.1 49.1 54.5\nLlama-3.2 11B ✗ 37.6 55.2 71.4 82.1 62.5 65.2 68.6 63.2\nComp. & Gen.\nShow-o 1.3B ✗ 29.0 50.4 30.9 22.0 30.8 34.2 33.8 33.0\nUnified-IO 2 7B ✗ 10.8 37.7 12.3 25.3 32.6 30.9 37.7 26.8\nJanus 1.3B ✗ 24.9 54.8 35.9 62.7 54.2 50.7 36.8 45.7\nHealthGPT-M3 3.8B ✓ 35.3 81.9 54.6 88.2 89.3 78.5 51.4 68.5\nHealthGPT-L14 14B ✓ 39.0 86.6 64.1 88.6 99.7 80.9 62.2 74.4\nThrough our analysis, we make the following observations: (i) HealthGPT-M3 outperforms other models in 4 out of 7\nsub-tasks, achieving an average score that exceeds cutting-edge medical Large Vision-Language Models (LVLMs) as well as\n15', '<2-hop>\n\nTable 3: Comparison results of super-resolution task.\nModel SSIM↑ PSNR↑ MSE↓ LPIPS↓\nSRGAN 71.34 32.01 41.27 24.50\nDASR 71.57 32.34 38.25 19.17\nReal-ESRGAN 67.30 31.87 42.57 20.64\nLIIF 73.27 32.13 40.14 22.93\nBSRGAN 69.97 31.97 41.52 28.72\nHealthGPT-M3 78.19 32.76 34.47 12.02\nHealthGPT-L14 77.94 32.71 35.19 12.43\nFigure 5: Performance comparison of LoRA, MoELoRA,\nand H-LoRA under different rank settings.\net al. 2024b), Llama-3.2 (Dubey et al. 2024)). Addition-\nally, we test several SOTA unified visual comprehension\nand generation models, including Show-o (Xie et al. 2024),\nUnified-IO 2 (Lu et al. 2024), and Janus (Wu et al.\n2024). The experimental results are shown in Table 1, with\nthe following key observations: (i) SOTA Results Com-\npared with LVLMs: In medical visual comprehension\ntasks, HealthGPT demonstrates superior performance,\nsignificantly outperforming both medical-specific models\n(e.g., HuatuoGPT-Vision) and general-purpose models (e.g.,\nLlama-3.2). (ii) Surpassing Current Unified LVLMs: De-\nspite being trained on billions of data points, unified mod-\nels still exhibit poor generalization performance in medi-\ncal visual comprehension. For instance, Unified-IO 2 scored\nonly 33.8. In contrast,HealthGPT-M3, with only 3.8B pa-\nrameters, scored 61.3 on the medical multi-modal unified\ntask, significantly outperforming existing unified models in\nmedical downstream scenarios. (iii) Stable Improvement\nwith Large Base Model: Our method demonstrates excel-\nlent scalability, with HealthGPT-L14 achieving a score\nof 66.4 in the larger model configuration. This result signif-\nicantly outperforms all other models, highlighting the effec-\ntiveness of scaling up the base model for enhanced perfor-\nmance in medical tasks.\nGeneration. We study three key tasks in medical imag-\ning. (i) Modality Conversion: In this task, we focus on\nthe conversion between CT and MRI modalities for the\nbrain and pelvic regions, designing four specific sub-tasks.\nAll comparative models (Pix2Pix (Isola et al. 2017), Cy-\ncleGAN (Zhu et al. 2017), BBDM (Li et al. 2023a),\n(%)\n(%)\n（a） （b）\nFigure 6: The loss visualization (a) and performance com-\nparison (b) with respect to different visual perceptions.\nVmamba (Liu et al. 2024e), and DiffMa (Wang et al.\n2024b)) trained a separate model for each sub-task, while\nHealthGPT unify all tasks into a single training process.\nThe experimental results, shown in Table 11, demonstrate\nthat our approach outperforms other methods across multi-\nple evaluation metrics. For instance, in the CT2MRI-Brain\ntask, HealthGPT-M3 achieves an SSIM of 79.38, signif-\nicantly surpassing traditional methods like Pix2Pix (71.09)\nand the recent DiffMa (71.47). (ii) Super-Resolution: We\nconduct 4× super-resolution experiments on the IXI dataset,\nwith the results presented in Table 3. Notably, most exist-\ning methods fail to fully leverage the prior knowledge of key\nstructures in medical images, resulting in significant short-\ncomings in detail recovery. In contrast, our method signif-\nicantly mitigates this issue. Specifically, HealthGPT-M3\nexcels in key metrics such as SSIM, PSNR, and ISE, achiev-\ning scores of 78.19, 32.76, and 34.47, respectively. Ad-\nditionally, HealthGPT-M3 achieves the lowest score of\n12.34, further validating its exceptional performance in hu-\nman visual perception. (iii) Reconstruction: We compare\nHealthGPT-M3 with unified models with reconstruction\ncapabilities, such as Unified-IO 2 and SEED-X. The results\nshow that our approach performs better controllability for vi-\nsual reconstruction. We also trainHealthGPT-L14 with a\nsimilar number of trainable parameters to the M3 version.\nHence, the similar performance between the two models\nmeets our expectations. Details are in the Appendix.\n5.3 In-Depth Study\nEffect of Heterogeneous Low-Rank Adaptation.H-LoRA\nprovides an optimized multi-LoRA architecture for multi-\ntask learning. We conduct extensive validation of this struc-\nture, with results presented in Table 4, comparing the per-\nformance of LoRA, MoELoRA, and H-LoRA in medical\nunified comprehension and generation tasks. In the majority\nof comprehension tasks and all generation tasks, H-LoRA\ndemonstrates superior performance, particularly in the Om-\nniMedVQA benchmark, where it improved from 64.90 to\n68.50. Notably, despite some applications of MoELoRA in\ncertain scenarios, it do not show advantages in this task and\n7']","MoELoRA introduces a linear increase in additional time complexity with respect to the number of experts k, resulting in a complexity of O(5k + 1), while H-LoRA’s additional time complexity is fixed at O(6), independent of k. This makes H-LoRA significantly more computationally efficient than MoELoRA, particularly in large-scale tasks. In terms of performance in medical visual comprehension tasks, H-LoRA demonstrates superior performance, particularly in the OmniMedVQA benchmark, where it improved from 64.90 to 68.50. Despite some applications of MoELoRA in certain scenarios, it does not show advantages in this task.",multi_hop_specific_query_synthesizer
What are the challenges in machine learning scalability and transparency?,"['<1-hop>\n\n## [115.60s] Defining Key Terminologies\nBefore we proceed, it is important to define some key terminologies. AI refers to any system that can simulate human intelligence. This can range from simple functions to complex machine learning models and deep learning architectures. Generative AI, a subset of AI, focuses on creating original content, which can include text, audio, and visual elements.\n\n### [155.28s] Understanding Large Language Models\nLarge language models (LLMs), such as ChatGPT from OpenAI, are examples of generative AI that specialize in natural language processing. They are designed to understand and generate text, making them a significant advancement in the field.', '<2-hop>\n\n**Time Range: 00:10:02 - 00:20:04**\n\n## [254.80s] Challenges in AI Scalability\nDespite these advancements, scalability remains a significant challenge in AI. Many organizations still face issues with scaling their AI solutions. However, improvements in speed are facilitating real-time interactions and capabilities accessible both in the cloud and at the edge.\n\n## [277.52s] Transparency and Explainability\nTransparency and explainability are ongoing challenges in machine learning. Progress is being made, as evidenced by the introduction of a transparency score that measures how transparent companies are regarding their model training processes. This score has notably increased for certain companies, indicating a move towards greater observability in AI systems.']","The challenges in machine learning scalability include issues with scaling AI solutions, although improvements in speed are helping facilitate real-time interactions both in the cloud and at the edge. Transparency and explainability are also ongoing challenges, with progress being made through the introduction of a transparency score that measures how transparent companies are about their model training processes.",multi_hop_specific_query_synthesizer
How generative AI change model performance and business operations?,"['<1-hop>\n\n# [939.84s] Evaluating Model Performance\nAn important aspect of our work involves evaluating model performance, especially in light of changes that may affect functionality. This is a significant area of research within the field of agents and generative AI, as these systems are inherently probabilistic. When the same prompt is called multiple times, it can yield different responses, complicating the testing process. \n\nTo address this, we need to establish methodologies and benchmark datasets to ensure consistent performance, particularly given the rapid advancements in technology. As we transition to new models every six months, it is vital to confirm that we do not lose any previously effective functionalities.', '<2-hop>\n\n## [77.52s] Understanding AI Transformation\nAI transformation is a term that, while not universally adopted, is gaining traction in discussions about enhancing business operations. The fundamental idea is to leverage AI to improve various aspects of an organization, leading to increased productivity, efficiency, and user experience. Additionally, AI can unlock new capabilities that were previously unattainable.\n\nAI has emerged as a powerful tool, particularly with the advent of generative AI. This technology allows us to create solutions that were once complex and resource-intensive, such as chatbots. Previously, developing a chatbot required extensive rule-based or knowledge-based systems. Now, it is as simple as writing a prompt and connecting to a large language model (LLM) with minimal financial investment.\n\nThe current landscape presents numerous opportunities, and businesses must adapt to these new capabilities to remain competitive. Failing to embrace AI transformation could result in falling behind in a rapidly evolving market, where many organizations are striving to enhance their operations through AI.']","Generative AI impacts model performance by introducing probabilistic elements that can yield different responses to the same prompt, complicating the testing process. This necessitates the establishment of methodologies and benchmark datasets to ensure consistent performance, especially as new models are adopted every six months. In terms of business operations, generative AI enhances productivity, efficiency, and user experience by simplifying complex tasks, such as developing chatbots, which previously required extensive rule-based systems. This transformation allows businesses to unlock new capabilities and remain competitive in a rapidly evolving market.",multi_hop_specific_query_synthesizer
What role does Arshad play in addressing governance challenges in AI services?,"['<1-hop>\n\n## [76.16s] Challenges in AI Application Deployment\nAs organizations develop new AI applications, it is crucial to consider the challenges that arise when transitioning from a development environment to production. While it may feel satisfactory to see something work in development, ensuring scalability in production is essential to prevent organizational setbacks. The speakers encourage audience participation, inviting questions and interactions throughout the session.\n\n## [125.20s] Governance in AI Services\nArshad begins discussing the governance aspect of AI services, referencing recent news cases where AI systems have produced inappropriate or harmful responses. Such incidents pose risks to organizations, as they are responsible for delivering these services to end users. It is vital to govern AI behavior effectively to prevent such occurrences.']","Arshad discusses the governance aspect of AI services, highlighting the importance of effectively governing AI behavior to prevent inappropriate or harmful responses, which pose risks to organizations responsible for delivering these services to end users.",multi_hop_specific_query_synthesizer
"How have large language models transformed the process of building AI applications, and what impact does this have on the accessibility of AI for non-experts?","['<1-hop>\n\n## [187.68s] The Current AI Landscape\nThe discussion now shifts to why AI is particularly relevant today. Although AI has been around for a long time, recent developments have made it accessible to a broader audience. Unlike in the past, when only AI developers and machine learning experts could build models, AI is now user-friendly. Previously, creating machine learning models required extensive work with numerical and categorical features, including data processing and cleaning. Today, users can simply interact with the model through conversational interfaces.\n\n### [244.00s] The Evolution of AI Applications\nIn the past, building AI applications involved a lengthy process of training, tuning, and deploying specific models. However, with the advent of large language models, users can now perform various tasks, such as text summarization or sentiment analysis, without needing to fine-tune the model. These models are versatile and can be applied across different domains. Additionally, they are available as APIs, making them easily accessible for developers.']","Large language models have transformed the process of building AI applications by eliminating the need for extensive training, tuning, and deploying of specific models. Users can now perform tasks such as text summarization or sentiment analysis without needing to fine-tune the model, thanks to the versatility of these models. This transformation has made AI more accessible to non-experts, as they can interact with AI through conversational interfaces and utilize APIs, which simplifies the process and broadens the audience that can effectively use AI technologies.",multi_hop_specific_query_synthesizer
How does Guard AI enhance PII detection and masking in healthcare AI systems?,"['<1-hop>\n\n## [3331.68s] Regex-Based PII Masking\nRegex-based PII (Personally Identifiable Information) masking allows users to define patterns, such as email addresses, that must not be matched in outgoing prompts. If an email is detected, the system replaces it with a dummy value, ensuring that sensitive information is not exposed while still allowing the LLM to function normally.\n\n## [3397.12s] Advanced PII Detection and Masking\nFor more ambiguous cases, advanced PII detection and masking techniques are employed. This involves using a framework called Guard AI, which utilizes LLMs to make decisions and perform reasoning. This combination of regex and advanced detection provides robust security for the egress gateway, preventing sensitive information from being leaked to the LLM.']","Guard AI enhances PII detection and masking in healthcare AI systems by utilizing large language models (LLMs) to make decisions and perform reasoning in more ambiguous cases. This advanced detection is combined with regex-based PII masking, which allows users to define patterns, such as email addresses, that must not be matched in outgoing prompts. This combination provides robust security for the egress gateway, preventing sensitive information from being leaked to the LLM.",multi_hop_specific_query_synthesizer
How does the MCP server help in integrating weather considerations into the AI agent's itinerary planning?,"['<1-hop>\n\n## [4584.64s] Integrating the Function into the AI Agent\nThe next step is to integrate this function into the AI agent. The tool will be designated as ""get personalized profile,"" and we will instruct the LLM to always use this tool to gather information about user preferences.\n\n## [4634.72s] Additional Tools and Weather Considerations\nAt this point, we have created three tools. If we want to consider weather conditions while planning the itinerary, we can connect to a specific MCP server that provides this information. An MCP server is already operational, allowing us to select the weather tool and incorporate it into our planning process.', ""<2-hop>\n\n## [651.84s] Personalization Agent\nA key component of the updated architecture is the personalization agent. This agent interacts with other components within the system. Upon receiving user consent, it utilizes the user's name and company information to conduct an internet search, thereby creating a personalized profile. The personalization agent employs two tools: the Surfer API, which retrieves a set of links relevant to the user, and the Scraper Web Scraper API, which scrapes content from those links. This process is iterative, continuing until the agent achieves its goal.\n\n## [720.96s] Introduction to MCP\nBefore delving into multi-agent systems, it is essential to briefly discuss the concept of the Multi-Component Protocol (MCP). The MCP standardizes how AI applications interact with external tools. The architecture of MCP includes concepts such as tools, resources, and prompts, which have been extensively discussed in AI labs.\n\nThe MCP introduces two new components to agent applications: the MCP client and the MCP server. The MCP client connects to the MCP host, allowing developers to access the MCP server without needing to write code for each individual tool connection. This simplifies the development process, enabling developers to focus on functionality rather than connectivity.""]","The MCP server aids in integrating weather considerations into the AI agent's itinerary planning by providing a standardized way for AI applications to interact with external tools. In this context, the MCP server is operational and allows the selection of a weather tool, which can be incorporated into the planning process. This integration is facilitated by the MCP's architecture, which includes the MCP client that connects to the MCP host, simplifying the development process by eliminating the need to write code for each individual tool connection.",multi_hop_specific_query_synthesizer
"How does Vertikal AI provide a competitive advntage in highly regulated industries like healthcare, and why is it more beneficial than generic AI solutions?","['<1-hop>\n\n## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.', '<2-hop>\n\n## [195.60s] Advantages of Vertical AI\nVertical AI offers several advantages, including:\n\n1. **Domain Expertise**: Vertical AI can deliver precision and relevance in critical applications.\n2. **Regulatory Alignment**: Industries such as healthcare, finance, and legal are highly regulated, necessitating strict adherence to data sharing and communication protocols.\n3. **Business Impact**: Vertical AI can drive automation and insights tailored to specific verticals, which generic solutions may not address.\n4. **Competitive Advantage**: Specialized tools designed for specific requirements provide a competitive edge.']","Vertical AI provides a competitive advantage in highly regulated industries such as healthcare by offering domain expertise and regulatory alignment. It delivers precision and relevance in critical applications, ensuring strict adherence to data sharing and communication protocols, which are essential in regulated sectors. Unlike generic AI solutions, Vertical AI is tailored to meet specific business needs, driving automation and insights that are aligned with industry-specific requirements, thereby offering a more advantageous approach.",multi_hop_specific_query_synthesizer
How MCP servers make it easier for agents to connect to APIs and what tools help manage these servers?,"['<1-hop>\n\n### [3190.24s] Visualizing MCP Functionality\nTo illustrate how MCP operates, consider a diagram featuring two agents, each equipped with a set of tools. These agents connect to APIs, necessitating the writing of specific code for each agent to handle API connections, input formatting, and output processing. This complexity can be mitigated by utilizing MCP servers, which centralize the logic and reduce redundancy in coding.\n\n## [3293.44s] Complexity of Architecture with MCP\nAs the architecture evolves, the introduction of MCPs adds complexity between data APIs and agent integration. For effective MCP server management, technologies such as Bijira and Coro can be employed. These tools facilitate the deployment of MCP servers both locally and remotely, ensuring flexibility in server management.']","MCP servers simplify the process for agents to connect to APIs by centralizing the logic, which reduces the need for writing specific code for each agent to handle API connections, input formatting, and output processing. This reduces redundancy in coding. For managing MCP servers effectively, technologies such as Bijira and Coro can be used. These tools facilitate the deployment of MCP servers both locally and remotely, ensuring flexibility in server management.",multi_hop_specific_query_synthesizer
"Why is vertical AI considered more advantageous than generic AI in addressing specific business needs, particularly in industries like healthcare?","['<1-hop>\n\n## [103.76s] Importance of Vertical AI\nVertical AI is crucial because generic AI does not adequately address all challenges, particularly in B2B and B2C scenarios. Consumers increasingly demand solutions that are specifically designed to meet their unique business needs. In an environment saturated with various AI solutions, a narrow and specific focus is more advantageous than a broad and generalized approach.\n\n## [19.92s] The Need for AI Transformation\nWe are currently undergoing an AI transformation, which we will discuss in detail, including examples from the business sector. The goal is to illustrate how we can implement AI transformation step by step using a specific business use case. Anjen will introduce a W integrator to facilitate this process, as implementing these concepts in real life requires the right toolkit for development. We will demonstrate how to achieve this transformation using the W integrator.', ""<2-hop>\n\n## [25.28s] Discussion on Vertical AI\nThe focus of today's discussion is on vertical AI, which is a significant aspect of the ongoing track dedicated to specialized AI applications. Before delving into vertical AI, it is essential to clarify what generic AI entails.\n\n### [38.24s] Understanding Generic AI\nGeneric AI, often referred to as general-purpose AI, has been widely used for various personal and business tasks. It is designed to handle a broad range of applications. However, we are transitioning from this general-purpose AI, which is built for diverse uses, to a more specialized form known as vertical AI. This shift allows for the development of specific AI solutions tailored to industries such as healthcare, legal, and financial services.""]","Vertical AI is considered more advantageous than generic AI in addressing specific business needs because it offers solutions that are specifically designed to meet unique business requirements. In industries like healthcare, where specialized applications are crucial, vertical AI provides a narrow and specific focus that is more beneficial than the broad and generalized approach of generic AI. This transition from general-purpose AI to vertical AI allows for the development of tailored AI solutions that better serve the needs of specific industries.",multi_hop_specific_query_synthesizer
How do large language models contribute to the functionality and transformation of AI agents in business operations?,"['<1-hop>\n\n## [2030.64s] The Functionality of AI Agents\nTo understand how AI agents operate, it is essential to recognize their components. An agent receives tasks from humans, has access to various tools (such as web services, APIs, and databases), and is connected to a large language model (LLM) for reasoning. Additionally, agents possess both short-term and long-term memory capabilities.\n\n### [2109.76s] Traits of AI Agents\nAI agents exhibit traits that enable them to reason, plan, act, learn, and adapt to their environment. They can also delegate tasks to other agents when necessary, leading to a multi-agent system, a concept that will be discussed in further detail in future sessions.', '<2-hop>\n\n## [77.52s] Understanding AI Transformation\nAI transformation is a term that, while not universally adopted, is gaining traction in discussions about enhancing business operations. The fundamental idea is to leverage AI to improve various aspects of an organization, leading to increased productivity, efficiency, and user experience. Additionally, AI can unlock new capabilities that were previously unattainable.\n\nAI has emerged as a powerful tool, particularly with the advent of generative AI. This technology allows us to create solutions that were once complex and resource-intensive, such as chatbots. Previously, developing a chatbot required extensive rule-based or knowledge-based systems. Now, it is as simple as writing a prompt and connecting to a large language model (LLM) with minimal financial investment.\n\nThe current landscape presents numerous opportunities, and businesses must adapt to these new capabilities to remain competitive. Failing to embrace AI transformation could result in falling behind in a rapidly evolving market, where many organizations are striving to enhance their operations through AI.']","Large language models (LLMs) contribute to the functionality of AI agents by providing reasoning capabilities, which are essential for the agents to perform tasks such as planning, learning, and adapting to their environment. These models are integral to the operation of AI agents, as they enable the agents to process and understand complex instructions. In the context of business operations, LLMs facilitate AI transformation by simplifying the development of solutions like chatbots, which previously required complex systems. By connecting to an LLM, businesses can enhance productivity and efficiency with minimal financial investment, thus unlocking new capabilities and improving user experience.",multi_hop_specific_query_synthesizer
How does VQGAN contribute to the HealthGPT architecture in terms of visual comprehension and generation tasks?,"['<1-hop>\n\nFigure 3: The HealthGPT architecture integrates hierarchical visual perception and H-LoRA, employing a task-specific hard\nrouter to select visual features and H-LoRA plugins, ultimately generating outputs with an autoregressive manner.\na design paradigm based on ViT, alignment adapters, and\npre-trained LLMs(Liu et al. 2023, 2024b), enabling quick\nadaptation to downstream tasks.\nVQGAN. VQGAN (Esser, Rombach, and Ommer 2021)\nemploys latent space compression and indexing mechanisms\nto effectively learn a complete discrete representation of im-\nages. VQGAN first maps the input imageximg to a latent rep-\nresentation z = E(x) through a encoder E. Then, the latent\nrepresentation is quantized using a codebookZ = {zk}K\nk=1,\ngenerating a discrete index sequence I = [im]N\nm=1, where\nim ∈ Zrepresents the quantized code index:\nI = Quantize(z|Z) = arg min\nzk∈Z\n∥z − zk∥2. (2)\nIn our approach, the discrete index sequence I serves as\na supervisory signal for the generation task, enabling the\nmodel to predict the index sequence ˆI from input conditions\nsuch as text or other modality signals. Finally, the predicted\nindex sequence ˆI is upsampled by the VQGAN decoder G,\ngenerating the high-quality image ˆximg = G(ˆI).\nLow Rank Adaptation. LoRA(Hu et al. 2021) effectively\ncaptures the characteristics of downstream tasks by intro-\nducing low-rank adapters. The core idea is to decompose\nthe bypass weight matrix ∆W ∈ Rdin×dout\ninto two low-\nrank matrices {A ∈ Rdin×r, B ∈ Rr×dout\n}, where r ≪\nmin{din, dout}, significantly reducing learnable parameters.\nThe output with the LoRA adapter for the input x is then\ngiven by:\nh = xW0 + αx∆W/r = xW0 + αxAB/r, (3)\nwhere matrix A is initialized with a Gaussian distribution,\nwhile the matrixB is initialized as a zero matrix. The scaling\nfactor α/r controls the impact of ∆W on the model.\n4 HealthGPT\n4.1 Unified Autoregressive Generation.\nHealthGPT (Figure 3) utilizes a discrete token representa-\ntion that covers both text and visual outputs, unifying visual\ncomprehension and generation as an autoregressive task. For\ncomprehension, Mllm receives the input joint sequence U\nand outputs a series of text token R = [ r1, r2, . . . , rNr ],\nwhere ri ∈ Vtxt, and Vtxt represents the LLM’s vocabulary:\nPθ(R | U) =\nNrY\ni=1\nPθ(ri | U, r<i). (4)\nFor generation, Mllm first receives a special start token\n⟨START IMG⟩, then generates a series of tokens corre-\nsponding to the VQGAN indices I = [ i1, i2, . . . , iNi ],\nwhere ij ∈ Vvq, and Vvq represents the index range of VQ-\nGAN. Upon completion of generation, the LLM outputs an\nend token ⟨END IMG⟩:\nPθ(I | U) =\nNiY\nj=1\nPθ(ij | U, i<j). (5)\nFinally, the generated index sequence I is fed into the de-\ncoder G, which reconstructs the target image ˆximg = G(I).\n4.2 Hierarchical Visual Perception\nGiven the differences in visual perception between compre-\nhension and generation tasks—where the former focuses on\nabstract semantics and the latter emphasizes complete se-\nmantics—we employ ViT to compress the image into dis-\ncrete visual tokens at multiple hierarchical levels. Specif-\nically, the image is converted into a series of features\n{f1, f2, . . . , fL} as it passes through L ViT blocks.\n4', '<2-hop>\n\nTo address the needs of various tasks, the hidden states\nare divided into two types: (i) Concrete-grained features\nFCon = {f1, f2, . . . , fk}, k < L, derived from the shal-\nlower layers of ViT, containing sufficient global features,\nsuitable for generation tasks; (ii) Abstract-grained features\nFAbs = {fk+1, fk+2, . . . , fL}, derived from the deeper\nlayers of ViT, which contain abstract semantic information\ncloser to the text space, suitable for comprehension tasks.\nThe task type T (comprehension or generation) deter-\nmines which set of features is selected as the input for the\ndownstream large language model:\nFimg\nT =\n(\nFCon, if T = generation task\nFAbs, if T = comprehension task (6)\nWe integrate the image featuresFimg\nT and text featuresT into\na joint sequence through simple concatenation, which is then\nfed into the LLM Mllm for autoregressive generation.\n4.3 Heterogeneous Knowledge Adaptation\nWe devise H-LoRA, which stores heterogeneous knowledge\nfrom comprehension and generation tasks in separate mod-\nules and dynamically routes to extract task-relevant knowl-\nedge from these modules. At the task level, for each task type\nT, we dynamically assign a dedicated H-LoRA submodule\nθT , which is expressed as:\nR = MLLM(U|θ, θT ), θ T = {AT , BT , RT\nouter}. (7)\nAt the feature level for a single task, H-LoRA integrates the\nidea of Mixture of Experts (MoE) (Masoudnia and Ebrahim-\npour 2014) and designs an efficient matrix merging and rout-\ning weight allocation mechanism, thus avoiding the signif-\nicant computational delay introduced by matrix splitting in\nexisting MoELoRA (Luo et al. 2024a). Specifically, we first\nmerge the low-rank matrices (rank = r) of k LoRA experts\ninto a unified matrix:\nAmerged, Bmerged = Concat({Ai}k\n1 ), Concat({Bi}k\n1 ), (8)\nwhere Amerged ∈ Rdin×rk and Bmerged ∈ Rrk×dout\n. The\nk-dimension routing layer generates expert weights W ∈\nRtoken num×k based on the input hidden state x, and these are\nexpanded to Rtoken num×rk as follows:\nWexpanded = αkW/r ⊗ 1r, (9)\nwhere ⊗ denotes the replication operation. The overall out-\nput of H-LoRA is computed as:\nOH-LoRA = (xAmerged ⊙ Wexpanded)Bmerged, (10)\nwhere ⊙ represents element-wise multiplication. Finally, the\noutput of H-LoRA is added to the frozen pre-trained weights\nto produce the final output:\nO = xW0 + OH-LoRA. (11)\n900\n800\n700\n600\n500\n400\n300\n200\n100\n0\nComp. Gen.\n(a) (b)\n783K765K\n（K）\nFigure 4: Data statistics of VL-Health.\n4.4 Training Pipeline\n1st Stage: Multi-modal Alignment. In the first stage, we\ndesign separate visual adapters and H-LoRA submodules for\nmedical unified tasks. For the medical comprehension task,\nwe train abstract-grained visual adapters using high-quality\nimage-text pairs to align visual embeddings with textual\nembeddings, thereby enabling the model to accurately de-\nscribe medical visual content. During this process, the pre-\ntrained LLM and its corresponding H-LoRA submodules\nremain frozen. In contrast, the medical generation task re-\nquires training concrete-grained adapters and H-LoRA sub-\nmodules while keeping the LLM frozen. Meanwhile, we ex-\ntend the textual vocabulary to include multimodal tokens,\nenabling the support of additional VQGAN vector quanti-\nzation indices. The model trains on image-VQ pairs, en-\ndowing the pre-trained LLM with the capability for image\nreconstruction. This design ensures pixel-level consistency\nof pre- and post-LVLM. The processes establish the initial\nalignment between the LLM’s outputs and the visual inputs.\n2nd Stage: Heterogeneous H-LoRA Plugin Adaptation.\nThe submodules of H-LoRA share the word embedding\nlayer and output head but may encounter issues such as\nbias and scale inconsistencies during training across dif-\nferent tasks. To ensure that the multiple H-LoRA plugins\nseamlessly interface with the LLMs and form a unified base,\nwe fine-tune the word embedding layer and output head us-\ning a small amount of mixed data to maintain consistency\nin the model weights. Specifically, during this stage, all H-\nLoRA submodules for different tasks are kept frozen, with\nonly the word embedding layer and output head being op-\ntimized. Through this stage, the model accumulates foun-\ndational knowledge for unified tasks by adapting H-LoRA\nplugins.\n3rd Stage: Visual Instruction Fine-Tuning. In the third\nstage, we introduce additional task-specific data to fur-\nther optimize the model and enhance its adaptability to\ndownstream tasks such as medical visual comprehension\n(e.g., medical QA, medical dialogues, and report generation)\nor generation tasks (e.g., super-resolution, denoising, and\n5']","VQGAN contributes to the HealthGPT architecture by employing latent space compression and indexing mechanisms to learn a discrete representation of images. In the HealthGPT framework, VQGAN maps an input image to a latent representation, which is then quantized into a discrete index sequence. This sequence serves as a supervisory signal for generation tasks, enabling the model to predict the index sequence from input conditions such as text. The predicted index sequence is upsampled by the VQGAN decoder to generate high-quality images. For visual comprehension tasks, HealthGPT utilizes hierarchical visual perception, where images are compressed into discrete visual tokens at multiple hierarchical levels using ViT. The task type determines whether concrete-grained features (suitable for generation) or abstract-grained features (suitable for comprehension) are used, integrating these image features with text features for autoregressive generation. Thus, VQGAN plays a crucial role in both visual comprehension and generation tasks within the HealthGPT architecture.",multi_hop_specific_query_synthesizer
How AI gateway help with prompt management and observability?,"['<1-hop>\n\n# [3897.20s] Prompt Management\nThe final section addresses prompt management, which involves templating and decorating prompts. This aspect is crucial for development use cases that interact with the AI gateway. While the AI gateway primarily handles governance, it also allows for the implementation of policies.\n\n### [373.68s] Unique Challenges of Agentic AI\nAyesha notes that traditional access management is not a new concept, but it faces unique challenges in the AI landscape. As agents gain access to APIs and operate autonomously, they can perform tasks on behalf of multiple users, complicating permission management. For example, an agent assisting with recruitment may interact with applicants and managers, necessitating a nuanced understanding of permissions and access rights.', '<2-hop>\n\n## [4142.16s] Observability and Logging\nFinally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored. This comprehensive approach allows for effective management and governance of the AI gateway, ensuring that all interactions are secure and compliant.\n\n**Time Range: 01:10:00 - 01:18:25**\n\n# [4200.40s] Introduction to API Usage with Guardrails\nBefore attempting to use the API with Guardrails, it is essential to understand how a use case would appear without these protective measures. In this demonstration, a query related to firearms is posed, which is not an appropriate topic for a hotel assistant.']","The AI gateway aids in prompt management by allowing for the templating and decorating of prompts, which is crucial for development use cases. It also handles governance and allows for the implementation of policies. Additionally, logging policies can be implemented for observability, ensuring that all actions are tracked and monitored, which contributes to effective management and governance of the AI gateway.",multi_hop_specific_query_synthesizer
Howw does vertikal AI enhanse healthcare customer support by integrating domain expertise and regulatory compliance?,"['<1-hop>\n\n## [195.60s] Advantages of Vertical AI\nVertical AI offers several advantages, including:\n\n1. **Domain Expertise**: Vertical AI can deliver precision and relevance in critical applications.\n2. **Regulatory Alignment**: Industries such as healthcare, finance, and legal are highly regulated, necessitating strict adherence to data sharing and communication protocols.\n3. **Business Impact**: Vertical AI can drive automation and insights tailored to specific verticals, which generic solutions may not address.\n4. **Competitive Advantage**: Specialized tools designed for specific requirements provide a competitive edge.', '<2-hop>\n\n### [350.72s] Framework for Vertical AI\nThe vertical AI layer is built on existing frameworks, utilizing core large language models (LLMs) from companies like OpenAI, Anthropic, and Gemini. These foundational models serve as the base for horizontal AI applications. On top of this, supporting frameworks such as retrieval-augmented generation (RAG) and data infrastructure are integrated. The vertical layer introduces industry-specific model tuning and regulatory compliance, ensuring that the AI solutions are tailored to meet the unique needs of specific sectors.\n\n## [424.88s] Example: Healthcare Customer Support\nTo illustrate the effectiveness of vertical AI, consider a healthcare customer support requirement. At the foundational level, general-purpose LLMs provide basic language capabilities. Companies like Sierra and Decagon enhance these capabilities with frameworks optimized for customer support. The vertical AI layer then adds the necessary clinical expertise, compliance with healthcare regulations, and integration with electronic health record systems. Without this tailored vertical layer, the AI solution would lack the understanding of healthcare nuances and regulatory constraints essential for real-world deployment.']","Vertical AI enhances healthcare customer support by integrating domain expertise and regulatory compliance through a specialized layer that builds on existing frameworks and large language models. This vertical layer introduces industry-specific model tuning and ensures compliance with healthcare regulations, which is crucial for real-world deployment. Companies like Sierra and Decagon optimize general-purpose language models for customer support, while the vertical AI layer adds clinical expertise and integrates with electronic health record systems, ensuring the AI solution understands healthcare nuances and meets regulatory constraints.",multi_hop_specific_query_synthesizer
